# -*- org-ref-bibliography-notes: "~/Dropbox/Org/Projects/SOPS.org" -*-
#+BIBLIOGRAPHY: ~/Code/SOPS/SOPS.bib
#+TITLE: A Safer Online Public Square: Research Notes

* Todo
** DONE [#A] start exploratory research
CLOSED: [2017-08-24 Thu 16:32]
:LOGBOOK:
#+BEGIN: clocktable :maxlevel 2 :scope subtree
#+CAPTION: Clock summary at [2017-08-30 Wed 12:40]
| Headline                       | Time   |      |
|--------------------------------+--------+------|
| *Total time*                   | *7:19* |      |
|--------------------------------+--------+------|
| \_  start exploratory research |        | 7:19 |
#+END:

CLOCK: [2017-08-18 Fri 14:28]--[2017-08-18 Fri 15:06] =>  0:38
CLOCK: [2017-08-18 Fri 11:30]--[2017-08-18 Fri 12:11] =>  0:41
CLOCK: [2017-08-17 Thu 20:02]--[2017-08-17 Thu 20:29] =>  0:27
CLOCK: [2017-08-17 Thu 17:41]--[2017-08-17 Thu 18:36] =>  0:55
CLOCK: [2017-08-16 Wed 13:28]--[2017-08-16 Wed 15:26] =>  1:58
CLOCK: [2017-08-13 Sun 17:51]--[2017-08-13 Sun 17:57] =>  0:06
CLOCK: [2017-08-13 Sun 17:17]--[2017-08-13 Sun 17:51] =>  0:34
CLOCK: [2017-08-13 Sun 16:14]--[2017-08-13 Sun 16:38] =>  0:24
CLOCK: [2017-08-13 Sun 15:42]--[2017-08-13 Sun 16:08] =>  0:26
CLOCK: [2017-08-13 Sun 13:17]--[2017-08-13 Sun 14:27] =>  1:10
:END:
** TODO read ACL workshop papers
#+BEGIN: clocktable :maxlevel 2 :scope subtree
#+CAPTION: Clock summary at [2017-08-30 Wed 12:41]
| Headline                     | Time    |       |
|------------------------------+---------+-------|
| *Total time*                 | *14:05* |       |
|------------------------------+---------+-------|
| \_  read ACL workshop papers |         | 14:05 |
#+END:

:LOGBOOK:
CLOCK: [2017-08-28 Mon 12:07]--[2017-08-28 Mon 13:18] =>  1:11
CLOCK: [2017-08-28 Mon 09:34]--[2017-08-28 Mon 11:58] =>  2:24
CLOCK: [2017-08-27 Sun 20:56]--[2017-08-27 Sun 21:24] =>  0:28
CLOCK: [2017-08-27 Sun 20:49]--[2017-08-27 Sun 20:56] =>  0:07
CLOCK: [2017-08-27 Sun 19:35]--[2017-08-27 Sun 19:58] =>  0:23
CLOCK: [2017-08-26 Sat 11:41]--[2017-08-26 Sat 13:13] =>  1:32
CLOCK: [2017-08-26 Sat 10:43]--[2017-08-26 Sat 11:21] =>  0:38
CLOCK: [2017-08-26 Sat 09:48]--[2017-08-26 Sat 10:14] =>  0:26
CLOCK: [2017-08-25 Fri 19:30]--[2017-08-25 Fri 20:01] =>  0:31
CLOCK: [2017-08-25 Fri 19:05]--[2017-08-25 Fri 19:23] =>  0:18
CLOCK: [2017-08-25 Fri 18:14]--[2017-08-25 Fri 19:04] =>  0:50
CLOCK: [2017-08-21 Mon 18:43]--[2017-08-21 Mon 19:00] =>  0:17
CLOCK: [2017-08-21 Mon 16:01]--[2017-08-21 Mon 17:19] =>  1:18
CLOCK: [2017-08-21 Mon 13:35]--[2017-08-21 Mon 14:15] =>  0:40
CLOCK: [2017-08-21 Mon 10:58]--[2017-08-21 Mon 12:19] =>  1:21
CLOCK: [2017-08-21 Mon 09:59]--[2017-08-21 Mon 10:45] =>  0:46
CLOCK: [2017-08-18 Fri 16:18]--[2017-08-18 Fri 16:31] =>  0:13
CLOCK: [2017-08-18 Fri 15:54]--[2017-08-18 Fri 16:08] =>  0:14
CLOCK: [2017-08-18 Fri 15:23]--[2017-08-18 Fri 15:51] =>  0:28
:END:

** DONE write first report
CLOSED: [2017-08-22 Tue 11:31]
:LOGBOOK:
CLOCK: [2017-08-22 Tue 09:23]--[2017-08-22 Tue 11:11] =>  1:48
:END:
** DONE write second report
CLOSED: [2017-08-28 Mon 15:38]
** DONE clean up, read short articles
CLOSED: [2017-08-28 Mon 15:38]
:LOGBOOK:
CLOCK: [2017-08-22 Tue 14:46]--[2017-08-22 Tue 14:54] =>  0:08
:END:
** TODO prepare a list of NLP journals to search
** TODO search NLP journals for keywords 
** TODO reach out to Phil for Gamergate tweets
** TODO search ACM
** TODO search Arxiv
** TODO read papers about readability
** TODO read papers about automated essay grading
** TODO read papers about spam filtering
** TODO explore Kaggle task: [[https://www.kaggle.com/c/detecting-insults-in-social-commentary][Detecting Insults in Social Commentary | Kaggle]]
:LOGBOOK:
CLOCK: [2017-09-03 Sun 17:16]--[2017-09-03 Sun 18:52] =>  1:36
:END:
** TODO identify good researchers to invite to Columbia
** Administrative
*** DONE send Susan a copy of my UW syllabus
CLOSED: [2017-09-01 Fri 15:51]
*** DONE send Susan a copy of my calendar
CLOSED: [2017-09-01 Fri 15:51]
*** DONE [#A] fill out timesheet and submit to French department
CLOSED: [2017-08-30 Wed 12:00] SCHEDULED: <2017-08-30 Wed>
:LOGBOOK:
CLOCK: [2017-08-30 Wed 12:39]--[2017-08-30 Wed 13:00] =>  0:21
:END:
*** DONE [#A] ask French dept about sending PAF back to the English Dept  
CLOSED: [2017-09-27 Wed 11:59]
:LOGBOOK:
CLOCK: [2017-09-27 Wed 11:46]--[2017-09-27 Wed 11:59] =>  0:13
:END:
  [[mu4e:msgid:cb16c372-6032-1fef-570e-4c1770b0e42d@columbia.edu][uwp-list Information Memo #3: What to do if you worked elsewhere on campus this summer or will during the year]]
*** TODO [#A] fill out timesheet and submit to French department
DEADLINE: <2017-09-28 Thu> SCHEDULED: <2017-09-27 Wed>
:LOGBOOK:
CLOCK: [2017-09-27 Wed 11:59]--[2017-09-27 Wed 12:24] =>  0:25
:END:
** TODO organize GitHub repository into folders  
  [[mu4e:msgid:CAAobwCjeCaVxUtrTRsE89qFFSnVW0dE46bp0jtBwX+YEP=3Zgg@mail.gmail.com][Re: a time to meet this week?]]
** TODO explore hatebase.org dataset
** TODO explore psycholinguistics journals
:LOGBOOK:
CLOCK: [2017-09-14 Thu 12:00]--[2017-09-14 Thu 13:02] =>  1:02
CLOCK: [2017-09-13 Wed 14:15]--[2017-09-13 Wed 14:46] =>  0:31
CLOCK: [2017-09-13 Wed 12:28]--[2017-09-13 Wed 13:13] =>  0:45
CLOCK: [2017-09-13 Wed 11:44]--[2017-09-13 Wed 12:17] =>  0:33
:END:
*** DONE Journal of Psycholinguistic Research
CLOSED: [2017-09-14 Thu 13:12]
** TODO write report 3
:LOGBOOK:
CLOCK: [2017-09-14 Thu 13:02]--[2017-09-14 Thu 14:03] =>  1:01
:END:
** DONE [#A] make outline of master report
CLOSED: [2017-09-27 Wed 12:36] SCHEDULED: <2017-09-23 Sat>
:LOGBOOK:
CLOCK: [2017-09-25 Mon 14:33]--[2017-09-25 Mon 15:53] =>  1:20
:END:
** TODO [#A] set up Doodle poll for next meeting
:LOGBOOK:
CLOCK: [2017-09-25 Mon 18:00]--[2017-09-25 Mon 18:19] =>  0:19
:END:
** TODO make master report
DEADLINE: <2017-10-07 Sat> SCHEDULED: <2017-10-07 Sat>
:LOGBOOK:
CLOCK: [2017-10-07 Sat 14:44]
CLOCK: [2017-10-07 Sat 12:20]--[2017-10-07 Sat 13:13] =>  0:53
:END:
* Links 
** News, Blogs, Mass Media
*** DONE [[https://www.nytimes.com/2017/06/21/opinion/whatsapp-crowds-and-power-in-india.html][*New York Times* WhatsApp, Crowd, Power in India]]
CLOSED: [2017-08-16 Wed 13:37]
- Describes fake news circulated using WhatsApp that results in mob violence, riots

*** DONE New York Times: [[https://www.nytimes.com/2017/07/01/opinion/sunday/save-free-speech-from-trolls.html?action=click&pgtype=Homepage&clickSource=story-heading&module=opinion-c-col-left-region&region=opinion-c-col-left-region&WT.nav=opinion-c-col-left-region][NYT: Save Free Speech from Trolls]]
CLOSED: [2017-08-16 Wed 14:55]
- "...the anti-free-speech charge, applied broadly to cultural criticism and especially to feminist discourse, has proliferated." 
- "[Anita] Sarkeesian has been relentlessly stalked, abused, and threatened since 2012, when she started a Kickstarter campaign to fund a series of YouTube videos critiquing the representation of women in video games."
- Sarkeesian: "They're weaponizing free speech to maintain their cultural dominance."
- "'Free speech' rhetoric begot 'fake news,' which begot 'alternative facts.'"

*** DONE [[https://datasociety.net/blog/2017/01/18/online-harassment-digital-abuse/][Data & Society: Online Harassment and Digital Abuse]]
CLOSED: [2017-08-16 Wed 15:02]
- See report in [[Statistics about Harassment]] below
*** DONE [[http://aclweb.org/anthology/W17-30][Proceedings of the first ACL Workshop on Abusive Language Online]]
CLOSED: [2017-08-18 Fri 12:06]
- Contains a number of relevant papers on the automated detection of abusive language. Parsed this into individual entries. 
*** TODO [[https://meta.wikimedia.org/wiki/Research:Online_harassment_resource_guide][Online Harassment Resource Guide - Mattias, J. Nathan (et. al)]]
- Susan: "Literature review on online harassment circa 2015/2016. Created for Wikimedia Foundation by folks from MIT Center for Civic Media & Berkman Center for Internet and Society"
- Very thorough overview
*** TED talks
**** [[https://www.ted.com/talks/ashley_judd_how_online_abuse_of_women_has_spiraled_out_of_control][Ashley Judd: How online abuse of women has spiraled out of control | TED Talk | TED.com]]
October 2016 at TEDWomen 2016

#+begin_quote
Judd recounts her ongoing experience of being terrorized on social media for her unwavering activism and calls on citizens of the internet, the tech community, law enforcement and legislators to recognize the offline harm of online harassment.
#+end_quote

"because the threat of violence is experienced neurobiologically as violence. The cortisol shoots up, the limbic system gets fired, we lose productivity at work." 

Judd founds The Speech Project: 
 - http://wmcspeechproject.com/
 
"EDGE, the global standard for gender equality, is the minimum standard." 

And the law: "In New York recently, the law could not be applied to a perpetrator because the crimes must have been committed -- even if it was anonymous -- they must have been committed by telephone, in mail, by telegraph --" 

https://github.com/JonathanReeve/sops
** Software
*** DONE [[https://devpost.com/software/trollbusters][TrollBusters | Devpost]]
CLOSED: [2017-08-25 Fri 19:16]
"Offering online "pest control" solutions for women news publishers"
**** DONE presentation slides: [[https://www.slideshare.net/locallygrownnews/trollbusters-international-womens-media-foundation-hackathon-solution][TrollBusters: International Women's Media Foundation Hackathon Soluti…]]
CLOSED: [2017-08-13 Sun 14:27]
***** TODO Use CATS: "C.A.T.S.: Clustering Analysis and Targeting System, Ohio University" 
 - "Using a proprietary technology for network analysis developed by Ohio University students, we find and aggregate communities of trolls and identify who else is a subject of attack"
**** DONE News article: [[http://alldigitocracy.org/combating-hate-speech-against-women-on-twitter/][Team developing tool to combat online harassment of women journalists takes top prize at New York hack-a-thon | All Digitocracy]]
CLOSED: [2017-08-13 Sun 14:26]
"TrollBusters will use proprietary audience targeting software, designed by a team at Ferrier’s university, to identify communities of trolls around any given issue using natural language processing. The service will counter cyberattacks in real- time with online community support and positive messaging, Ferrier said in her pitch." 
*** TODO [[http://www.perspectiveapi.com/][Perspective]] (Jigsaw, Google) 
- Looks like much of their code is [[https://github.com/conversationai][on GitHub]]
- NYT is working with them (Jigsaw) to aid moderation
**** TODO [[https://motherboard.vice.com/en_us/article/qvvv3p/googles-anti-bullying-ai-mistakes-civility-for-decency][Google's Anti-Bullying AI Mistakes Civility for Decency - Motherboard]]
**** TODO [[http://www.nytco.com/the-times-is-partnering-with-jigsaw-to-expand-comment-capabilities/][The Times is Partnering with Jigsaw to Expand Comment Capabilities | The New York Times Company]]
**** TODO Jigsaw working with Wikipedia: [[https://meta.wikimedia.org/wiki/Research:Detox][Research:Detox - Meta]]
*** DONE [[https://coralproject.net/][The Coral Project]]
CLOSED: [2017-08-22 Tue 14:46]
- Mozilla, also in use by NYT
- Unclear how or whether this uses ML or automated detection of abuse. 
  - "Our Talk tool makes it easier for people to mute other users, and for newsrooms to spot and deal with abusive contributions quickly. It keeps you closer to conversations that you want to participate in, and away from those that you don’t."
- [[https://blog.coralproject.net/talk-features/][Talk v1 features – The Coral Project]]
  - "Banned words are immediately rejected; suspect words are automatically flagged"
  - "Links and banned/suspect words are highlighted for easier moderation" 
*** TODO [[https://tools.wmflabs.org/detox/%20%20][Wikipedia DeTox]] (also Jigsaw) 
**** Test
- Testing aggression model: 
  - "Be careful, you might find some white powder in an envelope come in the mail one day." 1% aggressive. 
  - "If you keep this up, you find yourself sleeping with the fishes." 12% aggressive. 
  - "I'm going to come to your house." 48% aggressive. 
  - "I'm going to nominate you for the Nobel prize, you brilliant man." 61% aggressive.
*** Development contests
**** TODO 2012 Kaggle Task, [[https://www.kaggle.com/c/detecting-insults-in-social-commentary][Detecting Insults in Social Commentary]] :hasCorpus:
- winning entries used Python and scikit-learn; lots of entries ranking 8th and below used R
- tokenization is a (surprisingly) important part of this--what constitutes a word
  - collapsing spaces between single-letters: "f u c k" -> "fuck"
- many of these seem to have unnecessarily custom implementations of common tokenization, stemming, or other functions. 
  - Q: could this be improved by using industry-standard libraries?
- almost all use some form of cross-validation or grid search, tuning its own parameters 
***** Vivek Sharma, 1st Place
****** TODO original code: [[https://kaggle2.blob.core.windows.net/forum-message-attachments/4809/model6.py][single python script]]
- added to repository at [[file:Code/kaggle-1st-sharma/kaggle-1st-sharma.py]]
******* TODO try to get this to work
:LOGBOOK:
CLOCK: [2017-09-03 Sun 18:52]--[2017-09-03 Sun 20:07] =>  1:15
:END:
- [X] download test data from Kaggle
- [X] convert Python 2 to Python 3
- [ ] figure out what's going on with the strange probability scores - maybe read the discussion again
******* TODO see if it can be improved by:  
 - [ ] replacing stemmers
****** DONE [[https://kaggle2.blob.core.windows.net/forum-message-attachments/4810/badwords.txt][uses this "bad words" file]]
****** DONE description
CLOSED: [2017-09-03 Sun 17:34]
#+BEGIN_QUOTE  
My feature set was almost the same as the char and word features that Andreas used. SVC gave me better performance than regularized LR.  And, some normalizations (like tuzzeg mentioned), along with using a bad words list (http://urbanoalvarez.es/blog/2008/04/04/bad-words-list/) helped quite a bit. Those were probably the only differences between Andreas' score and mine. The single SVC model would have won by itself, although the winning submission combined SVC with RF which improved the score marginally over just SVC. Regularized LR and GBRT were also tried, but they did not change the score much. I did not use the datetime field.

Tuzzeg, I experimented a little bit with phrase features, and I'm pretty sure they would be needed in any implementation of such a system. A lot of the insults were of the form: "you are/you're a/an xxxx", "xxxx like you", "you xxxx". I tried to look for a large +ve/-ve word list to determine sentiment of such phrases with unseen words, but I couldn't find a good word list that was freely available for commercial use. Does anyone know of one? Ultimately, I didn't use any such features except for a very simplified one based on "you are/you're xxx" which did help the score, although, only to a small extent. 
#+END_QUOTE
***** Tuzzeg, 2nd Place
- uses Stanford POS and Stanford tagger for feature extraction, Python and scikit-learn for everything else
- uses a Random Forest regressor as a meta-classifier for a stack of basic classifiers
- uses different language models: 
  - char n-grams
  - stem + POS models
  - ! "syntax bigrams" using dependency modeling (a word paired with the tag of its dependent, e.g. "understand do" -> "understand AUX)
****** DONE Short technique description
CLOSED: [2017-09-03 Sun 17:34]
#+BEGIN_QUOTE    
I used scikit-learn as well, with Stanford POS tagger and Stanford parser. My approach in general was ensemble of LogisitcRegression classifiers over words, stemmed words, POS tags, char ngrams, words/stems 2,3-grams, word/stem subsequences, language models over words/stems/tags and a bunch of features over dependency parsing results (110 basic classifiers in final solution). All of them were stacked using ExtraTreesRegressor.

I didn't use word correction - which could help to detect such phrases like 'r u'=='are you' or 'f#%k'.
#+END_QUOTE 
****** DONE [[https://github.com/tuzzeg/detect_insults][code on GitHub]]
CLOSED: [2017-09-03 Sun 18:24]
- Much, much more code than the 1st place script
******* TODO get this to work
****** DONE [[https://github.com/tuzzeg/detect_insults/blob/master/README.md][In-depth description]]
CLOSED: [2017-09-03 Sun 18:24]
***** Andrei Olariu, 3rd Place
- very elaborate custom tokenization, removes repeated letters ("coooool" -> "cool")
  - "grouping together sequences of one-letter words – like “f u c k”"
- uses neural net classifier to tie together three basic categorizers
- adds custom features: "the ratio of curse words; the text length; the ratio of *, ! or ?; the ratio of capital letter (should have used words in all caps instead)" 
****** DONE Summary
CLOSED: [2017-09-03 Sun 17:41]
"SVMs, neural networks and some good tokenizing"
****** DONE [[http://webmining.olariu.org/my-first-kaggle-competition-and-how-i-ranked/][Description in blog post]]
CLOSED: [2017-09-03 Sun 18:33]
****** DONE [[https://github.com/andreiolariu/kaggle-insults][code on GitHub]]
CLOSED: [2017-09-03 Sun 18:35]

- like 2nd place entry, much, much more code here than 1st place script
***** Joshnk, 4th Place
****** DONE Summary 
CLOSED: [2017-09-03 Sun 17:42]
#+BEGIN_QUOTE 
I used character n-grams, tfidf with sublinear_tf and SGDRegressor with early stopping. I am somewhat proud of the early stopping code.

My reason for using a regression estimator was that the evaluation was going to be AUC, which is sensitive only to the order of the scores, not the finer details. Had I used a classifier, I would have needed to do something with predict proba to arrange the items in a good order anyway. SGD is also nice because it works well with sparse inputs lets you explore things like the use of the elastic net penalty while sticking with the same classifier.

As I said in my comment on Andreas Mueller's blog, the final order has an element of luck to it, because the final test set was so small and the labeling was rather noisy
#+END_QUOTE
****** DONE [[https://github.com/cbrew/Insults/blob/master/Insults/insults.py][code on GitHub]]
CLOSED: [2017-09-03 Sun 18:28]
- command-line Python program
- seems to be manually tuned instead of using CV? 
***** Andreas Mueller, 6th Place
****** TODO [[https://www.kaggle.com/c/detecting-insults-in-social-commentary][code on GitHub]]
****** DONE Blog post: [[http://peekaboo-vision.blogspot.de/2012/09/recap-of-my-first-kaggle-competition.html][Peekaboo: Recap of my first Kaggle Competition: Detecting Insults in Social Commentary {update 3}]]
CLOSED: [2017-09-03 Sun 18:50]
- uses a combination of four language models, incl. char n-grams, word n-grams (performed better than chars), custom features
- all params cross-validated
- bad words list: "For the list of bad words, I used one that allegedly is also used by google. As this will include 'motherfucker' but not 'idiot' or 'moron' (two VERY important words in the training / leaderboard set), I extended the list with these and whatever the thesaurus said was 'stupid'." 
** Organizations
*** Colin's doc: [[https://docs.google.com/document/d/1nMbD79FwAHny-9VEf2vLXZIk9hBdx8ttkcCFA5GFGyM/edit?ts=59a4686b#heading=h.iy6oqdld37n2][Organizations doing something - Google Docs]]
*** DONE [[http://wmcspeechproject.com/][WMC Speech Project]]
CLOSED: [2017-10-07 Sat 12:45]
**** DONE [[http://wmcspeechproject.com/research-statistics/][WMC Speech Project » Research & Statistics]]
CLOSED: [2017-10-07 Sat 12:45]
*** DONE [[https://www.trolldor.com/][Trolldor: the global blacklist of twitter trolls]]
CLOSED: [2017-08-13 Sun 14:17]

#+BEGIN_QUOTE 
The aim of Trolldor is to combat the defenselessness of Twitter users. We want to get across the need behavior on Twitter to be based on respect for users, to encourage a good social network environment.

We feel that the behavior of some Twitter users is part of the problem, which is why we’ve created Trolldor, a place where users themselves are the ones who can report other users that fail to respect everyone else.

Trolldor works like a blacklist of Trolls, and is open to any user in the world with a Twitter account.
#+END_QUOTE
 
- Needs three reports from different users to get listed. 
- Maintain a list of top 10 worldwide tr
*** DONE [[https://www.nohatespeechmovement.org/][No Hate Speech Movement]]
CLOSED: [2017-10-07 Sat 14:50]
 "A youth campaign of the Council of Europe for human rights online, to reduce the levels of acceptance of hate speech and develop online youth participation and citizenship, including in Internet governance processes."

*** TODO [[https://www.splcenter.org/hate-map][Southern Poverty Law Center]]
 - maintain a list and map of 917 hate groups operating in the US

*** TODO [[https://cyberbullying.org/][Cyberbullying Research Center]]
"The Cyberbullying Research Center is dedicated to providing up-to-date information about the nature, extent, causes, and consequences of cyberbullying among adolescents. Cyberbullying can be defined as “Willful and repeated harm inflicted through the use of computers, cell phones, and other electronic devices.” It is also known as “cyber bullying,” “electronic bullying,” “e-bullying,” “sms bullying,” “mobile bullying,” “online bullying,” “digital bullying,” or “Internet bullying.” The Center also explores other adolescent behaviors online including sexting, problematic social networking practices, and a variety of issues related to digital citizenship."

*** TODO [[https://cpj.org/][Committee to Protect Journalists]]
"The Committee to Protect Journalists is an independent, nonprofit organization that promotes press freedom worldwide. We defend the right of journalists to report the news without fear of reprisal."
*** TODO Anti-Defamation League Task Force on Harassment and Journalism
**** Description of report: [[http://denver.adl.org/news/adl-task-force-issues-report-detailing-widespread-anti-semitic-harassment-of-journalists-on-twitter-during-2016-campaign/][Anti-Defamation League | ADL TASK FORCE ISSUES REPORT DETAILING WIDESPREAD ANTI-SEMITIC HARASSMENT OF JOURNALISTS ON TWITTER DURING 2016 CAMPAIGN | Denver]]
cite:anti-defamation_league_adl_2016
*** TODO [[http://haltabuse.org/][Working to Halt Online Abuse]] 
*** TODO [[http://www.broadbandcommission.org/workinggroups/pages/bbandgender.aspx][UN Broadband Commission for Sustainable Development Working Group on Broadband and Gender]]
**** TODO Report: [[http://www.unwomen.org/~/media/headquarters/attachments/sections/library/publications/2015/cyber_violence_gender%2520report.pdf?v=1&d=20150924T154259][Cyber Violence Against Women and Girls]]
***** TODO Response in NY Mag: [[http://nymag.com/scienceofus/2015/09/uns-cyberharassment-report-is-really-bad.html][The U.N.’s Cyberharassment Report Is Really Bad]]
*** TODO SRI International 
"nine months ago, a social network approached the SRI and said it had a major problem with bullying on its platform. The company, which Winarsky declined to identify, had already gathered a wealth of reports and data sets on bullying and offered them to SRI to see if its researchers could do anything to help curb the problem." cite:alba_weeding_2015 
*** TODO [[https://womenactionmedia.org/][Women Action Media]] (WAM!)
"allowed to report and identify harassment on behalf of others" and report them to Twitter cite:lapowsky_its_2015 
*** TODO [[https://www.hackharassment.com/][Hack Harassment]]
"Hack Harassment is a coalition of organizations and individuals who share in the common goal of building a more inclusive and supportive online community.  Hack Harassment does not guarantee the world will be free from online harassment, but together, we hope to bring us all closer to that goal." 
*** Algorithmic
**** TODO [[https://jigsaw.google.com/vision/][Jigsaw]]: org within Alphabet (Google) 
"We’re an incubator within Alphabet that builds technology to tackle some of the toughest global security challenges facing the world today—from thwarting online censorship to mitigating the threats from digital attacks to countering violent extremism to protecting people from online harassment." 

- Creators of project [[http://www.perspectiveapi.com/][Perspective]]
** Statistics about Harassment
*** Proportion of Internet users that experience harassment
- 47% (D&S report) 
*** [[http://onlineharassmentdata.org/][Infographic: The Rise of Online Harassment]]
Survey by: 
 - Rad Campaign (Web Design Agency)
 - Lincoln Park Strategies (Data analytics)
 - Craig Newmark (Consultant?)
*** DONE [[http://www.pewinternet.org/2014/10/22/online-harassment/][Online Harassment | Pew Research Center]]
CLOSED: [2017-10-07 Sat 12:56]
2014 Report
*** DONE [[http://www.haltabuse.org/resources/stats/index.shtml][WHOA: Cyberstalking Statistics.]]
CLOSED: [2017-10-07 Sat 12:57]
*** [[http://www.iwmf.org/blog/2014/03/07/intimidation-threats-and-abuse/][Intimidation, Threats, and Abuse | International Women's Media Foundation (IWMF)]]
*** TODO [[https://www.datasociety.net/pubs/oh/Online_Harassment_2016.pdf][Data and Society Report: Online Harassment, Digital Abuse, and Cyberstalking in America]
**** DONE [[https://qz.com/844319/a-new-study-suggests-online-harassment-is-pressuring-women-and-minorities-to-self-censor/][A new study suggests online harassment is pressuring women and minorities to self-censor — Quartz]]
CLOSED: [2017-08-16 Wed 15:22]
- "Researchers consistently find that people self-censor online to avoid retaliation. This could be positive: For instance, people might be less likely to use a racial slur online if they think they’ll be condemned for it. But given the differences in people’s experience of harassment, this survey suggests that young people, especially young women and LGB people, are less likely to make online contributions at all because they’re worried about being attacked for it." 
**** DONE Blog post: [[https://points.datasociety.net/culture-of-harassment-1d999adbfac3][Culture of Harassment – Data & Society: Points]]
CLOSED: [2017-08-18 Fri 12:10]
- Summarizes D&S report. 
- "Danah Boyd reads Data & Society and CiPHR’s new report, “Online Harassment, Digital Abuse, and Cyberstalking in America,” and connects it with her own qualitative research and today’s political culture. Online harassment, she argues, suppresses voices that need to be heard for the public sphere to be public. — Ed." 
**** TODO [[https://www.theatlantic.com/technology/archive/2016/11/people-censor-themselves-online-for-fear-of-being-harassed/508523/][47 Percent of U.S. Internet Users Have Experienced Online Abuse - The Atlantic]]
** Social Media Services
*** General Legal / Terms of Service Issues
**** TODO "Towards a better protection of social media users: a legal perspective on the terms of use of social networking sites" cite:wauters_towards_2014 
**** TODO "Intermediaries and hate speech: Fostering digital citizenship for our information age." cite:citron_intermediaries_2011 
*** Facebook 
**** DONE - ProPublica: [[https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms][Facebook's Secret Censorship Rules Protect White Men from Hate Speech But Not Black Children]]
CLOSED: [2017-08-16 Wed 14:05]
- Describes Facebook's rules for deleting posts
- Facebook doesn't delete attacks on "subsets" of people, e.g. "female drivers," but deletes posts of "protected categories," of entire races, sexes, religious affiliations, e.g. "white men."
- Facebook permits speech that is illegal in some countries, like Holocaust denial
- FB currently employs about 4,500 censors
- FB shuts down accounts of some activists. (Article doesn't explain reasons.)
- "Kate Klonick, a Ph.D. candidate at Yale Law School who has spent two years studying censorship operations at tech companies,"
- "Candidate Trump’s posting — which has come back to haunt him in court decisions voiding his proposed travel ban — appeared to violate Facebook’s rules against “calls for exclusion” of a protected religious group. Zuckerberg decided to allow it because it was part of the political discourse, according to people familiar with the situation."
  - Q: Would allowing incendiary posts/comments ultimately be healthy for society, since it allows for criticism and discourse? 

*** Twitter 
**** DONE Twitter blog post: [[https://blog.twitter.com/official/en_us/a/2016/progress-on-addressing-online-abuse.html][Progress on addressing online abuse]]
CLOSED: [2017-08-16 Wed 15:19]
- "We’re enabling you to mute keywords, phrases, and even entire conversations you don’t want to see notifications about"
- "We’ve also improved our internal tools and systems in order to deal more effectively with this conduct when it’s reported to us. Our goal is a faster and more transparent process." 
**** DONE [[https://support.twitter.com/articles/20175050#][Twitter: Hateful Conduct Policy]]
CLOSED: [2017-08-16 Wed 15:21]
- "You may not promote violence against or directly attack or threaten other people on the basis of race, ethnicity, national origin, sexual orientation, gender, gender identity, religious affiliation, age, disability, or disease."
- "Context matters. Some Tweets may seem to be abusive when viewed in isolation, but may not be when viewed in the context of a larger conversation."
- Say that they may suspend accounts for violations.
**** DONE Wired article: [[https://www.wired.com/2017/03/twitter-abuse-tools/][Twitter Eggs, the End Has Finally Come for Your Awfulness | WIRED]]
CLOSED: [2017-08-17 Thu 17:52]
- On algorithms for filtering trolls: "Twitter says it has developed algorithms that can detect when an account engages in abusive behavior—for instance, if it repeatedly tweets at non-followers."
- On user-level filtering: "Twitter will now let users filter "Twitter eggs" out of their notifications."
**** Twitter timeout 
***** TODO [[https://techcrunch.com/2017/02/16/twitter-starts-putting-abusers-in-time-out/][Twitter starts putting abusers in “time out” | TechCrunch]]
*** Mastodon
**** DONE [[http://www.newstatesman.com/science-tech/social-media/2017/04/mastodonsocial-why-does-every-new-twitter-fail][Mastodon.social: Why does every new “Twitter” fail?]]
CLOSED: [2017-08-16 Wed 14:51]
- Calls Mastodon a failure, and attempts a postmortem. 
**** TODO WIRED: [[https://www.wired.com/2017/04/like-twitter-hate-trolls-try-mastodon/][Social Media Upstart Mastodon Is Like Twitter, Except Way More Civil | WIRED]]
*** WhatsApp
*** Reddit
**** DONE [[https://www.reddit.com/r/announcements/comments/4dmnn6/new_and_improved_block_user_feature_in_your_inbox/][New and improved "block user" feature in your inbox. : announcements]]
CLOSED: [2017-08-16 Wed 15:13]
**** TODO [[https://socialmediacollective.org/2015/06/16/reddit-research/][Recognizing the Work of Reddit’s Moderators: Summer Research Project | Social Media Collective]]
*** Wikipedia
**** TODO The Work of Sustaining Order in Wikipedia: The Banning of a Vandal cite:geiger_work_2010 
**** TODO Book: Wikipedia and the Politics of Openness cite:tkacz_wikipedia_2014 
*** Metafilter
**** TODO Dissertation: "What we talk about when we talk about talking: Ethos at work in an online community" cite:warnick_what_2010  
Abstract: "This dissertation explores the rhetorical concept of ethos as it functions in contemporary online communities, via a case study of one successful online community, MetaFilter. com. A year-long virtual ethnography of MetaFilter demonstrates that understanding ethos as it functions online requires a multilayered definition that accounts for the traditional notion of ethos as vir bonus, the strict Aristotelian conception of ethos as ..." 
** People 
** Patents
*** [[https://www-google-com.ezproxy.cul.columbia.edu/patents/US5796948][Patent US5796948 - Offensive message interceptor for computers - Google Patents]] 
*** [[https://www-google-com.ezproxy.cul.columbia.edu/patents/US8868408][Patent US8868408 - Systems and methods for word offensiveness processing using aggregated ... - Google Patents]]
*** [[https://www-google-com.ezproxy.cul.columbia.edu/patents/US8473443][Patent US8473443 - Inappropriate content detection method for senders - Google Patents]]
*** [[https://www-google-com.ezproxy.cul.columbia.edu/patents/US7818764][Patent US7818764 - System and method for monitoring blocked content - Google Patents]]
*** [[https://www-google-com.ezproxy.cul.columbia.edu/patents/US20080109214][Patent US20080109214 - System and method for computerized psychological content analysis of ... - Google Patents]]

*** [[https://www.google.com/patents/US20110191105][Patent US20110191105 - Systems and Methods for Word Offensiveness Detection and Processing Using ... - Google Patents]]
* Problems, Topics
** Censorship policies of social media companies
** Flagging
*** TODO "What is a Flag for? Social Media Reporting Tools and the Vocabulary of Complaint" cite:crawford_what_2016
*** TODO Reporting, Reviewing, and Responding to Harassment on Twitter. cite:matias_reporting_2015  
*** TODO [[http://www.cpeterson.org/2013/07/22/a-brief-guide-to-user-generated-censorship/][A Brief Guide To User-Generated Censorship - Chris Peterson]]
** Counterspeech, Moderation
*** DONE "Vectors for Counterspeech on Twitter" cite:wright_vectors_2017 
CLOSED: [2017-08-28 Mon 10:30]
- counterspeech :: "a direct response to hateful or harmful speech" 57

Counterpseech "can exhibit a number of different communicative strategies including humor, emotional appeals, multi-stage dialog, and over verbal attack itself" 58
 - "an empathetic and/or kind tone, use of images, and use of humor" 59
 - "no indication that these forms are templated" 58 

Identify one-to-one counterspeech, many-to-one, and many-to-many

"The blog “Racists Getting Fired” made a practice of punishing people who posted racist content by contacting their employers and, similarly, demanding that they be fired (McDonald, 2014). Such responses are no doubt successful at changing the online speech of their targets, but may only harden the hateful convictions of those targets,
and constitute online mob justice." 60
***** [[https://www.washingtonpost.com/news/morning-mix/wp/2014/12/02/racists-getting-fired-exposes-weaknesses-of-internet-vigilantism-no-matter-how-well-intentioned/][‘Racists Getting Fired’ exposes weaknesses of Internet vigilantism, no matter how well-intentioned - The Washington Post]]

*** TODO "The Virtues of Moderation" cite:grimmelmann_virtues_2015 
*** TODO "Slash (dot) and burn: distributed moderation in a large online conversation space" cite:lampe_slash_2004 
*** TODO [[https://link.springer.com/article/10.1007/s11109-016-9373-5][Tweetment Effects on the Tweeted: Experimentally Reducing Racist Harassment | SpringerLink]]
** Cross-cultural studies
*** TODO "Rephrasing Profanity in Chinese Text" cite:su_rephrasing_2017 
*** TODO "Legal Framework, Dataset and Annotation Schema for Socially Unacceptable Online Discourse Practices in Slovene" cite:fiser_legal_2017 
*** TODO "Abusive Language Detection on Arabic Social Media" cite:mubarak_abusive_2017   
** Troll detection / troll bots / misinformation bots
*** At least 10% of #gamergate tweets have bot OSes (see below) 
*** DONE Tweet: [[https://twitter.com/conspirator0/status/900158823515770880][A pattern you may have noticed: many bot and troll accounts have usernames that end in 8 random digits.]]
CLOSED: [2017-08-25 Fri 19:01]
*** DONE [[https://www.twitteraudit.com/][Twitter Audit | How many of your followers are real?]]
CLOSED: [2017-08-25 Fri 19:01]
- Service that tries to detect whether your followers are real people. 
- How does it work? 
*** TODO [#B] "Exposing Paid Opinion Manipulation Trolls" cite:mihaylov_exposing_2015  
Abstract: "We solve the training data problem by assuming that a user who is called a /troll/ by several different people is likely to be such" 

Data: 
 - Scraped comments from the largest Bulgarian newspaper website (445)
 - Requires users to be logged in 

Features that distinguish between paid trolls and non-trolls: 
 - day of week: F-score of 0.89
 - reply status: 0.75
 - time in hours: 0.75

Results: 
 - "Overall, paid trolls looked roughly like the 'mentioned' trolls, except that they were posting most of their comments on working days and during working hours."
 - Paid trolls are more successful at upsetting people (negative votes from other users were correlated) 

*** TODO [#B] "Finding Opinion Manipulation Trolls in News Community Forums" cite:mihaylov_finding_2015
*** TODO [#C] "Propagation of trust and distrust for the detection of trolls in a social network" cite:ortega_propagation_2012 
*** TODO [#C] "Accurately detecting trolls in slashdot zoo via decluttering" cite:kumar_accurately_2014 
*** TODO [#C] "Assessing trust: contextual accountability" cite:rowe_assessing_2009 
*** TODO [#C] "Filtering offensive language in online communities using grammatical relations" cite:xu_filtering_2010 
*** TODO [#C] "Offensive language detection using multi-level classification" cite:razavi_offensive_2010 
** Automated Detection
*** Of high-quality contributions
**** DONE "How Useful are Your Comments?- Analyzing and Predicting YouTube Comments and Comment Ratings" cite:siersdorfer_how_2010 
CLOSED: [2017-08-21 Mon 10:06]
- "Can we predict the community feedback for comments?" 892
- "automatically generated content ratings might help to identify users showing malicious behavior such as spammers and trolls at an early stage, and, in the future, might lead to methods for recommending to an individual user of the system other users with similar interests and points of views." 892
- use 6.1M comments from 67K videos 893
  - mean # comments 475
- distribution of comment ratings skews positive, with mean of 0.61
- find MDWs for comments with high, low ratings
  - low rating MDWs contain racial, gender slurs, obscenities
- sentiment analysis shows correlation between machine-detected sentiment and ratings
  - use SentiWordNet thesaurus
- use SVM classifiers to predict categories 
  - predictably, the classifier works best on high and low ratings, not as well on comments with neutral ratings
- test "variance of comment ratings as indicator for polarizing videos"
  - find MDWS for polarizing and non-polarizing videos. 
  - high comment rating variance MDWS include political terms, terms relating to religion
  - low comment rating variance MDWs include sports-, hobby-, and tax-related terms
- "Politics videos have significantly more negatively rated comments than any other category. Music videos, on the other hand, have a clear majority of positively rated comments."
- Music has the highest mean comment rating, science and automotive videos the lowest.
  - Mean sentivalues across categories also correlate, with music showing the highest mean, and autos, gaming, science the with the lowest mean. 
**** DONE "The Editor's Eye: Curation and Comment Relevance on the New York Times" cite:diakopoulos_editors_2015 
CLOSED: [2017-08-21 Mon 10:32]
"explores the manifestation of editorial quality criteria in comments that have been curated and selected on the New York Times website as “NYT Picks.” The relationship between comment selection and comment relevance is examined through the analysis of 331,785 comments, including 12,542 editor’s selections. A robust association between editorial selection and article relevance or conversational relevance was found." 

"Could new computational tools be used to reduce the amount of time journalists need to spend doing this curatorial work, to identify worthy but overlooked contributions, or to scale their ability to consider more content?" 

NYT comment moderation: 
 - pre-moderate comments
 - assign "NYT Picks" badge to good comments

Preprocessing: tokenize, normalize, stopword filter, and stem
 - reduce the vocabulary to 22,837 features
 - transform into tf-idfs
 - analyze cosine similarity between comments and articles

Find that "the article relevance of the comment is positively associated with a higher chance of it being selected by an editor." 

"There was a slight negative correlation between elapsed time and whether the comment was an editor’s selection (Spearman rho = -0.048, p = 0). Thus, there are less editor’s selections later in the conversation." 3 

"Comments made in the first hour have a distinctly higher article relevance than in the immediately subsequent hours. But after about 18 hours the average article relevance begins increasing again up to hour 48" 3

This article seems to assume that tf-idf cosine similarity can be directly interpreted as "relevance." 
 - It's possible that a very relevant comment contains very few of the words used in the article, and would then be computationally considered irrelevant. 

**** DONE "Predicting information credibility in time-sensitive social media"  cite:castillo_predicting_2013 
CLOSED: [2017-08-21 Mon 11:53]
- supervised categorization of "credible" and non-credible tweet groups or "information cascades"
- study propogation of tweets, tweet "affirmations," "questions," and other reactions
- use data set of manually-labeled (Amazon Turk) tweets as "likely to be true," etc.  
- best 8 features that distinguish between "NEWS" and "CHAT" (discussion) labels: (573) 
  - ! "fraction of authors in the topic that have written a self-description (“bio” in Twitter terms)" 
  - "count of distinct URLs" 
  - "fraction of URLs pointing to domains in the top 100 most visited domains on the web" 
  - "average length of the tweets" 
  - "count of distinct user mentions" 
  - "fraction of tweets containing a hashtag"
  - "fraction of tweets containing a “frowning” emoticon"
  - "maximum depth of propagation trees"
- test clustering/classification methods, find that Random Forest classifies best.
- best features that distinguish between "credible" and "not credible" labels: (575) 
  - the average number of tweets posted by authors of the tweets in the topic in the past
  - the average number of followers of authors posting these tweets
  - the fraction of tweets having a positive sentiment
  - the fraction of tweets having a negative sentiment
  - the fraction of tweets containing a URL that contain the most frequent URL
  - the fraction of tweets containing a URL
  - the fraction of URLs pointing to a domain among the top 10,000 most visited
  - the fraction of tweets containing a user mention;
  - the average length of the tweets;
  - the fraction of tweets containing a question mark;
  - the fraction of tweets containing an exclamation mark;
  - the fraction of tweets containing a question or an exclamation mark;
  - the fraction of tweets containing a “smiling” emoticons;
  - the fraction of tweets containing a first-person pronoun;
  - the fraction of tweets containing a third-person pronoun; and
  - the maximum depth of the propagation trees.
- test clustering methods, find that logistic regression classifies with ~80% accuracy

**** DONE "Constructive Language in News Comments" cite:kolhatkar_constructive_2017 :hasCorpus:
CLOSED: [2017-08-21 Mon 14:12]
- create a custom annotated corpus 
  - crowdsource the annotation of comments as "constructive" or not (12)
  - "Out of the 1,121 comments, 603 comments (53.79%) were classified as constructive, 517 (46.12%) as non-constructive, and the annotators were not sure in only one case." (12) 
  - [[https://github.com/sfu-discourse-lab/Constructiveness_Toxicity_Corpus][corpus available on GitHub]]
  - also use Yahoo News Annotated Corpus and Argument Extraction Corpus
- train a Bi-directional Long Short-Term Memory model (biLSTM) (implemented in TensorFlow)
  - make word vectors for each word, using GloVe vectors
  - categorization is about 72% precise
- features with strong correlation with constructiveness: 
  - "argumentative discourse relations"
  - "stance adverbials (e.g., undoubtedly, paradoxically, of course)"
  - "reasoning verbs (e.g., cause, lead)" 
  - modals
- crowdsource annotation of comments as "toxic" or not on a scale
  - "constructiveness and toxicity are orthogonal categories." 
**** DONE "Finding high-quality content in social media" cite:agichtein_finding_2008 
CLOSED: [2017-08-25 Fri 18:20]
- study a Yahoo Answers corpus
- express "high quality content" through user reputation, 
  - calculated through graph-based algorithms like PageRank, HITS, ExpertiseRank
- features: "all word n-grams up to length 5 that appear in the collection more than 3 times used as features."
  - also add as features POS representations of n-grams
    - ! "Some part-of-speech sequences are typical of correctly- formed questions: e.g., the sequence “when|how|why to (verb)” (as in “how to identify. . . ”) is typical of lower-quality ques- tions, whereas the sequence “when|how|why (verb) (personal pronoun) (verb)” (as in “how do I remove. . . ”) is more typical of correctly-formed content."
  - use formality score of cite:heylighen_variation_2002
- classifier: stochastic gradient boosted trees
  - "A particularly useful aspect of boosted trees for our settings is their ability to utilize combinations of sparse and dense features." (187)
- relevance scores: "To represent this we include the KL-divergence between the language models of the two texts, their non-stopword overlap, the ratio between their lengths, and other similar features."
  - measure "non-stopword word overlap between question and answer"; this is one of their answer features
- readability: Kincaid score is an answer feature
***** 20 most signification question quality features: 
- Average number of ”stars” to questions by the same asker; the punctuation density in the question’s subject; the question’s category (assigned by the asker).; “Normalized Clickthrough:” The number of clicks on the question thread, normalized by the average number of clicks for all questions in its category.; Average number of ”Thumbs up” received by answers written by the asker of the current question.; Number of words per sentence.; Average number of answers with references (URLs) given by the asker of the current question.; Fraction of questions asked by the asker in which he opens the question’s answers to voting (instead of pick- ing the best answer by hand).; Average length of the questions by the asker; the number of “best answers” authored by the user; the number of days the user was active in the system.; “Thumbs up” received by the answers wrote by the asker of the current question, minus “thumbs down”, divided by total number of “thumbs” received.; “Clicks over Views:” The number of clicks on a question thread divided by the number of times the question thread was retrieved as a search result (see [2]); the KL-divergence between the question’s language model and a model estimated from a collection of question answered by the Yahoo editorial team (available in http://ask.yahoo.com); the fraction of words that are not in the list of the top-10 words in the collection, ranked by frequency; the number of “capitalization errors” in the question (e.g., sentence not starting with a capitalized word); the number of days that has passed since the asker wrote his/her first question or answer in the system; the total number of answers of the asker that have been selected as the “best answer”; the number of questions that the asker has asked in its most active category, over the total number of questions that the asker has asked; the entropy of the part-of-speech tags of the question.
***** 20 most significant answer features: 
  - Answer length; The number of words in the answer with a corpus frequency larger than c; the number of “thumbs up” minus “thumbs down” received by the answerer, divided by the total number of “thumbs” s/he has received.; the entropy of the trigram character-level model of the answer; the fraction of answers of the answerer that have been picked as best answers (either by the askers of such questions, or by a community voting); The unique number of words in the answer; average number of abuse reports received by the answerer over his/her answers ; 
  - The non-stopword word overlap between the question and the answer.
  - ∅ The Kincaid [21] score of the answer. 
  - The average number of answers received by the questions asked by the asker of this answer; the ratio between the length of the question and the length of the answer; the number of “thumbs up” minus “thumbs down” received by the answerer; the average numbers of “thumbs” received by the answers to other questions asked by the asker of this answer; the entropy of the unigram character-level model of the answer; the KL-divergence between the answer’s language model and a model estimated from the Wikipedia discussion pages; number of abuse reports received by the asker of the question being answered; the sum of the lengths of all the answers received by the asker of the question being answered; the sum of the “thumbs down” received by the answers received by the asker of the question being answered; the average number of answers with votes in the questions asked by the asker of the question being answered
    
**** DONE "How opinions are received by online communities: a case study on amazon.com helpfulness votes" cite:danescu-niculescu-mizil_how_2009 
CLOSED: [2017-08-26 Sat 10:04]
Study of Amazon.com reviews and evaluations of those reviews ("24 out of 25 people found this review helpful"). 

"We find that the perceived helpfulness of a review depends not just on its content but also but also in subtle ways on how the expressed evaluation relates to other evaluations of the same product." 1

Three-party concerns: "Rather than asking questions of the form “What did Y think of X?”, we are asking, “What did Z think of Y’s opinion of X?” Crucially, there are now three entities in the process rather than two." 1
 - ! "Heider’s theory of structural balance in social psychology seeks to understand subjective relationships by considering sets of three entities at a time as the basic unit of analysis."

! "A significant and particularly wide-ranging set of effects is based on the relationship of a review’s star rating to the star ratings of other reviews for the same product. We view these as fundamentally social effects, given that they are based on the relationship of one user’s opinion to the opinions expressed by others in the same setting." 

Dataset: "over four million reviews of roughly 675,000 books on Amazon’s U.S. site, as well as smaller but comparably- sized corpora from Amazon’s U.K., Germany, and Japan sites"

Test four hypotheses (2): 
 - "conformity hypothesis" that reviews are considered more helpful if their star ratings are close to the average
 - "individual-bias hypothesis" that users like reviews that agree with their opinions
 - "brilliant-but-cruel hypothesis" that users assume low reviews correlate with intelligence
 - "quality-only" hypothesis that ratings correlate with textual quality

! find that helpfulness ratio inversely proportional to star rating
 - reviews "punished asymmetrically: slightly negative reviews are punished more strongly...than slightly positive reviews"
 - "it is not simply that closeness to the average is rewarded; among reviews that are slightly away from the mean, there is a bias toward overly positive ones" 3
 
 - find generally that "conformity hypothesis" is true, except when variance in star ratings is high

 - find that, cross-culturally, these findings hold true

 - they "control for text" by looking at helpfulness ratings of identical reviews 3, find that their observed effect holds true regardless

**** DONE "Variation in the contextuality of language: An empirical measure." cite:heylighen_variation_2002   
CLOSED: [2017-08-26 Sat 12:29]
From abstract: "An empirical measure of this variation is proposed, the 'formality' or 'F-score', based on the frequencies of different word classes. Nouns, adjectives, articles and prepositions are more frequent in low-context or 'formal' types of expression; pronouns, adverbs, verbs and interjections are more frequent in high-context styles."

Uses anthropologist Edward T. Hall's definition of "high-context" and "low-context" situations. 
 - high-context: communication is implicit
 - low-context: communication is more explicit and overt
 - "the association of context with specific cultures seems to imply that the degree of context, dependence is merely the result of historical accidents or of idiosyncratic differences between ethnicities"

Define a "formality/contextuality continuum" in which "the opposite of contextuality may be called 'formality'" 298
 - yet differentiate between "deep formality," which aims to be explicit and avoid ambiguity, and "surface formality," which is "ceremonial or required by convention." 

! Argue that "completely unambiguous description is impossible" (300), citing Gödel's incompleteness theorem and Heisenberg's uncertainty principle

And textual genres: "we expect contextuality to be lowest in the more static, intellectual or informational forms of expression ... this includes official, legal, technical or scientific documents ... We expect contextuality to be highest in the more interactive and personal communication situations ... this includes relaxed conversations, dialogues, ... and personal letters." 302

Divides lexicon into more and less context-dependent classes: 
 - deictic words ("we," "him," "my," "here," "upstairs," "however") 306
   - pronouns, adverbs, and interjections
 - non-deictic words: most nouns and adjectives
   - nouns, adjectives, and prepositions

F = (noun frequency + adjective freq. + preposition freq. + article freq. - pronoun freq. - verb freq. - adverb freq. - interjection freq. + 100)/2

Using a corpus with varying degrees of formality: 
 - F-scores: 44 (conversation), 54 (oral examination), 56 (essay)

Find that: 311
 - those with academic degrees score higher (44 vs. 40)
 - men higher than women (42 vs. 39)

Italian genres: 
 - movies, theater: 48, 52
 - novels: 58-64
 - newspapers and magazines: 66-71
 - essays, science 69, 72

French: 
 - "interview with a call-girl": 45
 - "interview with the president": 52
 - "an address to the nation by the president": 58
 - "an article in an intellectual newspaper": 78

Use factor analysis to find significant factors to explain variation

On integrating contextual information: "Following Levelt's (1989) classification of linguistic deixis, we can distinguish four categories of context factors: the /persons/ involved, the /space/ or setting of the communication, the /time/, and the /discourse/ preceding the present expression." 324 
 - "the larger the difference in psychological or cultural background [between people communicating] the higher the formality of their communication" 324
 - "the more different the /spatial setting/ for sender and receiver, the smaller the shared context"
 - "the longer the /time span/ between sending and receiving, the less will remain of the original context" [and thus higher formality]

"the degree of extroversion was found to have a significant negative correlation with the explicitness factor measuring formality." 331-2

**** DONE "Comment classification for an online news domain." cite:brand_comment_2014 
CLOSED: [2017-08-26 Sat 13:08]
"Through investigation of supervised learning techniques, we show that content-based features better serves as a predictor of popularity, while quality-based features are better suited for predicting user engagement." 50

Test "quality-based features" and "content-based features"

Quality-based features: 
 - response time of user's comment
 - length of comment
 - uppercase frequency
 - question mark / exclamation mark frequency

Lexical features: 
 - entropy of words in the comment: [is this just TR?] 
 - spelling 
 - profanity 
 - "informativeness": "how unique a comment is within its thread" (TF-IDF)
 - "relevance": set intersection of words between comment and article
 
Social features: 
 - sentiment analysis
 - "subjectivity" (neutrality of sentiment analysis, defined as between 45-50% sentiment)
 - "engagement": number of child comments

Use linear regression and support vector regression; 

Find that content-based features outperform quality-based features in predicting comment votes, but quality + content features outperforms both. 
 - But: "This could be attributed to biased voting patterns in the community, eg. users that would “like” a comment multiple times if it supports their viewpoint (politically, religiously, or otherwise), but not necessarily evaluate the comment’s quality." 55
 - "The quality-based features are, however, better suited for predicting the engagement a comment will receive from users in a comment thread" 55

*** Of potentially abusive behavior
**** DONE "Finding Deceptive Opinion Spam by Any Stretch of the Imagination" cite:ott_finding_2011 :hasCorpus:
CLOSED: [2017-08-27 Sun 19:26]
"ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset." 

- opinion spam :: defined as "inappropriate or fraudulent reviews," usu. for monetary gain 1
- deceptive opinion spam :: "fictitious opinions that have been deliberately written to sound authentic, in order to deceive the reader." 1

present public dataset of "gold-standard" deceptive reviews

Find that "a combined classifier with both n-gram and psychological deception features achieves nearly 90% cross-validated accuracy on this task. In contrast, we find deceptive opinion spam detection to be well beyond the capabilities of most human judges, who perform roughly at-chance" 

Dataset creation: 
 - ! generate set of deceptive spam by hiring spammers on Mechanical Turk
 - generate "truthful opinions" by removing five-star reviews, reviews by first-time authors

Find that: 
 - "automated classifiers outperform human judges for every metric"
 - "deceptive opinions contain more superlatives"

"The combined model LIWC+BIGRMAS+SVM is 89.8% accurate at detecting deceptive opinion spam" 8

Qualities of truthful/deceptive language: 
 - "truthful opinions tend to include more sensorial and concrete language than deceptive opinions; in particular, truthful opinions are more specific about spatial configurations" 9 
 - "we observe an increased focus in deceptive opinions on aspects external to the hotel being reviewed (e.g. husband, business, vacation)" 9

"We find that while standard n-gram-based text categorization is the best individual detection approach, a /combination/ approach using psycholinguistically-motivated features and n-gram features can perform slighly better." 9

**** DONE "Automatic identification of personal insults on social news sites" cite:sood_automatic_2012 
CLOSED: [2017-08-27 Sun 21:22]
"Our training corpus is a set of comments from a news commenting site that we tasked Amazon Mechanical Turk workers with labeling. Each comment is labeled for the presence of profanity, insults, and the object of the insults." 

"we believe it is worthwhile to distinguish /off-topic negative comments/ form /on-topic negative comments/ that, while negative, are offered the spirit of debate." 1

"sentiment analysis is, in addition to being author, context and community-specific, a domain-specific problem" 
 - "for example, a 'cold' beverage is good while a 'cold' politician is bad" 3
 - "in order to build an accurate sentiment analysis system, you must have labeled training data from within the target domain." 3

 
Corpus: 1.6M comments from 234K users in 168K threads from /Yahoo! Buzz/, 2010
 - filter this for comments of length between 72 and 324 chars.

Label the data with help from Amazon Turk workers
 - throw out comments in which there was no consensus

use linear kernel support vector machines for classification, end up usin gmultistep classifier SVM 

find that genre (politics, entertainment, etc.) strongly affects categorizer accuracy, with news and politics having the lowest, and business and entertainment having the highest. 

find that "bigrams and stems using a presence representation performed best," at around 85% accuracy
 - "presence" here is binary presence of words, rather than their frequency
 - using this representation, they redo the analysis, but find that it doesn't improve categorization in all domains

Relevance + sentiment analysis: "Our approach combines relevance analysis for detecting off-topic comments with valence analysis methods for detecting negative comments." 
 - relevance: relevance is the sum of TF-IDF differences between words

**** DONE "Using Convolutional Neural Networks to Classify Hate-Speech" cite:gamback_using_2017 
CLOSED: [2017-08-28 Mon 11:30]
"The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams. The feature set was down-sized in the networks by max- pooling, and a softmax function used to classify tweets. Tested by 10-fold cross-validation, the model based on word2vec embeddings performed best, with higher precision than recall, and a 78.3% F-score." 

Corpus: use the English Twtiter hate-speech dataset created by cite:waseem_hateful_2016 

"following Waseem and Hovy (2016) only length 4 character n-grams were used. Clearly it would be interesting to explore whether these are uniformly ineffective when changing the n-gram size" 

**** DONE "Detecting Nastiness in Social Media"  cite:samghabadi_detecting_2017 :hasCorpus:
CLOSED: [2017-08-28 Mon 14:03]
Corpus scraped from ask.fm 
 - 586K question-answer pairs
 - Ask.fm's anonymity "allows attackers the power to freely harass users by flooding their pages with profanity-laden questions and comments" 63
   - "Several teen suicides have been attributed to cyberbullying in ask.fm" 
 - "We crawl data containing profanities and then determine whether or not it contains invective. Annotations on this data are improved iteratively by in-lab annotations and crowdsourcing." 63
   - Crowdsourced annotation of corpus using CrowdFlower 65

Bad words list: 
- ! "Bad words list" compiled from Google's bad words list and words listed in cite:hosseinmardi_towards_2014
- "most of these bad words are often used in a casual way, so detecting cases in which there are potential invective requires careful feature engineering" 65 

"We also show the robustness of our model by evaluating it on different data sets (Wikipeida Abusive Language Data Set, and Kaggle)." 
 - ? Yet is this robustness a good thing? Shouldn't domain-specific models work better? 

And spam: "Researchers have reported that cyberbullying posts are contextual, personalized, and creative, which make them harder to detect than detecting spam." 64

Final F-score of 59%

Data available at http://ritual.uh.edu/resources

Also test their system on Kaggle data 

Use supervised classification algorithm linear SVM 

Features: 
 - TF-IDF-weighted n-grams, char n-grams
 - ! also k-skip n-grams ("to capture long-distance context")
 - Normalized count of emoticons
 - SentiWordNet scores on sentences
 - LIWC (Linguistic Inquiry and Word Count) categories
   - ? Has anyone used WordNet hypernyms?
 - LDA topics
 - Two types of Word embeddings: document vectors, and averaged word vectors
 - ! patterns: "combination of lexical forms and POS tags" 
 
Results: 
 - Best F-score AUC (area under curve) is 0.889 for Wikipedia data set; 
 - performs with a F-score of 0.75 using all features

Poor performance with ask.fm, since they use shorter texts

**** TODO "Automated hate speech detection and the problem of offensive language." cite:davidson_automated_2017   
**** TODO "Hateful Symbols or Hateful People: Predictive features for hate speech detection on twitter" cite:waseem_hateful_2016 :hasCorpus:
**** TODO "Abusive language detection in online user content" cite:nobata_abusive_2016 
**** TODO "Detection of harassment on web 2.0" cite:yin_detection_2009   
**** TODO "Improved cyberbullying detection using gender information"  cite:dadvar_improved_2012 
**** TODO "Impact of content features for automatic online abuse detection." cite:papegnies_impact_2017 
**** TODO "Ex machina: Personal attacks seen at scale." cite:wulczyn_ex_2017 :hasCorpus:
**** TODO "Script-based story matching for cyberbullying prevention" cite:macbeth_script-based_2013  
**** TODO "Let's gang up on cyberbullying" cite:lieberman_lets_2011 
**** TODO "Smokey: Automatic recognition of hostile messages" cite:spertus_smokey:_1997   
**** TODO "Measuring the reliability of hate speech annotations: The case of the European refugee crisis." cite:ross_measuring_2017 
**** TODO "Detecting offensive tweets via topical feature discovery over a large scale twitter corpus" cite:xiang_detecting_2012  
**** TODO "Towards understanding cyberbullying behavior in a semi-anonymous social network" cite:hosseinmardi_towards_2014 
**** TODO "Learning from bullying traces in social media" cite:xu_learning_2012 
**** TODO "A framework for cyberbullying detection in social network" cite:kansara_framework_2015  
**** TODO "Fast Learning for Sentiment Analysis on Bullying" cite:xu_fast_2012 
**** TODO "An examination of regret in bullying tweets" cite:xu_examination_2013 
**** TODO "Detection and fine-grained classification of cyberbullying events"  cite:van_hee_detection_2015 
**** TODO "Detecting offensive language in social media to protect adolescent online safety." cite:chen_detecting_2012  
**** TODO "Cyberbullying detection: a step toward a safer internet yard" cite:dadvar_cyberbullying_2012 
**** TODO "An effective approach for cyberbullying detection"  cite:nahar_effective_2013 
**** TODO "Modeling the detection of Textual Cyberbullying" cite:dinakar_modeling_2011 
**** TODO "Cross-Language Learning from Bots and Users to Detect Vandalism on Wikipedia" cite:tran_cross-language_2015 
**** TODO "Mining for gold farmers: Automatic detection of deviant players in mmogs." cite:ahmad_mining_2009  
**** TODO "Don’t hate the player, hate the game: The racialization of labor in World of Warcraft." cite:nakamura_dont_2009 
**** TODO "Antisocial Behavior in Online Discussion Communities" cite:cheng_antisocial_2015 
**** TODO "Deep Learning for User Comment Moderation" cite:pavlopoulos_deep_2017 
**** TODO "Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words" cite:serra_class-based_2017 
**** TODO "One-step and Two-step Classification for Abusive Language Detection on Twitter" cite:park_one-step_2017 
**** TODO "Technology Solutions to Combat Online Harassment" cite:kennedy_iii_hack_2017 
**** TODO "Understanding Abuse: A Typology of Abusive Language Detection Subtasks"  cite:waseem_understanding_2017 
**** TODO "Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations" cite:palmer_illegal_2017 
**** TODO "Locate the hate: Detecting tweets against blacks." cite:kwok_locate_2013 
**** TODO "Hate speech detection with comment embeddings" cite:djuric_hate_2015 
**** TODO "Analyzing the targets of hate in online social media" cite:silva_analyzing_2016 

*** Linguistic properties of abusive language
**** TODO "Dimensions of Abusive Language on Twitter" cite:clarke_dimensions_2017  
**** TODO "Abusive language detection in online user content" cite:nobata_abusive_2016 
*** Sentiment analysis 
**** TODO "A survey of opinion mining and sentiment analysis"  cite:liu_survey_2012 
*** Of opinion spam
**** TODO "Opinion spam and analysis" cite:jindal_opinion_2008 
**** TODO "Review spam detection" cite:jindal_review_2007 
**** TODO "Detecting group review spam"  cite:mukherjee_detecting_2011 
**** TODO "Analyzing and detecting review spam" cite:jindal_analyzing_2007 
**** TODO "Finding unusual review patterns using unexpected rules"  cite:jindal_finding_2010 
**** TODO "Detecting product review spammers using rating behavior" cite:lim_detecting_2010 
**** TODO "Distortion as a validation criterion in the identification of suspicious reviews" cite:wu_distortion_2010 
**** TODO "Comparison of deceptive and truthful travel reviews" cite:yoo_comparison_2009 
** Psychology, Perception
*** TODO "The “Nasty Effect:” Online Incivility and Risk Perceptions of Emerging Technologies." cite:anderson_nasty_2014   
*** TODO "Newsworthiness and Network Gatekeeping on Twitter: The Role of Social Deviance" cite:diakopoulos_newsworthiness_2014  
*** And (Computational/Quantitative) Psycholinguistics
**** DONE Labs
CLOSED: [2017-09-13 Wed 13:11]
***** DONE UCSD: [[http://cpl.ucsd.edu/][Computational Psycholinguistics Lab]]
CLOSED: [2017-09-13 Wed 11:51]
- Website not updated since 2014
***** DONE MIT: [[http://cpl.ucsd.edu/][Computational Psycholinguistics Lab]]
CLOSED: [2017-09-13 Wed 11:51]

- Website not updated since 2014
**** Linguistic properties of speech/writing of those diagnosed with mental illness
***** DONE "The Emotional Lexicon of Individuals Diagnosed with Antisocial Personality Disorder" cite:gawda_emotional_2013 
CLOSED: [2017-09-14 Thu 12:05]
Abstract: "This study investigated the specific emotional lexicons in narratives created by persons diagnosed with antisocial personality disorder (ASPD) to test the hypothesis that individuals with ASPD exhibit deficiencies in emotional language. Study participants consisted of 60 prison inmates with ASPD, 40 prison inmates without ASPD, and 60 men without antisocial tendencies who described situations involving love, hate and anxiety depicted by photographs. The lexical choices made in the narratives were analyzed, and a comparison of the three groups revealed differences between the emotional narratives of inmates with ASPD, inmates without ASPD, and the control group. Although the narratives of the individuals with ASPD included more words describing emotions and higher levels of emotional intensity, the valence of these words was inappropriate. The linguistic characteristics of these narratives were associated with high levels of psychopathy and low emotional reactivity." 

 - Citing previous research, "individuals with psychopathic personalities create less structured narratives that lack temporal perspective ... and do not describe the emotional context or focus on negative aspects of the situation" 572

Subjects: 
 - "60 prison inmates with ASPD"
 - "40 prison inmates without ASPD"
 - "60 men wihtout antisocial tendencies"
 - very similar age, education, IQ, verbal comprehension, etc among these groups

Results: 
 - ASPD narratives show much higher: 
   + emotion words (all)
   + positive words (all) 
   + negative words (love)
   + high-intensity words (love)
   + nouns (hate)
   + adjectives (love)
   + verbs (love, anxiety)
 - ASPD narratives show much lower: 
   + negative words (hate)

? This seems to suggest that with ASPD-diagnosed patients, sentimental valence of words might need to be context-dependent. 
 - Sentiment on its own, therefore, would prove not to be a great indicator of abusive language, but whether that sentiment was out-of-place for the context.
  
****** TODO survey works cited in this bibliography

***** TODO "Syntax of Emotional Narratives of Persons Diagnosed with Antisocial Personality" cite:gawda_syntax_2010 
***** DONE "The Language of the Psychopath" cite:rieber_language_1994 
CLOSED: [2017-09-14 Thu 12:25]
Deep review of the literature of the language of psychopathy, although not strictly employing a quantitative approach to the language.

"The true psychopath compels the psychiatric observer to ask the perplexing and largely unanswered question 'Why doesn't that person have the common decency to go crazy?'" 2

? Language that "goes crazy," therefore, cannot be considered a mark of psychopathy. 

"[Psychopaths] do not allow themselves to be moved by words and concepts that their fellow citizens value." 12

Notes Eichler's 1965 study's results: "sociopaths were higher than normals on /negation, retraction, evaluation/. As compared with impulsives, sociopaths were higher than normal on /nonpersonal references/." 15

***** TODO "A graph theory model of the semantic structure of attitudes" cite:bovasso_graph_1993 
abstract: "The semantic structure underlying the attitudes of pretreatment and posttreatment drug addicts was modeled using a network analysis of free word associations." 
**** Linguistic properties of emotional expression
***** TODO "Measuring Emotional Expression with the Linguistic Inquiry and Word Count" cite:kahn_measuring_2007 
***** TODO "Linguistic Markers and Emotional Intensity" cite:argaman_linguistic_2010 
- Study speakers of Hebrew language.
**** Swearing
***** DONE "Swears in Context: The Difference Between Casual and Abusive Swearing" cite:kapoor_swears_2016 
CLOSED: [2017-09-14 Thu 12:44]

Notes Rieber et al. 1979: "obscenities used denotatively can be considered far more harh and offensive than those used connotatively." 

Cites patent [[https://www.google.com/patents/US20110191105][Patent US20110191105]] (see above) where: "Reactions to offensive words were explained in terms of an 'offensiveness threshold' based on the individual’s sensitivity to profane language. Thus, if a word’s offensiveness score was higher than the individual’s offensiveness threshold, the word would be considered inappropriate and offensive; but if the individual’s tolerance for swearwords were high, and the word’s offensiveness score did not exceed the threshold, it was not likely to be perceived as offensive." 260

Distinguish between "mild," "moderate," and "severe" types of swears, cross-linguistically and across natioalities.

Test "appropriateness" 

Hypotheses: 
 - "H1: Mild swears are more appropriate than moderate swears, which in turn, are more appropriate than severe swears." 
 - "H2: Swearing in casual contexts is more appropriate than swearing in abusive settings."
 - "H3: Mild swears in casual contexts are the least inappropriate, and severe swears in abusive contexts are the most inappropriate." 

Results: 
 - "Mild swears were likely to be used in casual, cathartic, and hostile scenarios; moderate swears were more likely to be used in conversational and abusive contexts." 
 - results "partially support H4": "severe swears are likely to be employed in abusive and hostile contexts (H4)." 266

***** TODO "Does Emotional Arousal Influence Swearing Fluency?" cite:stephens_does_2017   
** Gamergate
*** DONE [[http://www.newyorker.com/tech/elements/zoe-quinns-depression-quest][Zoe Quinn’s Depression Quest | The New Yorker]]
CLOSED: [2017-08-21 Mon 13:22]
*** TODO [[https://www.nytimes.com/2014/10/16/technology/gamergate-women-video-game-threats-anita-sarkeesian.html][Feminist Critics of Video Games Facing Threats in ‘GamerGate’ Campaign - The New York Times]]
**** TODO "What Lies Beneath: The Linguistic Traces of Deception in Online Dating" cite:toma_what_2012 
*** Anita Sarkeesian, Zoe Quinn
**** TODO Video: [[https://www.youtube.com/watch?v=HLteBt0_LiI][Speech for the UN]] 
* Questions
** Has anyone done a comment/article similarity (relevance) study like cite:diakopoulos_editors_2015 but using word/document vectors instead of tf-idf? 
- cite:kolhatkar_constructive_2017 vectorizes words, but not to compute similarity with articles
- cite:gamback_using_2017 uses word embeddings, finds that categorizer works best with these
** Has anyone studied platform/OS source as predictor of potentially abusive language? 
- [[http://keyhole.co/][Keyhole]] shows high incidence of bot platforms for #gamergate. These account for almost 20%: 
  - [[http://twittbot.net/][twittbot]]
  - [[http://cheapbotsdonequick.com/][Cheap Bots, Done Quick!]]
  - ITTT (If this, then that) 
** What can psycholinguistics studies offer to fingerprinting of abusive language?  
** Has anyone written a Twitter bot to identify abusive speech, and then ask the alleged abuser/abusee whether he/she thought it was abusive? 
 - This approach might be able to learn from correct/incorrect identifications.
** What Twitter accounts or hashtags might be cataloging abusive tweets? Can these be mined to create new datasets? 
** If we can identify male voices or deceptive, can we use that as a proxy to identifying trolls? 
* Books and Other Sources
** TODO - Cybercrime and its victims
 :PROPERTIES:
  :Custom_ID: martellozzo_cybercrime_2017
  :AUTHOR: Martellozzo \& Jane
  :JOURNAL: 
  :YEAR: 
 :END:
cite:martellozzo_cybercrime_2017
** TODO - Misogyny Online: A Short (and Brutish) History
 :PROPERTIES:
  :Custom_ID: jane_misogyny_2016
  :AUTHOR: Jane
  :JOURNAL: 
  :YEAR: 
 :END:
cite:jane_misogyny_2016
** TODO - "Gendertrolling: How Misogyny Went Viral" cite:mantilla_gendertrolling:_2015 
** DONE - Weeding Out Online Bullying Is Tough, So Let Machines Do It
CLOSED: [2017-08-18 Fri 14:54]
 :PROPERTIES:
  :Custom_ID: alba_weeding_2015
  :AUTHOR: Alba
  :JOURNAL: WIRED
 :END:
cite:alba_weeding_2015
[[https://www.wired.com/2015/07/weeding-online-bullying-tough-let-machines/][Weeding Out Online Bullying Is Tough, So Let Machines Do It | WIRED]]

SRI International uses data from a major unspecified social media company to train an algorithm against reported data. 

"Smart abusers": "Jamia Wilson, executive director of Women Action Media, a group Twitter appointed last fall to look at reports of harassment on the social network, says her main concern is that abusers are well-aware of the initiatives to curb harassment on networks—and employ sophisticated techniques to avoid detection." 
 
** TODO - Pew Research Report 2014: Online Harassment
 :PROPERTIES:
  :Custom_ID: duggan_online_2014
  :AUTHOR: Duggan
  :JOURNAL: 
  :YEAR: 
 :END:
cite:duggan_online_2014

* Reports
** Report 1 <2017-08-22 Tue> 
The detection and prediction of abusive or other "low-quality" language is a much-discussed topic in the computer science field of natural language processing and in computational linguistics. The work I've examined so far largely treats the problem as one of document classification, a subset of machine learning. Documents, which could be articles, comments, tweets, or other text, are first preprocessed (converting them to words or sequences of words), vectorized (transformed into numeric representations of these words), and the resulting vectors, usually along with other contextual features, are used to train machine learning algorithms to recognize abusive or other kinds of language. Once the algorithm is trained against labeled data (comments that have been marked as abusive by other users, for instance), it can then be used to guess whether a test document should be categorized as abusive.  

Although the machine learning algorithm ultimately decides which of the features best categorize its data, whether to use word vector features or other contextual features, and how to weight those features, the researcher must first decide which features to feed it. In some cases, features include term frequencies, adjusted for their frequency in the document or corpus (TF-IDF) (cite:diakopoulos_editors_2015), or n-dimensional word embeddings (cite:agichtein_finding_2008), trained on data like [[https://nlp.stanford.edu/projects/glove/][Stanford's GloVe vectors]]. Nicholas Diakopoulos et al., for instance, introduce a measure of the "relevance" of a news website comment to its article by measuring the cosine similarities of TF-IDF vectors between them. Eugene Agichtein et al use a similar technique to measure relevance of questions and answers from a Q&A website, measuring instead the KL divergence of their language models. Agichtein's team also vectorizes their texts by transforming them into part-of-speech representations, discovering that certain grammatical constructions correlate with the "quality" of the question or answer. 

Sentiment analysis, a sub-field of natural language processing, can also provide useful features for categorization. Stefan Siersdorfer et al find that sentiment scores,  computed using the SentiWordNet, correlate with user ratings of comments on YouTube (cite:siersdorfer_how_2010). Carlos Castillo et al, as well, find sentiment scores to be among the best features that distinguish between "credible" and "non-credible" tweets (cite:castillo_predicting_2013). 

Some of the more interesting features used to train these categorizers, however, are metatextual, rather than textual features. Castillo et al, for instance, find that whether a Twitter user has completed his or her self-description ("bio") is a feature that is weighted highly in distinguishing between tweets automatically categorized as either "news" and "discussion" (cite:castillo_predicting_2013). Agichtein et al use social network theory, and in particular trust propagation theory, to predict "high-quality" questions and answers. If user A answers a question asked by a well-known expert answerer B, for instance, they assume a certain level of expertise on the part of user A.  

While these papers describe techniques for abusive language detection, and not necessarily software, such software does exist. TrollBusters, the fruit of a 2015 hackathon, claims to "identify communities of trolls around any given issue using natural language processing" and "counter cyberattacks in real-time with online community support and positive messaging." As far as I can tell, it is proprietary software. [[http://www.perspectiveapi.com/][Perspective]], a product produced by the startup Jigsaw, an Alphabet (Google) company, is a more mature-looking product, with a public API that could be used to label comments according to their potential "toxicity." Although much of [[https://github.com/conversationai][Perspective's code]] is on GitHub, it is unclear how much of their model is public, so there might still be room for development of a fully open-source tool. 

There are a few dozen other papers in this area I have yet to explore, and a few related fields, besides. The fields of automated essay grading and readability indexing may hold techniques that are useful to the automated detection of abusive text. Non-computational fields, as well, such as psychology and media studies, may provide useful ideas for ML feature design. I hope to explore the Gamergate controversy in more detail, especially since [[https://prpole.github.io/semantic-analysis-of-one-million-gamergate-tweets/][a colleague of mine has recently done a computational analysis of its tweets]]. (A quick analysis of gamergate tweets on Keyhole reveals that around 10% of the tweets came from Twitter bot platforms--are there automated abuse robots, and how might these be identified?) 
** Report 2, <2017-08-28 Mon>

Most of the work I've examined this week belongs to the fields of computational linguistics and natural language processing, and treats the problem of the identification of abusive language as a document categorizing problem. The training data used for these studies is often generated by employing casual workers on Amazon Mechanical Turk or CrowdFlower to manually annotate data. Features used by these studies include average sentiment analysis scores, emoticons used, sylistic patterns such as sentence length, word embeddings, and LDA (topic modeling) topics. In one case (cite:samghabadi_detecting_2017) a "bad words dictionary" was created from combining a Google-created list with a list from another researcher. Categorizers used include Long Short-Term Memory (LSTM) recurrent neural networks, (cite:kolhatkar_constructive_2017), Convolutional Neural Networks (cite:gamback_using_2017), and Support Vector Machines (SVM) (cite:samghabadi_detecting_2017). *The method that performs best in categorizing abusive language seems to vary greatly according to data set and domain.* Sood et al. (cite:sood_automatic_2012), for instance, find that word bigrams (sequences of two words) are the best-performing features, while Samghabadi et al. (cite:samghabadi_detecting_2017) find character 4-grams (sequences of four characters) to perform better. Data sets also show a wide variety: some consist of news comments, while others are of tweets. Typically, the longer the document, the better the categorizer will perform, and different algorithms are needed for each.

Although a number of these studies don't seem to publish their data and code, many of them do, making room for easy repetition of their experiments, or design of new experiments that make use of some of their code and/or data. In particular, the 2012 Kaggle task "Detecting Insults in Social Commentary" has [[https://www.kaggle.com/c/detecting-insults-in-social-commentary/discussion/2744][a thread where participants are posting their code]]. Also, I've started tagging those studies that publish their training corpora using the tag "hasCorpus."  

As previously noted, very little user-space software seems to exist for detection of harassment, and its quality seems to be very much in its infancy. I tested Jigsaw's /Perspective,/ which I mentioned in my previous report, against a number of intentionally ambiguous and threatening sentences. I then compared these scores with those generated from the Wiki DeTox agression model, also a Jigsaw project:  
  
 - "Be careful, you might find some white powder in an envelope come in the mail one day." 
   - WDT: 1% aggressive
   - Perspective: 14% toxic
 - "If you keep this up, you find yourself sleeping with the fishes." 
   - WDT: 12% aggressive.
   - Perspective: 38% toxic
 - "I'm going to come to your house." 
   - WDT: 48% aggressive.
   - Perspective: 15% toxic
 - "I'm going to nominate you for the Nobel prize, you brilliant man." 
   - WDT: 61% aggressive.
   - Perspective: 17% toxic. 

These scores highlight both the high variability between algorithms, and their difficulty with ambiguous language. 

More abstract and theoretical work in this area also seems worthy of more examination. Heylighen et al's formality score, a formula using part-of-speech representations of words, uses anthropological and psycholinguistic theories of contextuality (linguistic deixis). Although this measure is used directly in categorization experiments (cite:agichtein_finding_2008), its methodology might also be adapted to build other POS pattern-based approaches for the detection of abusive language. The methods of the sub-field of deceptive opinion spam (false product reviews, for instance), which in some cases succeed in detecting opinion spam at 90%, a success rate much higher than those of human judges, might also be adapted to the detection of abusive language.  
** Report 3, <2017-09-14 Thu> 
This week, I began by exploring some of the winning entries from the 2012 Kaggle data science contest, [[https://www.kaggle.com/c/detecting-insults-in-social-commentary][Detecting Insults in Social Commentary]]. The top six entries used the Python programming language and its machine learning libraries, like Scikit-Learn; other entries used the statistical language R or other programming languages. Since the top entries all seemed to use similar categorizers and meta-categorizers (grid-search cross-validation techniques), they largely differ in preprocessing. One coder credits "good tokenization" as one of the major keys to his success. Domain-specific knowledge, and in particular linguistic observation of the training data, then, provided the most tangible advantages. Knowledge of the obfuscation techniques used by speakers of insults, for instance, contributed to these useful tokenization techniques. 

Following my previous report on formality scores and their use in these categorization tasks, I began to investigate the field of computational psycholinguistics. A few articles in this field exist that take quantitative approaches to the study of language produced by people who have been diagnosed with mental illness. cite:gawda_emotional_2013, for instance, studies narratives written by prison inmates diagnosed with Antisocial Personality Disorder (ASPD), as compared with a control group, and those diagnosed as not having the disorder. They find that emotional words are higher in general among those with ASPD, but negative words, for instance, might have lower than normal scores for narratives that describe hate. When seen in the context of our project of the computational identification of abusive language, this finding suggests that negative words on their own may not be markers of abuse, at least that originating from those with ASPD. Similarly, cite:rieber_language_1994, a literature review of "the language of psychopathy" finds that often one of the distinguishing linguistic features of these patients is the /lack/ of emotional markers in certain contexts. Here again, this indicates that strong emotional valence, as measured by sentiment analysis, might not on its own be a useful feature for a categorizer, and that contextually contrasting emotional content might perform better.

These contextual complications are analogous with those studied in a few papers on swearing. cite:kapoor_swears_2016, for instance, attempts to differentiate between "casual" and "abusive" swearing. They categorize swear words as "mild," "moderate," and "severe," and find that "moderate" and "severe" swear words are more likely to occur in abusive contexts. They cite [[https://www.google.com/patents/US20110191105][a 2011 patent]] that scores offensiveness as swearing that contrasts with a user's swearing "threshold." This is another instance of abuse detection that relies on contextually contrasting language. 

Since many projects in abusive language detection position themselves socio-contextually, and describe their studies as attempt to identify "trolls," or those who habitually abuse or harass others, an important subcategory of this area of research is the identification of professional trolls. These are trolls that are either /agents provocateurs/ employed by government agencies, or employed by private "reputation management" consultants. One study in this area, studying comments on a Bulgarian news website, found that the day of the week and the hour of the day were useful features to distinguish between paid and unpaid trolls. Computationally identifying paid trolls, and other systematic or automated forms of harassment, might leverage metadata like this, potentially making it one of the easiest subtasks for abuse detection. 

New directions for research include six US patents related to the detection of abusive language, or for "offensiveness" more generally; a statistical exploration of the [[http://hatebase.org][hatebase.org]] dataset of hate speech (thanks for the tip, Colin); more work related to troll detection, especially in graph theory and signed social network theory; and more fine-grained analysis of the code from the 2012 Kaggle competition and other publicly-available algorithms. 

* References
<<bibliography link>> bibliographystyle:unsrt bibliography:SOPS.bib
* Meeting notes
** Notes from meeting <2017-08-22 Tue> 
How does anti-bullying work in real life? 
How does online bullying differ from real-world bullying? 
 - Does bullying happen IRL when no one else is around, when they're not being watched?
 - Clear definitions of harassment and bullying are important here.
The training corpus and its limitations is important. 
Statistical literature on evaluating bullying? 
 - How could we quantify the adverse effects of bullying? 
How would intervention work? 
"Publications on the Study of Bullying" 
 - http://research.cs.wisc.edu/bullying/
 - Using social media data to distinguish bullying from teasing.
What opportunities for colloration are there? 
Aggression, personal attacks as irrelevance. 
What power differentials are there between high-profile (lots of followers) figures and low-profile figures? 
What applications of RST might there be?  
** Notes from meeting <2017-08-28 Mon> 
:LOGBOOK:
CLOCK: [2017-08-28 Mon 16:00]--[2017-08-28 Mon 17:00] =>  1:00
:END:
Google account suspension of School of Prof. Studies stats professor, tweeting about Clinton and the 2016 election
 - ML algorithm probably made a mistake in categorizing this as abusive
 - [[https://www.inc.com/sonya-mann/salil-mehta-free-speech.html][A Handful of Tech Companies Decide Who Has Free Speech Online. That's Not Good. | Inc.com]]
*** Colin's week 1 summary: [[https://docs.google.com/document/d/1Hmk5KZxQ0ci_QZHlWFLDwX_Sr47fGgeSKS1qFFw17ok/edit?ts=59a45e96#heading=h.9eg2yefb1sbk][Summaries Week 1 - Google Docs]]

** Notes from meeting <2017-09-07 Thu> 
:LOGBOOK:
CLOCK: [2017-09-07 16:30]--[2017-09-07 Wed 17:30] =>  1:00
:END:
Colin: lack of theorizing re: cyberbullying
techniques of counterspeech
communities of abuse / trust propogation
social network studies have been done, and formality studies, but not yet formality+social network
! do more reading in psycholinguistics.
 - deixis
** Notes from meeting <2017-09-14 Thu>
*** NYU twitter bots: [[https://cds.nyu.edu/using-data-science-moderate-online-harrassment/][Using Data Science to Moderate Online Harrassment - NYU Center for Data Science]]
