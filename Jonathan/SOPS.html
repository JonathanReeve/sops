<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2017-10-10 Tue 10:28 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>A Safer Online Public Square: Research Notes</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Jonathan Reeve" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: visible;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
/*
@licstart  The following is the entire license notice for the
JavaScript code in this tag.

Copyright (C) 2012-2017 Free Software Foundation, Inc.

The JavaScript code in this tag is free software: you can
redistribute it and/or modify it under the terms of the GNU
General Public License (GNU GPL) as published by the Free Software
Foundation, either version 3 of the License, or (at your option)
any later version.  The code is distributed WITHOUT ANY WARRANTY;
without even the implied warranty of MERCHANTABILITY or FITNESS
FOR A PARTICULAR PURPOSE.  See the GNU GPL for more details.

As additional permission under GNU GPL version 3 section 7, you
may distribute non-source (e.g., minimized or compacted) forms of
that code without the copy of the GNU GPL normally required by
section 4, provided you include this license notice and a URL
through which recipients can access the Corresponding Source.


@licend  The above is the entire license notice
for the JavaScript code in this tag.
*/
<!--/*--><![CDATA[/*><!--*/
 function CodeHighlightOn(elem, id)
 {
   var target = document.getElementById(id);
   if(null != target) {
     elem.cacheClassElem = elem.className;
     elem.cacheClassTarget = target.className;
     target.className = "code-highlighted";
     elem.className   = "code-highlighted";
   }
 }
 function CodeHighlightOff(elem, id)
 {
   var target = document.getElementById(id);
   if(elem.cacheClassElem)
     elem.className = elem.cacheClassElem;
   if(elem.cacheClassTarget)
     target.className = elem.cacheClassTarget;
 }
/*]]>*///-->
</script>
</head>
<body>
<div id="content">
<h1 class="title">A Safer Online Public Square: Research Notes</h1>
<div id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#orgbb9b6e5">1. Todo</a>
<ul>
<li><a href="#org388f4e0">1.1. <span class="todo TODO">TODO</span> read ACL workshop papers</a></li>
<li><a href="#orgcac4a5d">1.2. <span class="todo TODO">TODO</span> prepare a list of NLP journals to search</a></li>
<li><a href="#orgf0baf9d">1.3. <span class="todo TODO">TODO</span> search NLP journals for keywords</a></li>
<li><a href="#org081f259">1.4. <span class="todo TODO">TODO</span> reach out to Phil for Gamergate tweets</a></li>
<li><a href="#orgb8270fe">1.5. <span class="todo TODO">TODO</span> search ACM</a></li>
<li><a href="#org3fdadc5">1.6. <span class="todo TODO">TODO</span> search Arxiv</a></li>
<li><a href="#org5321cce">1.7. <span class="todo TODO">TODO</span> read papers about readability</a></li>
<li><a href="#org6b31ec2">1.8. <span class="todo TODO">TODO</span> read papers about automated essay grading</a></li>
<li><a href="#org3eaee20">1.9. <span class="todo TODO">TODO</span> read papers about spam filtering</a></li>
<li><a href="#org6a1ee68">1.10. <span class="todo TODO">TODO</span> explore Kaggle task: Detecting Insults in Social Commentary | Kaggle</a></li>
<li><a href="#orgb1a9669">1.11. <span class="todo TODO">TODO</span> identify good researchers to invite to Columbia</a></li>
<li><a href="#orga320121">1.12. Administrative</a>
<ul>
<li><a href="#org0c53b2a">1.12.1. <span class="done DONE">DONE</span> send Susan a copy of my UW syllabus</a></li>
<li><a href="#org64fafbb">1.12.2. <span class="done DONE">DONE</span> send Susan a copy of my calendar</a></li>
<li><a href="#org1f12a52">1.12.3. <span class="done DONE">DONE</span> fill out timesheet and submit to French department</a></li>
<li><a href="#orgd020fbe">1.12.4. <span class="done DONE">DONE</span> ask French dept about sending PAF back to the English Dept</a></li>
<li><a href="#orgcd7b757">1.12.5. <span class="todo TODO">TODO</span> fill out timesheet and submit to French department</a></li>
</ul>
</li>
<li><a href="#org16407c6">1.13. <span class="todo TODO">TODO</span> organize GitHub repository into folders</a></li>
<li><a href="#orgf0ce49e">1.14. <span class="todo TODO">TODO</span> explore hatebase.org dataset</a></li>
<li><a href="#orge68d0ef">1.15. <span class="todo TODO">TODO</span> explore psycholinguistics journals</a>
<ul>
<li><a href="#org570cf8e">1.15.1. <span class="done DONE">DONE</span> Journal of Psycholinguistic Research</a></li>
</ul>
</li>
<li><a href="#org03ab526">1.16. <span class="done DONE">DONE</span> make outline of master report</a></li>
<li><a href="#orgd9f54c4">1.17. <span class="todo TODO">TODO</span> set up Doodle poll for next meeting</a></li>
<li><a href="#org96064a9">1.18. <span class="todo TODO">TODO</span> make master report</a></li>
</ul>
</li>
<li><a href="#org23f9d7c">2. Links</a>
<ul>
<li><a href="#orgf18d3f5">2.1. News, Blogs, Mass Media</a>
<ul>
<li><a href="#orgafe4a01">2.1.1. <span class="done DONE">DONE</span> <b>New York Times</b> WhatsApp, Crowd, Power in India</a></li>
<li><a href="#orgbe206f9">2.1.2. <span class="done DONE">DONE</span> New York Times: NYT: Save Free Speech from Trolls</a></li>
<li><a href="#org84dcb9f">2.1.3. <span class="done DONE">DONE</span> Data &amp; Society: Online Harassment and Digital Abuse</a></li>
<li><a href="#org9a8967d">2.1.4. <span class="done DONE">DONE</span> Proceedings of the first ACL Workshop on Abusive Language Online</a></li>
<li><a href="#org8bd7428">2.1.5. <span class="todo TODO">TODO</span> Online Harassment Resource Guide - Mattias, J. Nathan (et. al)</a></li>
<li><a href="#org331bd89">2.1.6. TED talks</a></li>
</ul>
</li>
<li><a href="#org1eeacd7">2.2. Software</a>
<ul>
<li><a href="#orgcff2f38">2.2.1. <span class="done DONE">DONE</span> TrollBusters | Devpost</a></li>
<li><a href="#orgb555c45">2.2.2. <span class="done DONE">DONE</span> Perspective (Jigsaw, Google)</a></li>
<li><a href="#org5364330">2.2.3. <span class="done DONE">DONE</span> The Coral Project</a></li>
<li><a href="#org224e72d">2.2.4. <span class="done DONE">DONE</span> Wikipedia DeTox (also Jigsaw)</a></li>
<li><a href="#org779c03a">2.2.5. Development contests</a></li>
</ul>
</li>
<li><a href="#org65bcbff">2.3. Organizations</a>
<ul>
<li><a href="#orge9d9cc3">2.3.1. Colin's doc: Organizations doing something - Google Docs</a></li>
<li><a href="#org71415cb">2.3.2. <span class="done DONE">DONE</span> WMC Speech Project</a></li>
<li><a href="#org5dfe155">2.3.3. <span class="done DONE">DONE</span> Trolldor: the global blacklist of twitter trolls</a></li>
<li><a href="#orgb74bc5b">2.3.4. <span class="done DONE">DONE</span> No Hate Speech Movement</a></li>
<li><a href="#org49f32e8">2.3.5. <span class="todo TODO">TODO</span> Southern Poverty Law Center</a></li>
<li><a href="#orgcb02924">2.3.6. <span class="todo TODO">TODO</span> Cyberbullying Research Center</a></li>
<li><a href="#org51ebce0">2.3.7. <span class="todo TODO">TODO</span> Committee to Protect Journalists</a></li>
<li><a href="#org80e5403">2.3.8. <span class="todo TODO">TODO</span> Anti-Defamation League Task Force on Harassment and Journalism</a></li>
<li><a href="#orgddd836b">2.3.9. <span class="todo TODO">TODO</span> Working to Halt Online Abuse</a></li>
<li><a href="#org0de3236">2.3.10. <span class="todo TODO">TODO</span> UN Broadband Commission for Sustainable Development Working Group on Broadband and Gender</a></li>
<li><a href="#org66c60f9">2.3.11. <span class="todo TODO">TODO</span> SRI International</a></li>
<li><a href="#org5149def">2.3.12. <span class="todo TODO">TODO</span> Women Action Media (WAM!)</a></li>
<li><a href="#org36334f4">2.3.13. <span class="todo TODO">TODO</span> Hack Harassment</a></li>
<li><a href="#org8d75203">2.3.14. Algorithmic</a></li>
</ul>
</li>
<li><a href="#orgc2543b6">2.4. Statistics about Harassment</a>
<ul>
<li><a href="#orgbf6dfcf">2.4.1. Proportion of Internet users that experience harassment</a></li>
<li><a href="#orge7ed424">2.4.2. Infographic: The Rise of Online Harassment</a></li>
<li><a href="#org91c7f33">2.4.3. <span class="done DONE">DONE</span> Online Harassment | Pew Research Center</a></li>
<li><a href="#orge38a90d">2.4.4. <span class="done DONE">DONE</span> WHOA: Cyberstalking Statistics.</a></li>
<li><a href="#org31e5afc">2.4.5. Intimidation, Threats, and Abuse | International Women's Media Foundation (IWMF)</a></li>
<li><a href="#org479f630">2.4.6. <span class="todo TODO">TODO</span> [[][Data and Society Report: Online Harassment, Digital Abuse, and Cyberstalking in America]</a></li>
</ul>
</li>
<li><a href="#orgf95b23e">2.5. Social Media Services</a>
<ul>
<li><a href="#org6b6ae00">2.5.1. General Legal / Terms of Service Issues</a></li>
<li><a href="#org72b190b">2.5.2. Facebook</a></li>
<li><a href="#orgb1bccac">2.5.3. Twitter</a></li>
<li><a href="#org84862ce">2.5.4. Mastodon</a></li>
<li><a href="#orga32cb17">2.5.5. WhatsApp</a></li>
<li><a href="#orgf036bb9">2.5.6. Reddit</a></li>
<li><a href="#org57a6e3d">2.5.7. Wikipedia</a></li>
<li><a href="#orgc40655d">2.5.8. Metafilter</a></li>
</ul>
</li>
<li><a href="#org163b6b8">2.6. People</a></li>
<li><a href="#orga8b9703">2.7. Patents</a>
<ul>
<li><a href="#orgf6fc3df">2.7.1. <span class="todo TODO">TODO</span> Patent US5796948 - Offensive message interceptor for computers - Google Patents</a></li>
<li><a href="#orgcee3e04">2.7.2. <span class="todo TODO">TODO</span> Patent US8868408 - Systems and methods for word offensiveness processing using aggregated &#x2026; - Google Patents</a></li>
<li><a href="#org978add9">2.7.3. <span class="todo TODO">TODO</span> Patent US8473443 - Inappropriate content detection method for senders - Google Patents</a></li>
<li><a href="#orga8b327e">2.7.4. <span class="todo TODO">TODO</span> Patent US7818764 - System and method for monitoring blocked content - Google Patents</a></li>
<li><a href="#orgd86fc6a">2.7.5. <span class="todo TODO">TODO</span> Patent US20080109214 - System and method for computerized psychological content analysis of &#x2026; - Google Patents</a></li>
<li><a href="#org7937126">2.7.6. <span class="todo TODO">TODO</span> Patent US20110191105 - Systems and Methods for Word Offensiveness Detection and Processing Using &#x2026; - Google Patents</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#orgf779602">3. Problems, Topics</a>
<ul>
<li><a href="#orgbb1d203">3.1. Censorship policies of social media companies</a></li>
<li><a href="#org898e6c0">3.2. Flagging</a>
<ul>
<li><a href="#orgad43a3a">3.2.1. <span class="todo TODO">TODO</span> "What is a Flag for? Social Media Reporting Tools and the Vocabulary of Complaint" </a></li>
<li><a href="#orgf754c6b">3.2.2. <span class="todo TODO">TODO</span> Reporting, Reviewing, and Responding to Harassment on Twitter. </a></li>
<li><a href="#org7396263">3.2.3. <span class="todo TODO">TODO</span> A Brief Guide To User-Generated Censorship - Chris Peterson</a></li>
</ul>
</li>
<li><a href="#orgfd6aaab">3.3. Counterspeech, Moderation</a>
<ul>
<li><a href="#orgd018bcc">3.3.1. <span class="done DONE">DONE</span> "Vectors for Counterspeech on Twitter" </a></li>
<li><a href="#orgd89eacb">3.3.2. <span class="todo TODO">TODO</span> "The Virtues of Moderation" </a></li>
<li><a href="#org4ee35f2">3.3.3. <span class="todo TODO">TODO</span> "Slash (dot) and burn: distributed moderation in a large online conversation space" </a></li>
<li><a href="#orgd6823fd">3.3.4. <span class="todo TODO">TODO</span> Tweetment Effects on the Tweeted: Experimentally Reducing Racist Harassment | SpringerLink</a></li>
</ul>
</li>
<li><a href="#org836d750">3.4. Cross-cultural studies</a>
<ul>
<li><a href="#orgf39c68f">3.4.1. <span class="todo TODO">TODO</span> "Rephrasing Profanity in Chinese Text" </a></li>
<li><a href="#org9d8835b">3.4.2. <span class="todo TODO">TODO</span> "Legal Framework, Dataset and Annotation Schema for Socially Unacceptable Online Discourse Practices in Slovene" </a></li>
<li><a href="#org490e4f8">3.4.3. <span class="todo TODO">TODO</span> "Abusive Language Detection on Arabic Social Media" </a></li>
</ul>
</li>
<li><a href="#org4d20707">3.5. Troll detection / troll bots / misinformation bots</a>
<ul>
<li><a href="#org7ccca83">3.5.1. At least 10% of #gamergate tweets have bot OSes (see below)</a></li>
<li><a href="#org0407e72">3.5.2. <span class="done DONE">DONE</span> Tweet: A pattern you may have noticed: many bot and troll accounts have usernames that end in 8 random digits.</a></li>
<li><a href="#org7ce73d9">3.5.3. <span class="done DONE">DONE</span> Twitter Audit | How many of your followers are real?</a></li>
<li><a href="#org85524e7">3.5.4. <span class="todo TODO">TODO</span> "Exposing Paid Opinion Manipulation Trolls" </a></li>
<li><a href="#orga88e3ad">3.5.5. <span class="todo TODO">TODO</span> "Finding Opinion Manipulation Trolls in News Community Forums" </a></li>
<li><a href="#org33413f5">3.5.6. <span class="todo TODO">TODO</span> "Propagation of trust and distrust for the detection of trolls in a social network" </a></li>
<li><a href="#org098f14b">3.5.7. <span class="todo TODO">TODO</span> "Accurately detecting trolls in slashdot zoo via decluttering" </a></li>
<li><a href="#org53a0a88">3.5.8. <span class="todo TODO">TODO</span> "Assessing trust: contextual accountability" </a></li>
<li><a href="#orga54cf2c">3.5.9. <span class="todo TODO">TODO</span> "Filtering offensive language in online communities using grammatical relations" </a></li>
<li><a href="#org2cf1154">3.5.10. <span class="todo TODO">TODO</span> "Offensive language detection using multi-level classification" </a></li>
</ul>
</li>
<li><a href="#org15d2d2e">3.6. Automated Detection</a>
<ul>
<li><a href="#org5dea352">3.6.1. Of high-quality contributions</a></li>
<li><a href="#orga2c93fb">3.6.2. Of potentially abusive behavior</a></li>
<li><a href="#org885213e">3.6.3. Linguistic properties of abusive language</a></li>
<li><a href="#orgf72e017">3.6.4. Sentiment analysis</a></li>
<li><a href="#org5c600e3">3.6.5. Of opinion spam</a></li>
</ul>
</li>
<li><a href="#orgee57e92">3.7. Psychology, Perception</a>
<ul>
<li><a href="#org9bd9246">3.7.1. <span class="todo TODO">TODO</span> "The “Nasty Effect:” Online Incivility and Risk Perceptions of Emerging Technologies." </a></li>
<li><a href="#org79ac00e">3.7.2. <span class="todo TODO">TODO</span> "Newsworthiness and Network Gatekeeping on Twitter: The Role of Social Deviance" </a></li>
<li><a href="#org89131e5">3.7.3. And (Computational/Quantitative) Psycholinguistics</a></li>
</ul>
</li>
<li><a href="#orgbeebc60">3.8. Gamergate</a>
<ul>
<li><a href="#orge44cdcb">3.8.1. <span class="done DONE">DONE</span> Zoe Quinn’s Depression Quest | The New Yorker</a></li>
<li><a href="#orgeca6e08">3.8.2. <span class="todo TODO">TODO</span> Feminist Critics of Video Games Facing Threats in ‘GamerGate’ Campaign - The New York Times</a></li>
<li><a href="#org5d4af67">3.8.3. Anita Sarkeesian, Zoe Quinn</a></li>
</ul>
</li>
</ul>
</li>
<li><a href="#org56973fb">4. Questions</a>
<ul>
<li><a href="#orgd6dbad0">4.1. Has anyone done a comment/article similarity (relevance) study like but using word/document vectors instead of tf-idf?</a></li>
<li><a href="#org86a7ab2">4.2. Has anyone studied platform/OS source as predictor of potentially abusive language?</a></li>
<li><a href="#orgaa64721">4.3. What can psycholinguistics studies offer to fingerprinting of abusive language?</a></li>
<li><a href="#org4fe7e33">4.4. Has anyone written a Twitter bot to identify abusive speech, and then ask the alleged abuser/abusee whether he/she thought it was abusive?</a></li>
<li><a href="#org503667e">4.5. What Twitter accounts or hashtags might be cataloging abusive tweets? Can these be mined to create new datasets?</a></li>
<li><a href="#org5bc2155">4.6. If we can identify male voices or deceptive, can we use that as a proxy to identifying trolls?</a></li>
</ul>
</li>
<li><a href="#orgef4d498">5. Books and Other Sources</a>
<ul>
<li><a href="#martellozzo_cybercrime_2017">5.1. <span class="todo TODO">TODO</span> - Cybercrime and its victims</a></li>
<li><a href="#jane_misogyny_2016">5.2. <span class="todo TODO">TODO</span> - Misogyny Online: A Short (and Brutish) History</a></li>
<li><a href="#org3307448">5.3. <span class="todo TODO">TODO</span> - "Gendertrolling: How Misogyny Went Viral" </a></li>
<li><a href="#alba_weeding_2015">5.4. <span class="done DONE">DONE</span> - Weeding Out Online Bullying Is Tough, So Let Machines Do It</a></li>
<li><a href="#duggan_online_2014">5.5. <span class="todo TODO">TODO</span> - Pew Research Report 2014: Online Harassment</a></li>
</ul>
</li>
<li><a href="#orgae77d2d">6. Reports</a>
<ul>
<li><a href="#orgcdc0a23">6.1. Report 1 <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-22 Tue&gt;</span></span></a></li>
<li><a href="#org88b6ddb">6.2. Report 2, <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-28 Mon&gt;</span></span></a></li>
<li><a href="#orga84db44">6.3. Report 3, <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-14 Thu&gt;</span></span></a></li>
</ul>
</li>
<li><a href="#orgc63c967">7. References</a></li>
<li><a href="#org39c6f85">8. Meeting notes</a>
<ul>
<li><a href="#org506568f">8.1. Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-22 Tue&gt;</span></span></a></li>
<li><a href="#org6b654cc">8.2. Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-28 Mon&gt;</span></span></a>
<ul>
<li><a href="#org4b51f3b">8.2.1. Colin's week 1 summary: Summaries Week 1 - Google Docs</a></li>
</ul>
</li>
<li><a href="#org284c713">8.3. Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-07 Thu&gt;</span></span></a></li>
<li><a href="#orgd3beb0d">8.4. Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-14 Thu&gt;</span></span></a>
<ul>
<li><a href="#orgf41271d">8.4.1. NYU twitter bots: Using Data Science to Moderate Online Harrassment - NYU Center for Data Science</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>

<div id="outline-container-orgbb9b6e5" class="outline-2">
<h2 id="orgbb9b6e5"><span class="section-number-2">1</span> Todo</h2>
<div class="outline-text-2" id="text-1">
</div><div id="outline-container-org388f4e0" class="outline-3">
<h3 id="org388f4e0"><span class="section-number-3">1.1</span> <span class="todo TODO">TODO</span> read ACL workshop papers</h3>
<div class="outline-text-3" id="text-1-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">
<caption class="t-above"><span class="table-number">Table 1:</span> Clock summary at <span class="timestamp-wrapper"><span class="timestamp">[2017-08-30 Wed 12:41]</span></span></caption>

<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Headline</th>
<th scope="col" class="org-left">Time</th>
<th scope="col" class="org-left">&#xa0;</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left"><b>Total time</b></td>
<td class="org-left"><b>14:05</b></td>
<td class="org-left">&#xa0;</td>
</tr>
</tbody>
<tbody>
<tr>
<td class="org-left">&ensp;&ensp;read ACL workshop papers</td>
<td class="org-left">&#xa0;</td>
<td class="org-left">14:05</td>
</tr>
</tbody>
</table>
</div>
</div>

<div id="outline-container-orgcac4a5d" class="outline-3">
<h3 id="orgcac4a5d"><span class="section-number-3">1.2</span> <span class="todo TODO">TODO</span> prepare a list of NLP journals to search</h3>
</div>
<div id="outline-container-orgf0baf9d" class="outline-3">
<h3 id="orgf0baf9d"><span class="section-number-3">1.3</span> <span class="todo TODO">TODO</span> search NLP journals for keywords</h3>
</div>
<div id="outline-container-org081f259" class="outline-3">
<h3 id="org081f259"><span class="section-number-3">1.4</span> <span class="todo TODO">TODO</span> reach out to Phil for Gamergate tweets</h3>
</div>
<div id="outline-container-orgb8270fe" class="outline-3">
<h3 id="orgb8270fe"><span class="section-number-3">1.5</span> <span class="todo TODO">TODO</span> search ACM</h3>
</div>
<div id="outline-container-org3fdadc5" class="outline-3">
<h3 id="org3fdadc5"><span class="section-number-3">1.6</span> <span class="todo TODO">TODO</span> search Arxiv</h3>
</div>
<div id="outline-container-org5321cce" class="outline-3">
<h3 id="org5321cce"><span class="section-number-3">1.7</span> <span class="todo TODO">TODO</span> read papers about readability</h3>
</div>
<div id="outline-container-org6b31ec2" class="outline-3">
<h3 id="org6b31ec2"><span class="section-number-3">1.8</span> <span class="todo TODO">TODO</span> read papers about automated essay grading</h3>
</div>
<div id="outline-container-org3eaee20" class="outline-3">
<h3 id="org3eaee20"><span class="section-number-3">1.9</span> <span class="todo TODO">TODO</span> read papers about spam filtering</h3>
</div>
<div id="outline-container-org6a1ee68" class="outline-3">
<h3 id="org6a1ee68"><span class="section-number-3">1.10</span> <span class="todo TODO">TODO</span> explore Kaggle task: <a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary">Detecting Insults in Social Commentary | Kaggle</a></h3>
<div class="outline-text-3" id="text-1-10">
</div>
</div>
<div id="outline-container-orgb1a9669" class="outline-3">
<h3 id="orgb1a9669"><span class="section-number-3">1.11</span> <span class="todo TODO">TODO</span> identify good researchers to invite to Columbia</h3>
</div>
<div id="outline-container-orga320121" class="outline-3">
<h3 id="orga320121"><span class="section-number-3">1.12</span> Administrative</h3>
<div class="outline-text-3" id="text-1-12">
</div><div id="outline-container-org0c53b2a" class="outline-4">
<h4 id="org0c53b2a"><span class="section-number-4">1.12.1</span> <span class="done DONE">DONE</span> send Susan a copy of my UW syllabus</h4>
<div class="outline-text-4" id="text-1-12-1">
</div>
</div>
<div id="outline-container-org64fafbb" class="outline-4">
<h4 id="org64fafbb"><span class="section-number-4">1.12.2</span> <span class="done DONE">DONE</span> send Susan a copy of my calendar</h4>
<div class="outline-text-4" id="text-1-12-2">
</div>
</div>
<div id="outline-container-org1f12a52" class="outline-4">
<h4 id="org1f12a52"><span class="section-number-4">1.12.3</span> <span class="done DONE">DONE</span> fill out timesheet and submit to French department</h4>
<div class="outline-text-4" id="text-1-12-3">
</div>
</div>
<div id="outline-container-orgd020fbe" class="outline-4">
<h4 id="orgd020fbe"><span class="section-number-4">1.12.4</span> <span class="done DONE">DONE</span> ask French dept about sending PAF back to the English Dept</h4>
<div class="outline-text-4" id="text-1-12-4">
<p>
<a href="msgid:cb16c372-6032-1fef-570e-4c1770b0e42d@columbia.edu">uwp-list Information Memo #3: What to do if you worked elsewhere on campus this summer or will during the year</a>
</p>
</div>
</div>
<div id="outline-container-orgcd7b757" class="outline-4">
<h4 id="orgcd7b757"><span class="section-number-4">1.12.5</span> <span class="todo TODO">TODO</span> fill out timesheet and submit to French department</h4>
<div class="outline-text-4" id="text-1-12-5">
</div>
</div>
</div>
<div id="outline-container-org16407c6" class="outline-3">
<h3 id="org16407c6"><span class="section-number-3">1.13</span> <span class="todo TODO">TODO</span> organize GitHub repository into folders</h3>
<div class="outline-text-3" id="text-1-13">
<p>
<a href="msgid:CAAobwCjeCaVxUtrTRsE89qFFSnVW0dE46bp0jtBwX+YEP=3Zgg@mail.gmail.com">Re: a time to meet this week?</a>
</p>
</div>
</div>
<div id="outline-container-orgf0ce49e" class="outline-3">
<h3 id="orgf0ce49e"><span class="section-number-3">1.14</span> <span class="todo TODO">TODO</span> explore hatebase.org dataset</h3>
</div>
<div id="outline-container-orge68d0ef" class="outline-3">
<h3 id="orge68d0ef"><span class="section-number-3">1.15</span> <span class="todo TODO">TODO</span> explore psycholinguistics journals</h3>
<div class="outline-text-3" id="text-1-15">
</div>
<div id="outline-container-org570cf8e" class="outline-4">
<h4 id="org570cf8e"><span class="section-number-4">1.15.1</span> <span class="done DONE">DONE</span> Journal of Psycholinguistic Research</h4>
<div class="outline-text-4" id="text-1-15-1">
</div>
</div>
</div>
<div id="outline-container-org03ab526" class="outline-3">
<h3 id="org03ab526"><span class="section-number-3">1.16</span> <span class="done DONE">DONE</span> make outline of master report</h3>
<div class="outline-text-3" id="text-1-16">
</div>
</div>
<div id="outline-container-orgd9f54c4" class="outline-3">
<h3 id="orgd9f54c4"><span class="section-number-3">1.17</span> <span class="todo TODO">TODO</span> set up Doodle poll for next meeting</h3>
<div class="outline-text-3" id="text-1-17">
</div>
</div>
<div id="outline-container-org96064a9" class="outline-3">
<h3 id="org96064a9"><span class="section-number-3">1.18</span> <span class="todo TODO">TODO</span> make master report</h3>
<div class="outline-text-3" id="text-1-18">
</div>
</div>
</div>
<div id="outline-container-org23f9d7c" class="outline-2">
<h2 id="org23f9d7c"><span class="section-number-2">2</span> Links</h2>
<div class="outline-text-2" id="text-2">
</div><div id="outline-container-orgf18d3f5" class="outline-3">
<h3 id="orgf18d3f5"><span class="section-number-3">2.1</span> News, Blogs, Mass Media</h3>
<div class="outline-text-3" id="text-2-1">
</div><div id="outline-container-orgafe4a01" class="outline-4">
<h4 id="orgafe4a01"><span class="section-number-4">2.1.1</span> <span class="done DONE">DONE</span> <a href="https://www.nytimes.com/2017/06/21/opinion/whatsapp-crowds-and-power-in-india.html"><b>New York Times</b> WhatsApp, Crowd, Power in India</a></h4>
<div class="outline-text-4" id="text-2-1-1">
<ul class="org-ul">
<li>Describes fake news circulated using WhatsApp that results in mob violence, riots</li>
</ul>
</div>
</div>

<div id="outline-container-orgbe206f9" class="outline-4">
<h4 id="orgbe206f9"><span class="section-number-4">2.1.2</span> <span class="done DONE">DONE</span> New York Times: <a href="https://www.nytimes.com/2017/07/01/opinion/sunday/save-free-speech-from-trolls.html?action=click&amp;pgtype=Homepage&amp;clickSource=story-heading&amp;module=opinion-c-col-left-region&amp;region=opinion-c-col-left-region&amp;WT.nav=opinion-c-col-left-region">NYT: Save Free Speech from Trolls</a></h4>
<div class="outline-text-4" id="text-2-1-2">
<ul class="org-ul">
<li>"&#x2026;the anti-free-speech charge, applied broadly to cultural criticism and especially to feminist discourse, has proliferated."</li>
<li>"[Anita] Sarkeesian has been relentlessly stalked, abused, and threatened since 2012, when she started a Kickstarter campaign to fund a series of YouTube videos critiquing the representation of women in video games."</li>
<li>Sarkeesian: "They're weaponizing free speech to maintain their cultural dominance."</li>
<li>"'Free speech' rhetoric begot 'fake news,' which begot 'alternative facts.'"</li>
</ul>
</div>
</div>

<div id="outline-container-org84dcb9f" class="outline-4">
<h4 id="org84dcb9f"><span class="section-number-4">2.1.3</span> <span class="done DONE">DONE</span> <a href="https://datasociety.net/blog/2017/01/18/online-harassment-digital-abuse/">Data &amp; Society: Online Harassment and Digital Abuse</a></h4>
<div class="outline-text-4" id="text-2-1-3">
<ul class="org-ul">
<li>See report in <a href="#orgc2543b6">2.4</a> below</li>
</ul>
</div>
</div>
<div id="outline-container-org9a8967d" class="outline-4">
<h4 id="org9a8967d"><span class="section-number-4">2.1.4</span> <span class="done DONE">DONE</span> <a href="http://aclweb.org/anthology/W17-30">Proceedings of the first ACL Workshop on Abusive Language Online</a></h4>
<div class="outline-text-4" id="text-2-1-4">
<ul class="org-ul">
<li>Contains a number of relevant papers on the automated detection of abusive language. Parsed this into individual entries.</li>
</ul>
</div>
</div>
<div id="outline-container-org8bd7428" class="outline-4">
<h4 id="org8bd7428"><span class="section-number-4">2.1.5</span> <span class="todo TODO">TODO</span> <a href="https://meta.wikimedia.org/wiki/Research:Online_harassment_resource_guide">Online Harassment Resource Guide - Mattias, J. Nathan (et. al)</a></h4>
<div class="outline-text-4" id="text-2-1-5">
<ul class="org-ul">
<li>Susan: "Literature review on online harassment circa 2015/2016. Created for Wikimedia Foundation by folks from MIT Center for Civic Media &amp; Berkman Center for Internet and Society"</li>
<li>Very thorough overview</li>
</ul>
</div>
</div>
<div id="outline-container-org331bd89" class="outline-4">
<h4 id="org331bd89"><span class="section-number-4">2.1.6</span> TED talks</h4>
<div class="outline-text-4" id="text-2-1-6">
</div><ol class="org-ol"><li><a id="org5f82780"></a><a href="https://www.ted.com/talks/ashley_judd_how_online_abuse_of_women_has_spiraled_out_of_control">Ashley Judd: How online abuse of women has spiraled out of control | TED Talk | TED.com</a><br /><div class="outline-text-5" id="text-2-1-6-1">
<p>
October 2016 at TEDWomen 2016
</p>

<blockquote>
<p>
Judd recounts her ongoing experience of being terrorized on social media for her unwavering activism and calls on citizens of the internet, the tech community, law enforcement and legislators to recognize the offline harm of online harassment.
</p>
</blockquote>

<p>
"because the threat of violence is experienced neurobiologically as violence. The cortisol shoots up, the limbic system gets fired, we lose productivity at work." 
</p>

<p>
Judd founds The Speech Project: 
</p>
<ul class="org-ul">
<li><a href="http://wmcspeechproject.com/">http://wmcspeechproject.com/</a></li>
</ul>

<p>
"EDGE, the global standard for gender equality, is the minimum standard." 
</p>

<p>
And the law: "In New York recently, the law could not be applied to a perpetrator because the crimes must have been committed &#x2013; even if it was anonymous &#x2013; they must have been committed by telephone, in mail, by telegraph &#x2013;" 
</p>

<p>
<a href="https://github.com/JonathanReeve/sops">https://github.com/JonathanReeve/sops</a>
</p>
</div></li></ol>
</div>
</div>
<div id="outline-container-org1eeacd7" class="outline-3">
<h3 id="org1eeacd7"><span class="section-number-3">2.2</span> Software</h3>
<div class="outline-text-3" id="text-2-2">
</div><div id="outline-container-orgcff2f38" class="outline-4">
<h4 id="orgcff2f38"><span class="section-number-4">2.2.1</span> <span class="done DONE">DONE</span> <a href="https://devpost.com/software/trollbusters">TrollBusters | Devpost</a></h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
"Offering online "pest control" solutions for women news publishers"
</p>
</div>
<ol class="org-ol"><li><a id="orgfbdc227"></a><span class="done DONE">DONE</span> presentation slides: <a href="https://www.slideshare.net/locallygrownnews/trollbusters-international-womens-media-foundation-hackathon-solution">TrollBusters: International Women's Media Foundation Hackathon Soluti…</a><br /><div class="outline-text-5" id="text-2-2-1-1">
</div>
<ol class="org-ol"><li><a id="org7938c22"></a><span class="todo TODO">TODO</span> Use CATS: "C.A.T.S.: Clustering Analysis and Targeting System, Ohio University"<br /><div class="outline-text-6" id="text-2-2-1-1-1">
<ul class="org-ul">
<li>"Using a proprietary technology for network analysis developed by Ohio University students, we find and aggregate communities of trolls and identify who else is a subject of attack"</li>
</ul>
</div></li></ol></li>
<li><a id="orgc04e6af"></a><span class="done DONE">DONE</span> News article: <a href="http://alldigitocracy.org/combating-hate-speech-against-women-on-twitter/">Team developing tool to combat online harassment of women journalists takes top prize at New York hack-a-thon | All Digitocracy</a><br /><div class="outline-text-5" id="text-2-2-1-2">
<p>
"TrollBusters will use proprietary audience targeting software, designed by a team at Ferrier’s university, to identify communities of trolls around any given issue using natural language processing. The service will counter cyberattacks in real- time with online community support and positive messaging, Ferrier said in her pitch." 
</p>
</div></li></ol>
</div>
<div id="outline-container-orgb555c45" class="outline-4">
<h4 id="orgb555c45"><span class="section-number-4">2.2.2</span> <span class="done DONE">DONE</span> <a href="http://www.perspectiveapi.com/">Perspective</a> (Jigsaw, Google)</h4>
<div class="outline-text-4" id="text-2-2-2">
<ul class="org-ul">
<li>Looks like much of their code is <a href="https://github.com/conversationai">on GitHub</a></li>
<li>NYT is working with them (Jigsaw) to aid moderation</li>
</ul>
</div>
<ol class="org-ol"><li><a id="org58ba65c"></a><span class="done DONE">DONE</span> <a href="https://motherboard.vice.com/en_us/article/qvvv3p/googles-anti-bullying-ai-mistakes-civility-for-decency">Google's Anti-Bullying AI Mistakes Civility for Decency - Motherboard</a><br /><div class="outline-text-5" id="text-2-2-2-1">
</div></li>
<li><a id="orge0e6a4a"></a><span class="done DONE">DONE</span> <a href="http://www.nytco.com/the-times-is-partnering-with-jigsaw-to-expand-comment-capabilities/">The Times is Partnering with Jigsaw to Expand Comment Capabilities | The New York Times Company</a><br /><div class="outline-text-5" id="text-2-2-2-2">
</div></li>
<li><a id="org3760203"></a><span class="done DONE">DONE</span> Jigsaw working with Wikipedia: <a href="https://meta.wikimedia.org/wiki/Research:Detox">Research:Detox - Meta</a><br /><div class="outline-text-5" id="text-2-2-2-3">
</div></li></ol>
</div>
<div id="outline-container-org5364330" class="outline-4">
<h4 id="org5364330"><span class="section-number-4">2.2.3</span> <span class="done DONE">DONE</span> <a href="https://coralproject.net/">The Coral Project</a></h4>
<div class="outline-text-4" id="text-2-2-3">
<ul class="org-ul">
<li>Mozilla, also in use by NYT</li>
<li>Unclear how or whether this uses ML or automated detection of abuse. 
<ul class="org-ul">
<li>"Our Talk tool makes it easier for people to mute other users, and for newsrooms to spot and deal with abusive contributions quickly. It keeps you closer to conversations that you want to participate in, and away from those that you don’t."</li>
</ul></li>
<li><a href="https://blog.coralproject.net/talk-features/">Talk v1 features – The Coral Project</a>
<ul class="org-ul">
<li>"Banned words are immediately rejected; suspect words are automatically flagged"</li>
<li>"Links and banned/suspect words are highlighted for easier moderation"</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-org224e72d" class="outline-4">
<h4 id="org224e72d"><span class="section-number-4">2.2.4</span> <span class="done DONE">DONE</span> <a href="https://tools.wmflabs.org/detox/%20%20">Wikipedia DeTox</a> (also Jigsaw)</h4>
<div class="outline-text-4" id="text-2-2-4">
</div>
<ol class="org-ol"><li><a id="org5d29025"></a>Test<br /><div class="outline-text-5" id="text-2-2-4-1">
<ul class="org-ul">
<li>Testing aggression model: 
<ul class="org-ul">
<li>"Be careful, you might find some white powder in an envelope come in the mail one day." 1% aggressive.</li>
<li>"If you keep this up, you find yourself sleeping with the fishes." 12% aggressive.</li>
<li>"I'm going to come to your house." 48% aggressive.</li>
<li>"I'm going to nominate you for the Nobel prize, you brilliant man." 61% aggressive.</li>
</ul></li>
</ul>
</div></li></ol>
</div>
<div id="outline-container-org779c03a" class="outline-4">
<h4 id="org779c03a"><span class="section-number-4">2.2.5</span> Development contests</h4>
<div class="outline-text-4" id="text-2-2-5">
</div><ol class="org-ol"><li><a id="orgb06035b"></a><span class="todo TODO">TODO</span> 2012 Kaggle Task, <a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary">Detecting Insults in Social Commentary</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /><div class="outline-text-5" id="text-2-2-5-1">
<ul class="org-ul">
<li>winning entries used Python and scikit-learn; lots of entries ranking 8th and below used R</li>
<li>tokenization is a (surprisingly) important part of this&#x2013;what constitutes a word
<ul class="org-ul">
<li>collapsing spaces between single-letters: "f u c k" -&gt; "fuck"</li>
</ul></li>
<li>many of these seem to have unnecessarily custom implementations of common tokenization, stemming, or other functions. 
<ul class="org-ul">
<li>Q: could this be improved by using industry-standard libraries?</li>
</ul></li>
<li>almost all use some form of cross-validation or grid search, tuning its own parameters</li>
</ul>
</div>
<ol class="org-ol"><li><a id="orgbddbad4"></a>Vivek Sharma, 1st Place<br /><ol class="org-ol"><li><a id="orgc9cd21c"></a><span class="todo TODO">TODO</span> original code: <a href="https://kaggle2.blob.core.windows.net/forum-message-attachments/4809/model6.py">single python script</a><br /><div class="outline-text-7" id="text-2-2-5-1-1-1">
<ul class="org-ul">
<li>added to repository at <a href="Code/kaggle-1st-sharma/kaggle-1st-sharma.py">Code/kaggle-1st-sharma/kaggle-1st-sharma.py</a></li>
</ul>
</div>
<ol class="org-ol"><li><a id="org5a86d0f"></a><span class="todo TODO">TODO</span> try to get this to work<br /><div class="outline-text-8" id="text-2-2-5-1-1-1-1">
<ul class="org-ul">
<li class="on"><code>[X]</code> download test data from Kaggle</li>
<li class="on"><code>[X]</code> convert Python 2 to Python 3</li>
<li class="off"><code>[&#xa0;]</code> figure out what's going on with the strange probability scores - maybe read the discussion again</li>
</ul>
</div></li>
<li><a id="org9532763"></a><span class="todo TODO">TODO</span> see if it can be improved by:<br /><div class="outline-text-8" id="text-2-2-5-1-1-1-2">
<ul class="org-ul">
<li class="off"><code>[&#xa0;]</code> replacing stemmers</li>
</ul>
</div></li></ol></li>
<li><a id="orgbff9ad8"></a><span class="done DONE">DONE</span> <a href="https://kaggle2.blob.core.windows.net/forum-message-attachments/4810/badwords.txt">uses this "bad words" file</a><br /></li>
<li><a id="org189ba45"></a><span class="done DONE">DONE</span> description<br /><div class="outline-text-7" id="text-2-2-5-1-1-3">
<blockquote>
<p>
My feature set was almost the same as the char and word features that Andreas used. SVC gave me better performance than regularized LR.  And, some normalizations (like tuzzeg mentioned), along with using a bad words list (<a href="http://urbanoalvarez.es/blog/2008/04/04/bad-words-list/">http://urbanoalvarez.es/blog/2008/04/04/bad-words-list/</a>) helped quite a bit. Those were probably the only differences between Andreas' score and mine. The single SVC model would have won by itself, although the winning submission combined SVC with RF which improved the score marginally over just SVC. Regularized LR and GBRT were also tried, but they did not change the score much. I did not use the datetime field.
</p>

<p>
Tuzzeg, I experimented a little bit with phrase features, and I'm pretty sure they would be needed in any implementation of such a system. A lot of the insults were of the form: "you are/you're a/an xxxx", "xxxx like you", "you xxxx". I tried to look for a large +ve/-ve word list to determine sentiment of such phrases with unseen words, but I couldn't find a good word list that was freely available for commercial use. Does anyone know of one? Ultimately, I didn't use any such features except for a very simplified one based on "you are/you're xxx" which did help the score, although, only to a small extent. 
</p>
</blockquote>
</div></li></ol></li>
<li><a id="orgbd5ccab"></a>Tuzzeg, 2nd Place<br /><div class="outline-text-6" id="text-2-2-5-1-2">
<ul class="org-ul">
<li>uses Stanford POS and Stanford tagger for feature extraction, Python and scikit-learn for everything else</li>
<li>uses a Random Forest regressor as a meta-classifier for a stack of basic classifiers</li>
<li>uses different language models: 
<ul class="org-ul">
<li>char n-grams</li>
<li>stem + POS models</li>
<li>! "syntax bigrams" using dependency modeling (a word paired with the tag of its dependent, e.g. "understand do" -&gt; "understand AUX)</li>
</ul></li>
</ul>
</div>
<ol class="org-ol"><li><a id="orgdc603ab"></a><span class="done DONE">DONE</span> Short technique description<br /><div class="outline-text-7" id="text-2-2-5-1-2-1">
<blockquote>
<p>
I used scikit-learn as well, with Stanford POS tagger and Stanford parser. My approach in general was ensemble of LogisitcRegression classifiers over words, stemmed words, POS tags, char ngrams, words/stems 2,3-grams, word/stem subsequences, language models over words/stems/tags and a bunch of features over dependency parsing results (110 basic classifiers in final solution). All of them were stacked using ExtraTreesRegressor.
</p>

<p>
I didn't use word correction - which could help to detect such phrases like 'r u'=='are you' or 'f#%k'.
</p>
</blockquote>
</div></li>
<li><a id="orgf367d4d"></a><span class="done DONE">DONE</span> <a href="https://github.com/tuzzeg/detect_insults">code on GitHub</a><br /><div class="outline-text-7" id="text-2-2-5-1-2-2">
<ul class="org-ul">
<li>Much, much more code than the 1st place script</li>
</ul>
</div>
<ol class="org-ol"><li><a id="org80fa9ab"></a><span class="todo TODO">TODO</span> get this to work<br /></li></ol></li>
<li><a id="orgc14f383"></a><span class="done DONE">DONE</span> <a href="https://github.com/tuzzeg/detect_insults/blob/master/README.md">In-depth description</a><br /><div class="outline-text-7" id="text-2-2-5-1-2-3">
</div></li></ol></li>
<li><a id="org541367f"></a>Andrei Olariu, 3rd Place<br /><div class="outline-text-6" id="text-2-2-5-1-3">
<ul class="org-ul">
<li>very elaborate custom tokenization, removes repeated letters ("coooool" -&gt; "cool")
<ul class="org-ul">
<li>"grouping together sequences of one-letter words – like “f u c k”"</li>
</ul></li>
<li>uses neural net classifier to tie together three basic categorizers</li>
<li>adds custom features: "the ratio of curse words; the text length; the ratio of *, ! or ?; the ratio of capital letter (should have used words in all caps instead)"</li>
</ul>
</div>
<ol class="org-ol"><li><a id="org66b1bbf"></a><span class="done DONE">DONE</span> Summary<br /><div class="outline-text-7" id="text-2-2-5-1-3-1">
<p>
"SVMs, neural networks and some good tokenizing"
</p>
</div></li>
<li><a id="orgb126963"></a><span class="done DONE">DONE</span> <a href="http://webmining.olariu.org/my-first-kaggle-competition-and-how-i-ranked/">Description in blog post</a><br /><div class="outline-text-7" id="text-2-2-5-1-3-2">
</div></li>
<li><a id="org1b19a8e"></a><span class="done DONE">DONE</span> <a href="https://github.com/andreiolariu/kaggle-insults">code on GitHub</a><br /><div class="outline-text-7" id="text-2-2-5-1-3-3">
<ul class="org-ul">
<li>like 2nd place entry, much, much more code here than 1st place script</li>
</ul>
</div></li></ol></li>
<li><a id="org7dfe34b"></a>Joshnk, 4th Place<br /><ol class="org-ol"><li><a id="org679ed1b"></a><span class="done DONE">DONE</span> Summary<br /><div class="outline-text-7" id="text-2-2-5-1-4-1">
<blockquote>
<p>
I used character n-grams, tfidf with sublinear<sub>tf</sub> and SGDRegressor with early stopping. I am somewhat proud of the early stopping code.
</p>

<p>
My reason for using a regression estimator was that the evaluation was going to be AUC, which is sensitive only to the order of the scores, not the finer details. Had I used a classifier, I would have needed to do something with predict proba to arrange the items in a good order anyway. SGD is also nice because it works well with sparse inputs lets you explore things like the use of the elastic net penalty while sticking with the same classifier.
</p>

<p>
As I said in my comment on Andreas Mueller's blog, the final order has an element of luck to it, because the final test set was so small and the labeling was rather noisy
</p>
</blockquote>
</div></li>
<li><a id="orgcb52b91"></a><span class="done DONE">DONE</span> <a href="https://github.com/cbrew/Insults/blob/master/Insults/insults.py">code on GitHub</a><br /><div class="outline-text-7" id="text-2-2-5-1-4-2">
<ul class="org-ul">
<li>command-line Python program</li>
<li>seems to be manually tuned instead of using CV?</li>
</ul>
</div></li></ol></li>
<li><a id="org764eaba"></a>Andreas Mueller, 6th Place<br /><ol class="org-ol"><li><a id="org1c470f6"></a><span class="todo TODO">TODO</span> <a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary">code on GitHub</a><br /></li>
<li><a id="org9a55637"></a><span class="done DONE">DONE</span> Blog post: <a href="http://peekaboo-vision.blogspot.de/2012/09/recap-of-my-first-kaggle-competition.html">Peekaboo: Recap of my first Kaggle Competition: Detecting Insults in Social Commentary {update 3}</a><br /><div class="outline-text-7" id="text-2-2-5-1-5-2">
<ul class="org-ul">
<li>uses a combination of four language models, incl. char n-grams, word n-grams (performed better than chars), custom features</li>
<li>all params cross-validated</li>
<li>bad words list: "For the list of bad words, I used one that allegedly is also used by google. As this will include 'motherfucker' but not 'idiot' or 'moron' (two VERY important words in the training / leaderboard set), I extended the list with these and whatever the thesaurus said was 'stupid'."</li>
</ul>
</div></li></ol></li></ol></li></ol>
</div>
</div>
<div id="outline-container-org65bcbff" class="outline-3">
<h3 id="org65bcbff"><span class="section-number-3">2.3</span> Organizations</h3>
<div class="outline-text-3" id="text-2-3">
</div><div id="outline-container-orge9d9cc3" class="outline-4">
<h4 id="orge9d9cc3"><span class="section-number-4">2.3.1</span> Colin's doc: <a href="https://docs.google.com/document/d/1nMbD79FwAHny-9VEf2vLXZIk9hBdx8ttkcCFA5GFGyM/edit?ts=59a4686b#heading=h.iy6oqdld37n2">Organizations doing something - Google Docs</a></h4>
</div>
<div id="outline-container-org71415cb" class="outline-4">
<h4 id="org71415cb"><span class="section-number-4">2.3.2</span> <span class="done DONE">DONE</span> <a href="http://wmcspeechproject.com/">WMC Speech Project</a></h4>
<div class="outline-text-4" id="text-2-3-2">
</div>
<ol class="org-ol"><li><a id="org768302a"></a><span class="done DONE">DONE</span> <a href="http://wmcspeechproject.com/research-statistics/">WMC Speech Project » Research &amp; Statistics</a><br /><div class="outline-text-5" id="text-2-3-2-1">
</div></li></ol>
</div>
<div id="outline-container-org5dfe155" class="outline-4">
<h4 id="org5dfe155"><span class="section-number-4">2.3.3</span> <span class="done DONE">DONE</span> <a href="https://www.trolldor.com/">Trolldor: the global blacklist of twitter trolls</a></h4>
<div class="outline-text-4" id="text-2-3-3">
<blockquote>
<p>
The aim of Trolldor is to combat the defenselessness of Twitter users. We want to get across the need behavior on Twitter to be based on respect for users, to encourage a good social network environment.
</p>

<p>
We feel that the behavior of some Twitter users is part of the problem, which is why we’ve created Trolldor, a place where users themselves are the ones who can report other users that fail to respect everyone else.
</p>

<p>
Trolldor works like a blacklist of Trolls, and is open to any user in the world with a Twitter account.
</p>
</blockquote>

<ul class="org-ul">
<li>Needs three reports from different users to get listed.</li>
<li>Maintain a list of top 10 worldwide tr</li>
</ul>
</div>
</div>
<div id="outline-container-orgb74bc5b" class="outline-4">
<h4 id="orgb74bc5b"><span class="section-number-4">2.3.4</span> <span class="done DONE">DONE</span> <a href="https://www.nohatespeechmovement.org/">No Hate Speech Movement</a></h4>
<div class="outline-text-4" id="text-2-3-4">
<p>
"A youth campaign of the Council of Europe for human rights online, to reduce the levels of acceptance of hate speech and develop online youth participation and citizenship, including in Internet governance processes."
</p>
</div>
</div>

<div id="outline-container-org49f32e8" class="outline-4">
<h4 id="org49f32e8"><span class="section-number-4">2.3.5</span> <span class="todo TODO">TODO</span> <a href="https://www.splcenter.org/hate-map">Southern Poverty Law Center</a></h4>
<div class="outline-text-4" id="text-2-3-5">
<ul class="org-ul">
<li>maintain a list and map of 917 hate groups operating in the US</li>
</ul>
</div>
</div>

<div id="outline-container-orgcb02924" class="outline-4">
<h4 id="orgcb02924"><span class="section-number-4">2.3.6</span> <span class="todo TODO">TODO</span> <a href="https://cyberbullying.org/">Cyberbullying Research Center</a></h4>
<div class="outline-text-4" id="text-2-3-6">
<p>
"The Cyberbullying Research Center is dedicated to providing up-to-date information about the nature, extent, causes, and consequences of cyberbullying among adolescents. Cyberbullying can be defined as “Willful and repeated harm inflicted through the use of computers, cell phones, and other electronic devices.” It is also known as “cyber bullying,” “electronic bullying,” “e-bullying,” “sms bullying,” “mobile bullying,” “online bullying,” “digital bullying,” or “Internet bullying.” The Center also explores other adolescent behaviors online including sexting, problematic social networking practices, and a variety of issues related to digital citizenship."
</p>
</div>
</div>

<div id="outline-container-org51ebce0" class="outline-4">
<h4 id="org51ebce0"><span class="section-number-4">2.3.7</span> <span class="todo TODO">TODO</span> <a href="https://cpj.org/">Committee to Protect Journalists</a></h4>
<div class="outline-text-4" id="text-2-3-7">
<p>
"The Committee to Protect Journalists is an independent, nonprofit organization that promotes press freedom worldwide. We defend the right of journalists to report the news without fear of reprisal."
</p>
</div>
</div>
<div id="outline-container-org80e5403" class="outline-4">
<h4 id="org80e5403"><span class="section-number-4">2.3.8</span> <span class="todo TODO">TODO</span> Anti-Defamation League Task Force on Harassment and Journalism</h4>
<div class="outline-text-4" id="text-2-3-8">
</div><ol class="org-ol"><li><a id="org16c99be"></a>Description of report: <a href="http://denver.adl.org/news/adl-task-force-issues-report-detailing-widespread-anti-semitic-harassment-of-journalists-on-twitter-during-2016-campaign/">Anti-Defamation League | ADL TASK FORCE ISSUES REPORT DETAILING WIDESPREAD ANTI-SEMITIC HARASSMENT OF JOURNALISTS ON TWITTER DURING 2016 CAMPAIGN | Denver</a><br /><div class="outline-text-5" id="text-2-3-8-1">
<p>
<a class='org-ref-reference' href="#anti-defamation_league_adl_2016">anti-defamation_league_adl_2016</a>
</p>
</div></li></ol>
</div>
<div id="outline-container-orgddd836b" class="outline-4">
<h4 id="orgddd836b"><span class="section-number-4">2.3.9</span> <span class="todo TODO">TODO</span> <a href="http://haltabuse.org/">Working to Halt Online Abuse</a></h4>
</div>
<div id="outline-container-org0de3236" class="outline-4">
<h4 id="org0de3236"><span class="section-number-4">2.3.10</span> <span class="todo TODO">TODO</span> <a href="http://www.broadbandcommission.org/workinggroups/pages/bbandgender.aspx">UN Broadband Commission for Sustainable Development Working Group on Broadband and Gender</a></h4>
<div class="outline-text-4" id="text-2-3-10">
</div><ol class="org-ol"><li><a id="org5942e38"></a><span class="todo TODO">TODO</span> Report: <a href="http://www.unwomen.org/~/media/headquarters/attachments/sections/library/publications/2015/cyber_violence_gender%20report.pdf?v=1&amp;d=20150924T154259">Cyber Violence Against Women and Girls</a><br /><ol class="org-ol"><li><a id="org0558747"></a><span class="todo TODO">TODO</span> Response in NY Mag: <a href="http://nymag.com/scienceofus/2015/09/uns-cyberharassment-report-is-really-bad.html">The U.N.’s Cyberharassment Report Is Really Bad</a><br /></li></ol></li></ol>
</div>
<div id="outline-container-org66c60f9" class="outline-4">
<h4 id="org66c60f9"><span class="section-number-4">2.3.11</span> <span class="todo TODO">TODO</span> SRI International</h4>
<div class="outline-text-4" id="text-2-3-11">
<p>
"nine months ago, a social network approached the SRI and said it had a major problem with bullying on its platform. The company, which Winarsky declined to identify, had already gathered a wealth of reports and data sets on bullying and offered them to SRI to see if its researchers could do anything to help curb the problem." <a class='org-ref-reference' href="#alba_weeding_2015">alba_weeding_2015</a> 
</p>
</div>
</div>
<div id="outline-container-org5149def" class="outline-4">
<h4 id="org5149def"><span class="section-number-4">2.3.12</span> <span class="todo TODO">TODO</span> <a href="https://womenactionmedia.org/">Women Action Media</a> (WAM!)</h4>
<div class="outline-text-4" id="text-2-3-12">
<p>
"allowed to report and identify harassment on behalf of others" and report them to Twitter <a class='org-ref-reference' href="#lapowsky_its_2015">lapowsky_its_2015</a> 
</p>
</div>
</div>
<div id="outline-container-org36334f4" class="outline-4">
<h4 id="org36334f4"><span class="section-number-4">2.3.13</span> <span class="todo TODO">TODO</span> <a href="https://www.hackharassment.com/">Hack Harassment</a></h4>
<div class="outline-text-4" id="text-2-3-13">
<p>
"Hack Harassment is a coalition of organizations and individuals who share in the common goal of building a more inclusive and supportive online community.  Hack Harassment does not guarantee the world will be free from online harassment, but together, we hope to bring us all closer to that goal." 
</p>
</div>
</div>
<div id="outline-container-org8d75203" class="outline-4">
<h4 id="org8d75203"><span class="section-number-4">2.3.14</span> Algorithmic</h4>
<div class="outline-text-4" id="text-2-3-14">
</div><ol class="org-ol"><li><a id="org1fc3d74"></a><span class="todo TODO">TODO</span> <a href="https://jigsaw.google.com/vision/">Jigsaw</a>: org within Alphabet (Google)<br /><div class="outline-text-5" id="text-2-3-14-1">
<p>
"We’re an incubator within Alphabet that builds technology to tackle some of the toughest global security challenges facing the world today—from thwarting online censorship to mitigating the threats from digital attacks to countering violent extremism to protecting people from online harassment." 
</p>

<ul class="org-ul">
<li>Creators of project <a href="http://www.perspectiveapi.com/">Perspective</a></li>
</ul>
</div></li></ol>
</div>
</div>
<div id="outline-container-orgc2543b6" class="outline-3">
<h3 id="orgc2543b6"><span class="section-number-3">2.4</span> Statistics about Harassment</h3>
<div class="outline-text-3" id="text-2-4">
</div><div id="outline-container-orgbf6dfcf" class="outline-4">
<h4 id="orgbf6dfcf"><span class="section-number-4">2.4.1</span> Proportion of Internet users that experience harassment</h4>
<div class="outline-text-4" id="text-2-4-1">
<ul class="org-ul">
<li>47% (D&amp;S report)</li>
</ul>
</div>
</div>
<div id="outline-container-orge7ed424" class="outline-4">
<h4 id="orge7ed424"><span class="section-number-4">2.4.2</span> <a href="http://onlineharassmentdata.org/">Infographic: The Rise of Online Harassment</a></h4>
<div class="outline-text-4" id="text-2-4-2">
<p>
Survey by: 
</p>
<ul class="org-ul">
<li>Rad Campaign (Web Design Agency)</li>
<li>Lincoln Park Strategies (Data analytics)</li>
<li>Craig Newmark (Consultant?)</li>
</ul>
</div>
</div>
<div id="outline-container-org91c7f33" class="outline-4">
<h4 id="org91c7f33"><span class="section-number-4">2.4.3</span> <span class="done DONE">DONE</span> <a href="http://www.pewinternet.org/2014/10/22/online-harassment/">Online Harassment | Pew Research Center</a></h4>
<div class="outline-text-4" id="text-2-4-3">
<p>
2014 Report
</p>
</div>
</div>
<div id="outline-container-orge38a90d" class="outline-4">
<h4 id="orge38a90d"><span class="section-number-4">2.4.4</span> <span class="done DONE">DONE</span> <a href="http://www.haltabuse.org/resources/stats/index.shtml">WHOA: Cyberstalking Statistics.</a></h4>
<div class="outline-text-4" id="text-2-4-4">
</div>
</div>
<div id="outline-container-org31e5afc" class="outline-4">
<h4 id="org31e5afc"><span class="section-number-4">2.4.5</span> <a href="http://www.iwmf.org/blog/2014/03/07/intimidation-threats-and-abuse/">Intimidation, Threats, and Abuse | International Women's Media Foundation (IWMF)</a></h4>
</div>
<div id="outline-container-org479f630" class="outline-4">
<h4 id="org479f630"><span class="section-number-4">2.4.6</span> <span class="todo TODO">TODO</span> [[<a href="https://www.datasociety.net/pubs/oh/Online_Harassment_2016.pdf">https://www.datasociety.net/pubs/oh/Online_Harassment_2016.pdf</a>][Data and Society Report: Online Harassment, Digital Abuse, and Cyberstalking in America]</h4>
<div class="outline-text-4" id="text-2-4-6">
</div><ol class="org-ol"><li><a id="org89fb1b9"></a><span class="done DONE">DONE</span> <a href="https://qz.com/844319/a-new-study-suggests-online-harassment-is-pressuring-women-and-minorities-to-self-censor/">A new study suggests online harassment is pressuring women and minorities to self-censor — Quartz</a><br /><div class="outline-text-5" id="text-2-4-6-1">
<ul class="org-ul">
<li>"Researchers consistently find that people self-censor online to avoid retaliation. This could be positive: For instance, people might be less likely to use a racial slur online if they think they’ll be condemned for it. But given the differences in people’s experience of harassment, this survey suggests that young people, especially young women and LGB people, are less likely to make online contributions at all because they’re worried about being attacked for it."</li>
</ul>
</div></li>
<li><a id="org7b009ff"></a><span class="done DONE">DONE</span> Blog post: <a href="https://points.datasociety.net/culture-of-harassment-1d999adbfac3">Culture of Harassment – Data &amp; Society: Points</a><br /><div class="outline-text-5" id="text-2-4-6-2">
<ul class="org-ul">
<li>Summarizes D&amp;S report.</li>
<li>"Danah Boyd reads Data &amp; Society and CiPHR’s new report, “Online Harassment, Digital Abuse, and Cyberstalking in America,” and connects it with her own qualitative research and today’s political culture. Online harassment, she argues, suppresses voices that need to be heard for the public sphere to be public. — Ed."</li>
</ul>
</div></li>
<li><a id="orge81bb0e"></a><span class="todo TODO">TODO</span> <a href="https://www.theatlantic.com/technology/archive/2016/11/people-censor-themselves-online-for-fear-of-being-harassed/508523/">47 Percent of U.S. Internet Users Have Experienced Online Abuse - The Atlantic</a><br /></li></ol>
</div>
</div>
<div id="outline-container-orgf95b23e" class="outline-3">
<h3 id="orgf95b23e"><span class="section-number-3">2.5</span> Social Media Services</h3>
<div class="outline-text-3" id="text-2-5">
</div><div id="outline-container-org6b6ae00" class="outline-4">
<h4 id="org6b6ae00"><span class="section-number-4">2.5.1</span> General Legal / Terms of Service Issues</h4>
<div class="outline-text-4" id="text-2-5-1">
</div><ol class="org-ol"><li><a id="orgb113f4a"></a><span class="todo TODO">TODO</span> "Towards a better protection of social media users: a legal perspective on the terms of use of social networking sites" <a class='org-ref-reference' href="#wauters_towards_2014">wauters_towards_2014</a><br /></li>
<li><a id="org15976a8"></a><span class="todo TODO">TODO</span> "Intermediaries and hate speech: Fostering digital citizenship for our information age." <a class='org-ref-reference' href="#citron_intermediaries_2011">citron_intermediaries_2011</a><br /></li></ol>
</div>
<div id="outline-container-org72b190b" class="outline-4">
<h4 id="org72b190b"><span class="section-number-4">2.5.2</span> Facebook</h4>
<div class="outline-text-4" id="text-2-5-2">
</div><ol class="org-ol"><li><a id="orge5228bd"></a><span class="done DONE">DONE</span> - ProPublica: <a href="https://www.propublica.org/article/facebook-hate-speech-censorship-internal-documents-algorithms">Facebook's Secret Censorship Rules Protect White Men from Hate Speech But Not Black Children</a><br /><div class="outline-text-5" id="text-2-5-2-1">
<ul class="org-ul">
<li>Describes Facebook's rules for deleting posts</li>
<li>Facebook doesn't delete attacks on "subsets" of people, e.g. "female drivers," but deletes posts of "protected categories," of entire races, sexes, religious affiliations, e.g. "white men."</li>
<li>Facebook permits speech that is illegal in some countries, like Holocaust denial</li>
<li>FB currently employs about 4,500 censors</li>
<li>FB shuts down accounts of some activists. (Article doesn't explain reasons.)</li>
<li>"Kate Klonick, a Ph.D. candidate at Yale Law School who has spent two years studying censorship operations at tech companies,"</li>
<li>"Candidate Trump’s posting — which has come back to haunt him in court decisions voiding his proposed travel ban — appeared to violate Facebook’s rules against “calls for exclusion” of a protected religious group. Zuckerberg decided to allow it because it was part of the political discourse, according to people familiar with the situation."
<ul class="org-ul">
<li>Q: Would allowing incendiary posts/comments ultimately be healthy for society, since it allows for criticism and discourse?</li>
</ul></li>
</ul>
</div></li></ol>
</div>

<div id="outline-container-orgb1bccac" class="outline-4">
<h4 id="orgb1bccac"><span class="section-number-4">2.5.3</span> Twitter</h4>
<div class="outline-text-4" id="text-2-5-3">
</div><ol class="org-ol"><li><a id="org713a06b"></a><span class="done DONE">DONE</span> Twitter blog post: <a href="https://blog.twitter.com/official/en_us/a/2016/progress-on-addressing-online-abuse.html">Progress on addressing online abuse</a><br /><div class="outline-text-5" id="text-2-5-3-1">
<ul class="org-ul">
<li>"We’re enabling you to mute keywords, phrases, and even entire conversations you don’t want to see notifications about"</li>
<li>"We’ve also improved our internal tools and systems in order to deal more effectively with this conduct when it’s reported to us. Our goal is a faster and more transparent process."</li>
</ul>
</div></li>
<li><a id="orgb882821"></a><span class="done DONE">DONE</span> <a href="https://support.twitter.com/articles/20175050#">Twitter: Hateful Conduct Policy</a><br /><div class="outline-text-5" id="text-2-5-3-2">
<ul class="org-ul">
<li>"You may not promote violence against or directly attack or threaten other people on the basis of race, ethnicity, national origin, sexual orientation, gender, gender identity, religious affiliation, age, disability, or disease."</li>
<li>"Context matters. Some Tweets may seem to be abusive when viewed in isolation, but may not be when viewed in the context of a larger conversation."</li>
<li>Say that they may suspend accounts for violations.</li>
</ul>
</div></li>
<li><a id="org62441e1"></a><span class="done DONE">DONE</span> Wired article: <a href="https://www.wired.com/2017/03/twitter-abuse-tools/">Twitter Eggs, the End Has Finally Come for Your Awfulness | WIRED</a><br /><div class="outline-text-5" id="text-2-5-3-3">
<ul class="org-ul">
<li>On algorithms for filtering trolls: "Twitter says it has developed algorithms that can detect when an account engages in abusive behavior—for instance, if it repeatedly tweets at non-followers."</li>
<li>On user-level filtering: "Twitter will now let users filter "Twitter eggs" out of their notifications."</li>
</ul>
</div></li>
<li><a id="org0e86d59"></a>Twitter timeout<br /><ol class="org-ol"><li><a id="org18e23b8"></a><span class="todo TODO">TODO</span> <a href="https://techcrunch.com/2017/02/16/twitter-starts-putting-abusers-in-time-out/">Twitter starts putting abusers in “time out” | TechCrunch</a><br /></li></ol></li></ol>
</div>
<div id="outline-container-org84862ce" class="outline-4">
<h4 id="org84862ce"><span class="section-number-4">2.5.4</span> Mastodon</h4>
<div class="outline-text-4" id="text-2-5-4">
</div><ol class="org-ol"><li><a id="orgdaf6faf"></a><span class="done DONE">DONE</span> <a href="http://www.newstatesman.com/science-tech/social-media/2017/04/mastodonsocial-why-does-every-new-twitter-fail">Mastodon.social: Why does every new “Twitter” fail?</a><br /><div class="outline-text-5" id="text-2-5-4-1">
<ul class="org-ul">
<li>Calls Mastodon a failure, and attempts a postmortem.</li>
</ul>
</div></li>
<li><a id="org0b633ba"></a><span class="todo TODO">TODO</span> WIRED: <a href="https://www.wired.com/2017/04/like-twitter-hate-trolls-try-mastodon/">Social Media Upstart Mastodon Is Like Twitter, Except Way More Civil | WIRED</a><br /></li></ol>
</div>
<div id="outline-container-orga32cb17" class="outline-4">
<h4 id="orga32cb17"><span class="section-number-4">2.5.5</span> WhatsApp</h4>
</div>
<div id="outline-container-orgf036bb9" class="outline-4">
<h4 id="orgf036bb9"><span class="section-number-4">2.5.6</span> Reddit</h4>
<div class="outline-text-4" id="text-2-5-6">
</div><ol class="org-ol"><li><a id="org42b74df"></a><span class="done DONE">DONE</span> <a href="https://www.reddit.com/r/announcements/comments/4dmnn6/new_and_improved_block_user_feature_in_your_inbox/">New and improved "block user" feature in your inbox. : announcements</a><br /><div class="outline-text-5" id="text-2-5-6-1">
</div></li>
<li><a id="org237ed97"></a><span class="todo TODO">TODO</span> <a href="https://socialmediacollective.org/2015/06/16/reddit-research/">Recognizing the Work of Reddit’s Moderators: Summer Research Project | Social Media Collective</a><br /></li></ol>
</div>
<div id="outline-container-org57a6e3d" class="outline-4">
<h4 id="org57a6e3d"><span class="section-number-4">2.5.7</span> Wikipedia</h4>
<div class="outline-text-4" id="text-2-5-7">
</div><ol class="org-ol"><li><a id="org87b5473"></a><span class="todo TODO">TODO</span> The Work of Sustaining Order in Wikipedia: The Banning of a Vandal <a class='org-ref-reference' href="#geiger_work_2010">geiger_work_2010</a><br /></li>
<li><a id="org9d40e66"></a><span class="todo TODO">TODO</span> Book: Wikipedia and the Politics of Openness <a class='org-ref-reference' href="#tkacz_wikipedia_2014">tkacz_wikipedia_2014</a><br /></li></ol>
</div>
<div id="outline-container-orgc40655d" class="outline-4">
<h4 id="orgc40655d"><span class="section-number-4">2.5.8</span> Metafilter</h4>
<div class="outline-text-4" id="text-2-5-8">
</div><ol class="org-ol"><li><a id="org437e01a"></a><span class="todo TODO">TODO</span> Dissertation: "What we talk about when we talk about talking: Ethos at work in an online community" <a class='org-ref-reference' href="#warnick_what_2010">warnick_what_2010</a><br /><div class="outline-text-5" id="text-2-5-8-1">
<p>
Abstract: "This dissertation explores the rhetorical concept of ethos as it functions in contemporary online communities, via a case study of one successful online community, MetaFilter. com. A year-long virtual ethnography of MetaFilter demonstrates that understanding ethos as it functions online requires a multilayered definition that accounts for the traditional notion of ethos as vir bonus, the strict Aristotelian conception of ethos as &#x2026;" 
</p>
</div></li></ol>
</div>
</div>
<div id="outline-container-org163b6b8" class="outline-3">
<h3 id="org163b6b8"><span class="section-number-3">2.6</span> People</h3>
</div>
<div id="outline-container-orga8b9703" class="outline-3">
<h3 id="orga8b9703"><span class="section-number-3">2.7</span> Patents</h3>
<div class="outline-text-3" id="text-2-7">
</div><div id="outline-container-orgf6fc3df" class="outline-4">
<h4 id="orgf6fc3df"><span class="section-number-4">2.7.1</span> <span class="todo TODO">TODO</span> <a href="https://www-google-com.ezproxy.cul.columbia.edu/patents/US5796948">Patent US5796948 - Offensive message interceptor for computers - Google Patents</a></h4>
</div>
<div id="outline-container-orgcee3e04" class="outline-4">
<h4 id="orgcee3e04"><span class="section-number-4">2.7.2</span> <span class="todo TODO">TODO</span> <a href="https://www-google-com.ezproxy.cul.columbia.edu/patents/US8868408">Patent US8868408 - Systems and methods for word offensiveness processing using aggregated &#x2026; - Google Patents</a></h4>
</div>
<div id="outline-container-org978add9" class="outline-4">
<h4 id="org978add9"><span class="section-number-4">2.7.3</span> <span class="todo TODO">TODO</span> <a href="https://www-google-com.ezproxy.cul.columbia.edu/patents/US8473443">Patent US8473443 - Inappropriate content detection method for senders - Google Patents</a></h4>
</div>
<div id="outline-container-orga8b327e" class="outline-4">
<h4 id="orga8b327e"><span class="section-number-4">2.7.4</span> <span class="todo TODO">TODO</span> <a href="https://www-google-com.ezproxy.cul.columbia.edu/patents/US7818764">Patent US7818764 - System and method for monitoring blocked content - Google Patents</a></h4>
</div>
<div id="outline-container-orgd86fc6a" class="outline-4">
<h4 id="orgd86fc6a"><span class="section-number-4">2.7.5</span> <span class="todo TODO">TODO</span> <a href="https://www-google-com.ezproxy.cul.columbia.edu/patents/US20080109214">Patent US20080109214 - System and method for computerized psychological content analysis of &#x2026; - Google Patents</a></h4>
</div>

<div id="outline-container-org7937126" class="outline-4">
<h4 id="org7937126"><span class="section-number-4">2.7.6</span> <span class="todo TODO">TODO</span> <a href="https://www.google.com/patents/US20110191105">Patent US20110191105 - Systems and Methods for Word Offensiveness Detection and Processing Using &#x2026; - Google Patents</a></h4>
</div>
</div>
</div>
<div id="outline-container-orgf779602" class="outline-2">
<h2 id="orgf779602"><span class="section-number-2">3</span> Problems, Topics</h2>
<div class="outline-text-2" id="text-3">
</div><div id="outline-container-orgbb1d203" class="outline-3">
<h3 id="orgbb1d203"><span class="section-number-3">3.1</span> Censorship policies of social media companies</h3>
</div>
<div id="outline-container-org898e6c0" class="outline-3">
<h3 id="org898e6c0"><span class="section-number-3">3.2</span> Flagging</h3>
<div class="outline-text-3" id="text-3-2">
</div><div id="outline-container-orgad43a3a" class="outline-4">
<h4 id="orgad43a3a"><span class="section-number-4">3.2.1</span> <span class="todo TODO">TODO</span> "What is a Flag for? Social Media Reporting Tools and the Vocabulary of Complaint" <a class='org-ref-reference' href="#crawford_what_2016">crawford_what_2016</a></h4>
</div>
<div id="outline-container-orgf754c6b" class="outline-4">
<h4 id="orgf754c6b"><span class="section-number-4">3.2.2</span> <span class="todo TODO">TODO</span> Reporting, Reviewing, and Responding to Harassment on Twitter. <a class='org-ref-reference' href="#matias_reporting_2015">matias_reporting_2015</a></h4>
</div>
<div id="outline-container-org7396263" class="outline-4">
<h4 id="org7396263"><span class="section-number-4">3.2.3</span> <span class="todo TODO">TODO</span> <a href="http://www.cpeterson.org/2013/07/22/a-brief-guide-to-user-generated-censorship/">A Brief Guide To User-Generated Censorship - Chris Peterson</a></h4>
</div>
</div>
<div id="outline-container-orgfd6aaab" class="outline-3">
<h3 id="orgfd6aaab"><span class="section-number-3">3.3</span> Counterspeech, Moderation</h3>
<div class="outline-text-3" id="text-3-3">
</div><div id="outline-container-orgd018bcc" class="outline-4">
<h4 id="orgd018bcc"><span class="section-number-4">3.3.1</span> <span class="done DONE">DONE</span> "Vectors for Counterspeech on Twitter" <a class='org-ref-reference' href="#wright_vectors_2017">wright_vectors_2017</a></h4>
<div class="outline-text-4" id="text-3-3-1">
<dl class="org-dl">
<dt>counterspeech</dt><dd>"a direct response to hateful or harmful speech" 57</dd>
</dl>

<p>
Counterpseech "can exhibit a number of different communicative strategies including humor, emotional appeals, multi-stage dialog, and over verbal attack itself" 58
</p>
<ul class="org-ul">
<li>"an empathetic and/or kind tone, use of images, and use of humor" 59</li>
<li>"no indication that these forms are templated" 58</li>
</ul>

<p>
Identify one-to-one counterspeech, many-to-one, and many-to-many
</p>

<p>
"The blog “Racists Getting Fired” made a practice of punishing people who posted racist content by contacting their employers and, similarly, demanding that they be fired (McDonald, 2014). Such responses are no doubt successful at changing the online speech of their targets, but may only harden the hateful convictions of those targets,
and constitute online mob justice." 60
</p>
</div>
<ol class="org-ol"><li><a id="orgca657bd"></a><a href="https://www.washingtonpost.com/news/morning-mix/wp/2014/12/02/racists-getting-fired-exposes-weaknesses-of-internet-vigilantism-no-matter-how-well-intentioned/">‘Racists Getting Fired’ exposes weaknesses of Internet vigilantism, no matter how well-intentioned - The Washington Post</a><br /></li></ol>
</div>

<div id="outline-container-orgd89eacb" class="outline-4">
<h4 id="orgd89eacb"><span class="section-number-4">3.3.2</span> <span class="todo TODO">TODO</span> "The Virtues of Moderation" <a class='org-ref-reference' href="#grimmelmann_virtues_2015">grimmelmann_virtues_2015</a></h4>
</div>
<div id="outline-container-org4ee35f2" class="outline-4">
<h4 id="org4ee35f2"><span class="section-number-4">3.3.3</span> <span class="todo TODO">TODO</span> "Slash (dot) and burn: distributed moderation in a large online conversation space" <a class='org-ref-reference' href="#lampe_slash_2004">lampe_slash_2004</a></h4>
</div>
<div id="outline-container-orgd6823fd" class="outline-4">
<h4 id="orgd6823fd"><span class="section-number-4">3.3.4</span> <span class="todo TODO">TODO</span> <a href="https://link.springer.com/article/10.1007/s11109-016-9373-5">Tweetment Effects on the Tweeted: Experimentally Reducing Racist Harassment | SpringerLink</a></h4>
</div>
</div>
<div id="outline-container-org836d750" class="outline-3">
<h3 id="org836d750"><span class="section-number-3">3.4</span> Cross-cultural studies</h3>
<div class="outline-text-3" id="text-3-4">
</div><div id="outline-container-orgf39c68f" class="outline-4">
<h4 id="orgf39c68f"><span class="section-number-4">3.4.1</span> <span class="todo TODO">TODO</span> "Rephrasing Profanity in Chinese Text" <a class='org-ref-reference' href="#su_rephrasing_2017">su_rephrasing_2017</a></h4>
</div>
<div id="outline-container-org9d8835b" class="outline-4">
<h4 id="org9d8835b"><span class="section-number-4">3.4.2</span> <span class="todo TODO">TODO</span> "Legal Framework, Dataset and Annotation Schema for Socially Unacceptable Online Discourse Practices in Slovene" <a class='org-ref-reference' href="#fiser_legal_2017">fiser_legal_2017</a></h4>
</div>
<div id="outline-container-org490e4f8" class="outline-4">
<h4 id="org490e4f8"><span class="section-number-4">3.4.3</span> <span class="todo TODO">TODO</span> "Abusive Language Detection on Arabic Social Media" <a class='org-ref-reference' href="#mubarak_abusive_2017">mubarak_abusive_2017</a></h4>
</div>
</div>
<div id="outline-container-org4d20707" class="outline-3">
<h3 id="org4d20707"><span class="section-number-3">3.5</span> Troll detection / troll bots / misinformation bots</h3>
<div class="outline-text-3" id="text-3-5">
</div><div id="outline-container-org7ccca83" class="outline-4">
<h4 id="org7ccca83"><span class="section-number-4">3.5.1</span> At least 10% of #gamergate tweets have bot OSes (see below)</h4>
</div>
<div id="outline-container-org0407e72" class="outline-4">
<h4 id="org0407e72"><span class="section-number-4">3.5.2</span> <span class="done DONE">DONE</span> Tweet: <a href="https://twitter.com/conspirator0/status/900158823515770880">A pattern you may have noticed: many bot and troll accounts have usernames that end in 8 random digits.</a></h4>
<div class="outline-text-4" id="text-3-5-2">
</div>
</div>
<div id="outline-container-org7ce73d9" class="outline-4">
<h4 id="org7ce73d9"><span class="section-number-4">3.5.3</span> <span class="done DONE">DONE</span> <a href="https://www.twitteraudit.com/">Twitter Audit | How many of your followers are real?</a></h4>
<div class="outline-text-4" id="text-3-5-3">
<ul class="org-ul">
<li>Service that tries to detect whether your followers are real people.</li>
<li>How does it work?</li>
</ul>
</div>
</div>
<div id="outline-container-org85524e7" class="outline-4">
<h4 id="org85524e7"><span class="section-number-4">3.5.4</span> <span class="todo TODO">TODO</span> "Exposing Paid Opinion Manipulation Trolls" <a class='org-ref-reference' href="#mihaylov_exposing_2015">mihaylov_exposing_2015</a></h4>
<div class="outline-text-4" id="text-3-5-4">
<p>
Abstract: "We solve the training data problem by assuming that a user who is called a <i>troll</i> by several different people is likely to be such" 
</p>

<p>
Data: 
</p>
<ul class="org-ul">
<li>Scraped comments from the largest Bulgarian newspaper website (445)</li>
<li>Requires users to be logged in</li>
</ul>

<p>
Features that distinguish between paid trolls and non-trolls: 
</p>
<ul class="org-ul">
<li>day of week: F-score of 0.89</li>
<li>reply status: 0.75</li>
<li>time in hours: 0.75</li>
</ul>

<p>
Results: 
</p>
<ul class="org-ul">
<li>"Overall, paid trolls looked roughly like the 'mentioned' trolls, except that they were posting most of their comments on working days and during working hours."</li>
<li>Paid trolls are more successful at upsetting people (negative votes from other users were correlated)</li>
</ul>
</div>
</div>

<div id="outline-container-orga88e3ad" class="outline-4">
<h4 id="orga88e3ad"><span class="section-number-4">3.5.5</span> <span class="todo TODO">TODO</span> "Finding Opinion Manipulation Trolls in News Community Forums" <a class='org-ref-reference' href="#mihaylov_finding_2015">mihaylov_finding_2015</a></h4>
</div>
<div id="outline-container-org33413f5" class="outline-4">
<h4 id="org33413f5"><span class="section-number-4">3.5.6</span> <span class="todo TODO">TODO</span> "Propagation of trust and distrust for the detection of trolls in a social network" <a class='org-ref-reference' href="#ortega_propagation_2012">ortega_propagation_2012</a></h4>
</div>
<div id="outline-container-org098f14b" class="outline-4">
<h4 id="org098f14b"><span class="section-number-4">3.5.7</span> <span class="todo TODO">TODO</span> "Accurately detecting trolls in slashdot zoo via decluttering" <a class='org-ref-reference' href="#kumar_accurately_2014">kumar_accurately_2014</a></h4>
</div>
<div id="outline-container-org53a0a88" class="outline-4">
<h4 id="org53a0a88"><span class="section-number-4">3.5.8</span> <span class="todo TODO">TODO</span> "Assessing trust: contextual accountability" <a class='org-ref-reference' href="#rowe_assessing_2009">rowe_assessing_2009</a></h4>
</div>
<div id="outline-container-orga54cf2c" class="outline-4">
<h4 id="orga54cf2c"><span class="section-number-4">3.5.9</span> <span class="todo TODO">TODO</span> "Filtering offensive language in online communities using grammatical relations" <a class='org-ref-reference' href="#xu_filtering_2010">xu_filtering_2010</a></h4>
</div>
<div id="outline-container-org2cf1154" class="outline-4">
<h4 id="org2cf1154"><span class="section-number-4">3.5.10</span> <span class="todo TODO">TODO</span> "Offensive language detection using multi-level classification" <a class='org-ref-reference' href="#razavi_offensive_2010">razavi_offensive_2010</a></h4>
</div>
</div>
<div id="outline-container-org15d2d2e" class="outline-3">
<h3 id="org15d2d2e"><span class="section-number-3">3.6</span> Automated Detection</h3>
<div class="outline-text-3" id="text-3-6">
</div><div id="outline-container-org5dea352" class="outline-4">
<h4 id="org5dea352"><span class="section-number-4">3.6.1</span> Of high-quality contributions</h4>
<div class="outline-text-4" id="text-3-6-1">
</div><ol class="org-ol"><li><a id="orga0515a9"></a><span class="done DONE">DONE</span> "How Useful are Your Comments?- Analyzing and Predicting YouTube Comments and Comment Ratings" <a class='org-ref-reference' href="#siersdorfer_how_2010">siersdorfer_how_2010</a><br /><div class="outline-text-5" id="text-3-6-1-1">
<ul class="org-ul">
<li>"Can we predict the community feedback for comments?" 892</li>
<li>"automatically generated content ratings might help to identify users showing malicious behavior such as spammers and trolls at an early stage, and, in the future, might lead to methods for recommending to an individual user of the system other users with similar interests and points of views." 892</li>
<li>use 6.1M comments from 67K videos 893
<ul class="org-ul">
<li>mean # comments 475</li>
</ul></li>
<li>distribution of comment ratings skews positive, with mean of 0.61</li>
<li>find MDWs for comments with high, low ratings
<ul class="org-ul">
<li>low rating MDWs contain racial, gender slurs, obscenities</li>
</ul></li>
<li>sentiment analysis shows correlation between machine-detected sentiment and ratings
<ul class="org-ul">
<li>use SentiWordNet thesaurus</li>
</ul></li>
<li>use SVM classifiers to predict categories 
<ul class="org-ul">
<li>predictably, the classifier works best on high and low ratings, not as well on comments with neutral ratings</li>
</ul></li>
<li>test "variance of comment ratings as indicator for polarizing videos"
<ul class="org-ul">
<li>find MDWS for polarizing and non-polarizing videos.</li>
<li>high comment rating variance MDWS include political terms, terms relating to religion</li>
<li>low comment rating variance MDWs include sports-, hobby-, and tax-related terms</li>
</ul></li>
<li>"Politics videos have significantly more negatively rated comments than any other category. Music videos, on the other hand, have a clear majority of positively rated comments."</li>
<li>Music has the highest mean comment rating, science and automotive videos the lowest.
<ul class="org-ul">
<li>Mean sentivalues across categories also correlate, with music showing the highest mean, and autos, gaming, science the with the lowest mean.</li>
</ul></li>
</ul>
</div></li>
<li><a id="org325e23b"></a><span class="done DONE">DONE</span> "The Editor's Eye: Curation and Comment Relevance on the New York Times" <a class='org-ref-reference' href="#diakopoulos_editors_2015">diakopoulos_editors_2015</a><br /><div class="outline-text-5" id="text-3-6-1-2">
<p>
"explores the manifestation of editorial quality criteria in comments that have been curated and selected on the New York Times website as “NYT Picks.” The relationship between comment selection and comment relevance is examined through the analysis of 331,785 comments, including 12,542 editor’s selections. A robust association between editorial selection and article relevance or conversational relevance was found." 
</p>

<p>
"Could new computational tools be used to reduce the amount of time journalists need to spend doing this curatorial work, to identify worthy but overlooked contributions, or to scale their ability to consider more content?" 
</p>

<p>
NYT comment moderation: 
</p>
<ul class="org-ul">
<li>pre-moderate comments</li>
<li>assign "NYT Picks" badge to good comments</li>
</ul>

<p>
Preprocessing: tokenize, normalize, stopword filter, and stem
</p>
<ul class="org-ul">
<li>reduce the vocabulary to 22,837 features</li>
<li>transform into tf-idfs</li>
<li>analyze cosine similarity between comments and articles</li>
</ul>

<p>
Find that "the article relevance of the comment is positively associated with a higher chance of it being selected by an editor." 
</p>

<p>
"There was a slight negative correlation between elapsed time and whether the comment was an editor’s selection (Spearman rho = -0.048, p = 0). Thus, there are less editor’s selections later in the conversation." 3 
</p>

<p>
"Comments made in the first hour have a distinctly higher article relevance than in the immediately subsequent hours. But after about 18 hours the average article relevance begins increasing again up to hour 48" 3
</p>

<p>
This article seems to assume that tf-idf cosine similarity can be directly interpreted as "relevance." 
</p>
<ul class="org-ul">
<li>It's possible that a very relevant comment contains very few of the words used in the article, and would then be computationally considered irrelevant.</li>
</ul>
</div></li>

<li><a id="orgd35b731"></a><span class="done DONE">DONE</span> "Predicting information credibility in time-sensitive social media"  <a class='org-ref-reference' href="#castillo_predicting_2013">castillo_predicting_2013</a><br /><div class="outline-text-5" id="text-3-6-1-3">
<ul class="org-ul">
<li>supervised categorization of "credible" and non-credible tweet groups or "information cascades"</li>
<li>study propogation of tweets, tweet "affirmations," "questions," and other reactions</li>
<li>use data set of manually-labeled (Amazon Turk) tweets as "likely to be true," etc.</li>
<li>best 8 features that distinguish between "NEWS" and "CHAT" (discussion) labels: (573) 
<ul class="org-ul">
<li>! "fraction of authors in the topic that have written a self-description (“bio” in Twitter terms)"</li>
<li>"count of distinct URLs"</li>
<li>"fraction of URLs pointing to domains in the top 100 most visited domains on the web"</li>
<li>"average length of the tweets"</li>
<li>"count of distinct user mentions"</li>
<li>"fraction of tweets containing a hashtag"</li>
<li>"fraction of tweets containing a “frowning” emoticon"</li>
<li>"maximum depth of propagation trees"</li>
</ul></li>
<li>test clustering/classification methods, find that Random Forest classifies best.</li>
<li>best features that distinguish between "credible" and "not credible" labels: (575) 
<ul class="org-ul">
<li>the average number of tweets posted by authors of the tweets in the topic in the past</li>
<li>the average number of followers of authors posting these tweets</li>
<li>the fraction of tweets having a positive sentiment</li>
<li>the fraction of tweets having a negative sentiment</li>
<li>the fraction of tweets containing a URL that contain the most frequent URL</li>
<li>the fraction of tweets containing a URL</li>
<li>the fraction of URLs pointing to a domain among the top 10,000 most visited</li>
<li>the fraction of tweets containing a user mention;</li>
<li>the average length of the tweets;</li>
<li>the fraction of tweets containing a question mark;</li>
<li>the fraction of tweets containing an exclamation mark;</li>
<li>the fraction of tweets containing a question or an exclamation mark;</li>
<li>the fraction of tweets containing a “smiling” emoticons;</li>
<li>the fraction of tweets containing a first-person pronoun;</li>
<li>the fraction of tweets containing a third-person pronoun; and</li>
<li>the maximum depth of the propagation trees.</li>
</ul></li>
<li>test clustering methods, find that logistic regression classifies with ~80% accuracy</li>
</ul>
</div></li>

<li><a id="org35ba277"></a><span class="done DONE">DONE</span> "Constructive Language in News Comments" <a class='org-ref-reference' href="#kolhatkar_constructive_2017">kolhatkar_constructive_2017</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /><div class="outline-text-5" id="text-3-6-1-4">
<ul class="org-ul">
<li>create a custom annotated corpus 
<ul class="org-ul">
<li>crowdsource the annotation of comments as "constructive" or not (12)</li>
<li>"Out of the 1,121 comments, 603 comments (53.79%) were classified as constructive, 517 (46.12%) as non-constructive, and the annotators were not sure in only one case." (12)</li>
<li><a href="https://github.com/sfu-discourse-lab/Constructiveness_Toxicity_Corpus">corpus available on GitHub</a></li>
<li>also use Yahoo News Annotated Corpus and Argument Extraction Corpus</li>
</ul></li>
<li>train a Bi-directional Long Short-Term Memory model (biLSTM) (implemented in TensorFlow)
<ul class="org-ul">
<li>make word vectors for each word, using GloVe vectors</li>
<li>categorization is about 72% precise</li>
</ul></li>
<li>features with strong correlation with constructiveness: 
<ul class="org-ul">
<li>"argumentative discourse relations"</li>
<li>"stance adverbials (e.g., undoubtedly, paradoxically, of course)"</li>
<li>"reasoning verbs (e.g., cause, lead)"</li>
<li>modals</li>
</ul></li>
<li>crowdsource annotation of comments as "toxic" or not on a scale
<ul class="org-ul">
<li>"constructiveness and toxicity are orthogonal categories."</li>
</ul></li>
</ul>
</div></li>
<li><a id="orgc132114"></a><span class="done DONE">DONE</span> "Finding high-quality content in social media" <a class='org-ref-reference' href="#agichtein_finding_2008">agichtein_finding_2008</a><br /><div class="outline-text-5" id="text-3-6-1-5">
<ul class="org-ul">
<li>study a Yahoo Answers corpus</li>
<li>express "high quality content" through user reputation, 
<ul class="org-ul">
<li>calculated through graph-based algorithms like PageRank, HITS, ExpertiseRank</li>
</ul></li>
<li>features: "all word n-grams up to length 5 that appear in the collection more than 3 times used as features."
<ul class="org-ul">
<li>also add as features POS representations of n-grams
<ul class="org-ul">
<li>! "Some part-of-speech sequences are typical of correctly- formed questions: e.g., the sequence “when|how|why to (verb)” (as in “how to identify. . . ”) is typical of lower-quality ques- tions, whereas the sequence “when|how|why (verb) (personal pronoun) (verb)” (as in “how do I remove. . . ”) is more typical of correctly-formed content."</li>
</ul></li>
<li>use formality score of <a class='org-ref-reference' href="#heylighen_variation_2002">heylighen_variation_2002</a></li>
</ul></li>
<li>classifier: stochastic gradient boosted trees
<ul class="org-ul">
<li>"A particularly useful aspect of boosted trees for our settings is their ability to utilize combinations of sparse and dense features." (187)</li>
</ul></li>
<li>relevance scores: "To represent this we include the KL-divergence between the language models of the two texts, their non-stopword overlap, the ratio between their lengths, and other similar features."
<ul class="org-ul">
<li>measure "non-stopword word overlap between question and answer"; this is one of their answer features</li>
</ul></li>
<li>readability: Kincaid score is an answer feature</li>
</ul>
</div>
<ol class="org-ol"><li><a id="org6d04d32"></a>20 most signification question quality features:<br /><div class="outline-text-6" id="text-3-6-1-5-1">
<ul class="org-ul">
<li>Average number of ”stars” to questions by the same asker; the punctuation density in the question’s subject; the question’s category (assigned by the asker).; “Normalized Clickthrough:” The number of clicks on the question thread, normalized by the average number of clicks for all questions in its category.; Average number of ”Thumbs up” received by answers written by the asker of the current question.; Number of words per sentence.; Average number of answers with references (URLs) given by the asker of the current question.; Fraction of questions asked by the asker in which he opens the question’s answers to voting (instead of pick- ing the best answer by hand).; Average length of the questions by the asker; the number of “best answers” authored by the user; the number of days the user was active in the system.; “Thumbs up” received by the answers wrote by the asker of the current question, minus “thumbs down”, divided by total number of “thumbs” received.; “Clicks over Views:” The number of clicks on a question thread divided by the number of times the question thread was retrieved as a search result (see [2]); the KL-divergence between the question’s language model and a model estimated from a collection of question answered by the Yahoo editorial team (available in <a href="http://ask.yahoo.com">http://ask.yahoo.com</a>); the fraction of words that are not in the list of the top-10 words in the collection, ranked by frequency; the number of “capitalization errors” in the question (e.g., sentence not starting with a capitalized word); the number of days that has passed since the asker wrote his/her first question or answer in the system; the total number of answers of the asker that have been selected as the “best answer”; the number of questions that the asker has asked in its most active category, over the total number of questions that the asker has asked; the entropy of the part-of-speech tags of the question.</li>
</ul>
</div></li>
<li><a id="orgbf9d68d"></a>20 most significant answer features:<br /><div class="outline-text-6" id="text-3-6-1-5-2">
<ul class="org-ul">
<li>Answer length; The number of words in the answer with a corpus frequency larger than c; the number of “thumbs up” minus “thumbs down” received by the answerer, divided by the total number of “thumbs” s/he has received.; the entropy of the trigram character-level model of the answer; the fraction of answers of the answerer that have been picked as best answers (either by the askers of such questions, or by a community voting); The unique number of words in the answer; average number of abuse reports received by the answerer over his/her answers ;</li>
<li>The non-stopword word overlap between the question and the answer.</li>
<li>∅ The Kincaid [21] score of the answer.</li>
<li>The average number of answers received by the questions asked by the asker of this answer; the ratio between the length of the question and the length of the answer; the number of “thumbs up” minus “thumbs down” received by the answerer; the average numbers of “thumbs” received by the answers to other questions asked by the asker of this answer; the entropy of the unigram character-level model of the answer; the KL-divergence between the answer’s language model and a model estimated from the Wikipedia discussion pages; number of abuse reports received by the asker of the question being answered; the sum of the lengths of all the answers received by the asker of the question being answered; the sum of the “thumbs down” received by the answers received by the asker of the question being answered; the average number of answers with votes in the questions asked by the asker of the question being answered</li>
</ul>
</div></li></ol></li>

<li><a id="org7e524e5"></a><span class="done DONE">DONE</span> "How opinions are received by online communities: a case study on amazon.com helpfulness votes" <a class='org-ref-reference' href="#danescu-niculescu-mizil_how_2009">danescu-niculescu-mizil_how_2009</a><br /><div class="outline-text-5" id="text-3-6-1-6">
<p>
Study of Amazon.com reviews and evaluations of those reviews ("24 out of 25 people found this review helpful"). 
</p>

<p>
"We find that the perceived helpfulness of a review depends not just on its content but also but also in subtle ways on how the expressed evaluation relates to other evaluations of the same product." 1
</p>

<p>
Three-party concerns: "Rather than asking questions of the form “What did Y think of X?”, we are asking, “What did Z think of Y’s opinion of X?” Crucially, there are now three entities in the process rather than two." 1
</p>
<ul class="org-ul">
<li>! "Heider’s theory of structural balance in social psychology seeks to understand subjective relationships by considering sets of three entities at a time as the basic unit of analysis."</li>
</ul>

<p>
! "A significant and particularly wide-ranging set of effects is based on the relationship of a review’s star rating to the star ratings of other reviews for the same product. We view these as fundamentally social effects, given that they are based on the relationship of one user’s opinion to the opinions expressed by others in the same setting." 
</p>

<p>
Dataset: "over four million reviews of roughly 675,000 books on Amazon’s U.S. site, as well as smaller but comparably- sized corpora from Amazon’s U.K., Germany, and Japan sites"
</p>

<p>
Test four hypotheses (2): 
</p>
<ul class="org-ul">
<li>"conformity hypothesis" that reviews are considered more helpful if their star ratings are close to the average</li>
<li>"individual-bias hypothesis" that users like reviews that agree with their opinions</li>
<li>"brilliant-but-cruel hypothesis" that users assume low reviews correlate with intelligence</li>
<li>"quality-only" hypothesis that ratings correlate with textual quality</li>
</ul>

<p>
! find that helpfulness ratio inversely proportional to star rating
</p>
<ul class="org-ul">
<li>reviews "punished asymmetrically: slightly negative reviews are punished more strongly&#x2026;than slightly positive reviews"</li>
<li>"it is not simply that closeness to the average is rewarded; among reviews that are slightly away from the mean, there is a bias toward overly positive ones" 3</li>

<li>find generally that "conformity hypothesis" is true, except when variance in star ratings is high</li>

<li>find that, cross-culturally, these findings hold true</li>

<li>they "control for text" by looking at helpfulness ratings of identical reviews 3, find that their observed effect holds true regardless</li>
</ul>
</div></li>

<li><a id="orga6a4e8e"></a><span class="done DONE">DONE</span> "Variation in the contextuality of language: An empirical measure." <a class='org-ref-reference' href="#heylighen_variation_2002">heylighen_variation_2002</a><br /><div class="outline-text-5" id="text-3-6-1-7">
<p>
From abstract: "An empirical measure of this variation is proposed, the 'formality' or 'F-score', based on the frequencies of different word classes. Nouns, adjectives, articles and prepositions are more frequent in low-context or 'formal' types of expression; pronouns, adverbs, verbs and interjections are more frequent in high-context styles."
</p>

<p>
Uses anthropologist Edward T. Hall's definition of "high-context" and "low-context" situations. 
</p>
<ul class="org-ul">
<li>high-context: communication is implicit</li>
<li>low-context: communication is more explicit and overt</li>
<li>"the association of context with specific cultures seems to imply that the degree of context, dependence is merely the result of historical accidents or of idiosyncratic differences between ethnicities"</li>
</ul>

<p>
Define a "formality/contextuality continuum" in which "the opposite of contextuality may be called 'formality'" 298
</p>
<ul class="org-ul">
<li>yet differentiate between "deep formality," which aims to be explicit and avoid ambiguity, and "surface formality," which is "ceremonial or required by convention."</li>
</ul>

<p>
! Argue that "completely unambiguous description is impossible" (300), citing Gödel's incompleteness theorem and Heisenberg's uncertainty principle
</p>

<p>
And textual genres: "we expect contextuality to be lowest in the more static, intellectual or informational forms of expression &#x2026; this includes official, legal, technical or scientific documents &#x2026; We expect contextuality to be highest in the more interactive and personal communication situations &#x2026; this includes relaxed conversations, dialogues, &#x2026; and personal letters." 302
</p>

<p>
Divides lexicon into more and less context-dependent classes: 
</p>
<ul class="org-ul">
<li>deictic words ("we," "him," "my," "here," "upstairs," "however") 306
<ul class="org-ul">
<li>pronouns, adverbs, and interjections</li>
</ul></li>
<li>non-deictic words: most nouns and adjectives
<ul class="org-ul">
<li>nouns, adjectives, and prepositions</li>
</ul></li>
</ul>

<p>
F = (noun frequency + adjective freq. + preposition freq. + article freq. - pronoun freq. - verb freq. - adverb freq. - interjection freq. + 100)/2
</p>

<p>
Using a corpus with varying degrees of formality: 
</p>
<ul class="org-ul">
<li>F-scores: 44 (conversation), 54 (oral examination), 56 (essay)</li>
</ul>

<p>
Find that: 311
</p>
<ul class="org-ul">
<li>those with academic degrees score higher (44 vs. 40)</li>
<li>men higher than women (42 vs. 39)</li>
</ul>

<p>
Italian genres: 
</p>
<ul class="org-ul">
<li>movies, theater: 48, 52</li>
<li>novels: 58-64</li>
<li>newspapers and magazines: 66-71</li>
<li>essays, science 69, 72</li>
</ul>

<p>
French: 
</p>
<ul class="org-ul">
<li>"interview with a call-girl": 45</li>
<li>"interview with the president": 52</li>
<li>"an address to the nation by the president": 58</li>
<li>"an article in an intellectual newspaper": 78</li>
</ul>

<p>
Use factor analysis to find significant factors to explain variation
</p>

<p>
On integrating contextual information: "Following Levelt's (1989) classification of linguistic deixis, we can distinguish four categories of context factors: the <i>persons</i> involved, the <i>space</i> or setting of the communication, the <i>time</i>, and the <i>discourse</i> preceding the present expression." 324 
</p>
<ul class="org-ul">
<li>"the larger the difference in psychological or cultural background [between people communicating] the higher the formality of their communication" 324</li>
<li>"the more different the <i>spatial setting</i> for sender and receiver, the smaller the shared context"</li>
<li>"the longer the <i>time span</i> between sending and receiving, the less will remain of the original context" [and thus higher formality]</li>
</ul>

<p>
"the degree of extroversion was found to have a significant negative correlation with the explicitness factor measuring formality." 331-2
</p>
</div></li>

<li><a id="orgd464591"></a><span class="done DONE">DONE</span> "Comment classification for an online news domain." <a class='org-ref-reference' href="#brand_comment_2014">brand_comment_2014</a><br /><div class="outline-text-5" id="text-3-6-1-8">
<p>
"Through investigation of supervised learning techniques, we show that content-based features better serves as a predictor of popularity, while quality-based features are better suited for predicting user engagement." 50
</p>

<p>
Test "quality-based features" and "content-based features"
</p>

<p>
Quality-based features: 
</p>
<ul class="org-ul">
<li>response time of user's comment</li>
<li>length of comment</li>
<li>uppercase frequency</li>
<li>question mark / exclamation mark frequency</li>
</ul>

<p>
Lexical features: 
</p>
<ul class="org-ul">
<li>entropy of words in the comment: [is this just TR?]</li>
<li>spelling</li>
<li>profanity</li>
<li>"informativeness": "how unique a comment is within its thread" (TF-IDF)</li>
<li>"relevance": set intersection of words between comment and article</li>
</ul>

<p>
Social features: 
</p>
<ul class="org-ul">
<li>sentiment analysis</li>
<li>"subjectivity" (neutrality of sentiment analysis, defined as between 45-50% sentiment)</li>
<li>"engagement": number of child comments</li>
</ul>

<p>
Use linear regression and support vector regression; 
</p>

<p>
Find that content-based features outperform quality-based features in predicting comment votes, but quality + content features outperforms both. 
</p>
<ul class="org-ul">
<li>But: "This could be attributed to biased voting patterns in the community, eg. users that would “like” a comment multiple times if it supports their viewpoint (politically, religiously, or otherwise), but not necessarily evaluate the comment’s quality." 55</li>
<li>"The quality-based features are, however, better suited for predicting the engagement a comment will receive from users in a comment thread" 55</li>
</ul>
</div></li></ol>
</div>

<div id="outline-container-orga2c93fb" class="outline-4">
<h4 id="orga2c93fb"><span class="section-number-4">3.6.2</span> Of potentially abusive behavior</h4>
<div class="outline-text-4" id="text-3-6-2">
</div><ol class="org-ol"><li><a id="orgf7faf53"></a>Bullying<br /><ol class="org-ol"><li><a id="org5d45015"></a><span class="todo TODO">TODO</span> "Improved cyberbullying detection using gender information"  <a class='org-ref-reference' href="#dadvar_improved_2012">dadvar_improved_2012</a><br /></li>
<li><a id="orgf3b17c3"></a><span class="todo TODO">TODO</span> "Towards understanding cyberbullying behavior in a semi-anonymous social network" <a class='org-ref-reference' href="#hosseinmardi_towards_2014">hosseinmardi_towards_2014</a><br /></li>
<li><a id="org361a45e"></a><span class="todo TODO">TODO</span> "Let's gang up on cyberbullying" <a class='org-ref-reference' href="#lieberman_lets_2011">lieberman_lets_2011</a><br /></li>
<li><a id="org2a495c9"></a><span class="todo TODO">TODO</span> "A framework for cyberbullying detection in social network" <a class='org-ref-reference' href="#kansara_framework_2015">kansara_framework_2015</a><br /></li>
<li><a id="org6b94541"></a><span class="todo TODO">TODO</span> "Script-based story matching for cyberbullying prevention" <a class='org-ref-reference' href="#macbeth_script-based_2013">macbeth_script-based_2013</a><br /></li>
<li><a id="org8925d61"></a><span class="todo TODO">TODO</span> "Fast Learning for Sentiment Analysis on Bullying" <a class='org-ref-reference' href="#xu_fast_2012">xu_fast_2012</a><br /></li>
<li><a id="org6071672"></a><span class="todo TODO">TODO</span> "An examination of regret in bullying tweets" <a class='org-ref-reference' href="#xu_examination_2013">xu_examination_2013</a><br /></li>
<li><a id="org831a4bd"></a><span class="todo TODO">TODO</span> "Detection and fine-grained classification of cyberbullying events"  <a class='org-ref-reference' href="#van_hee_detection_2015">van_hee_detection_2015</a><br /></li>
<li><a id="orgedf031d"></a><span class="todo TODO">TODO</span> "Learning from bullying traces in social media" <a class='org-ref-reference' href="#xu_learning_2012">xu_learning_2012</a><br /></li>
<li><a id="org76290a8"></a><span class="todo TODO">TODO</span> "Cyberbullying detection: a step toward a safer internet yard" <a class='org-ref-reference' href="#dadvar_cyberbullying_2012">dadvar_cyberbullying_2012</a><br /></li>
<li><a id="org5b2545b"></a><span class="todo TODO">TODO</span> "Modeling the detection of Textual Cyberbullying" <a class='org-ref-reference' href="#dinakar_modeling_2011">dinakar_modeling_2011</a><br /></li>
<li><a id="orgeb435d9"></a><span class="todo TODO">TODO</span> "Detecting offensive language in social media to protect adolescent online safety." <a class='org-ref-reference' href="#chen_detecting_2012">chen_detecting_2012</a><br /></li>
<li><a id="org29bb136"></a><span class="todo TODO">TODO</span> "An effective approach for cyberbullying detection"  <a class='org-ref-reference' href="#nahar_effective_2013">nahar_effective_2013</a><br /></li></ol></li>
<li><a id="org93db2e0"></a><span class="done DONE">DONE</span> "Finding Deceptive Opinion Spam by Any Stretch of the Imagination" <a class='org-ref-reference' href="#ott_finding_2011">ott_finding_2011</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /><div class="outline-text-5" id="text-3-6-2-2">
<p>
"ultimately develop a classifier that is nearly 90% accurate on our gold-standard opinion spam dataset." 
</p>

<dl class="org-dl">
<dt>opinion spam</dt><dd>defined as "inappropriate or fraudulent reviews," usu. for monetary gain 1</dd>
<dt>deceptive opinion spam</dt><dd>"fictitious opinions that have been deliberately written to sound authentic, in order to deceive the reader." 1</dd>
</dl>

<p>
present public dataset of "gold-standard" deceptive reviews
</p>

<p>
Find that "a combined classifier with both n-gram and psychological deception features achieves nearly 90% cross-validated accuracy on this task. In contrast, we find deceptive opinion spam detection to be well beyond the capabilities of most human judges, who perform roughly at-chance" 
</p>

<p>
Dataset creation: 
</p>
<ul class="org-ul">
<li>! generate set of deceptive spam by hiring spammers on Mechanical Turk</li>
<li>generate "truthful opinions" by removing five-star reviews, reviews by first-time authors</li>
</ul>

<p>
Find that: 
</p>
<ul class="org-ul">
<li>"automated classifiers outperform human judges for every metric"</li>
<li>"deceptive opinions contain more superlatives"</li>
</ul>

<p>
"The combined model LIWC+BIGRMAS+SVM is 89.8% accurate at detecting deceptive opinion spam" 8
</p>

<p>
Qualities of truthful/deceptive language: 
</p>
<ul class="org-ul">
<li>"truthful opinions tend to include more sensorial and concrete language than deceptive opinions; in particular, truthful opinions are more specific about spatial configurations" 9</li>
<li>"we observe an increased focus in deceptive opinions on aspects external to the hotel being reviewed (e.g. husband, business, vacation)" 9</li>
</ul>

<p>
"We find that while standard n-gram-based text categorization is the best individual detection approach, a <i>combination</i> approach using psycholinguistically-motivated features and n-gram features can perform slighly better." 9
</p>
</div></li>

<li><a id="orge95bb2d"></a><span class="done DONE">DONE</span> "Automatic identification of personal insults on social news sites" <a class='org-ref-reference' href="#sood_automatic_2012">sood_automatic_2012</a><br /><div class="outline-text-5" id="text-3-6-2-3">
<p>
"Our training corpus is a set of comments from a news commenting site that we tasked Amazon Mechanical Turk workers with labeling. Each comment is labeled for the presence of profanity, insults, and the object of the insults." 
</p>

<p>
"we believe it is worthwhile to distinguish <i>off-topic negative comments</i> form <i>on-topic negative comments</i> that, while negative, are offered the spirit of debate." 1
</p>

<p>
"sentiment analysis is, in addition to being author, context and community-specific, a domain-specific problem" 
</p>
<ul class="org-ul">
<li>"for example, a 'cold' beverage is good while a 'cold' politician is bad" 3</li>
<li>"in order to build an accurate sentiment analysis system, you must have labeled training data from within the target domain." 3</li>
</ul>


<p>
Corpus: 1.6M comments from 234K users in 168K threads from <i>Yahoo! Buzz</i>, 2010
</p>
<ul class="org-ul">
<li>filter this for comments of length between 72 and 324 chars.</li>
</ul>

<p>
Label the data with help from Amazon Turk workers
</p>
<ul class="org-ul">
<li>throw out comments in which there was no consensus</li>
</ul>

<p>
use linear kernel support vector machines for classification, end up usin gmultistep classifier SVM 
</p>

<p>
find that genre (politics, entertainment, etc.) strongly affects categorizer accuracy, with news and politics having the lowest, and business and entertainment having the highest. 
</p>

<p>
find that "bigrams and stems using a presence representation performed best," at around 85% accuracy
</p>
<ul class="org-ul">
<li>"presence" here is binary presence of words, rather than their frequency</li>
<li>using this representation, they redo the analysis, but find that it doesn't improve categorization in all domains</li>
</ul>

<p>
Relevance + sentiment analysis: "Our approach combines relevance analysis for detecting off-topic comments with valence analysis methods for detecting negative comments." 
</p>
<ul class="org-ul">
<li>relevance: relevance is the sum of TF-IDF differences between words</li>
</ul>
</div></li>

<li><a id="orge723126"></a><span class="done DONE">DONE</span> "Using Convolutional Neural Networks to Classify Hate-Speech" <a class='org-ref-reference' href="#gamback_using_2017">gamback_using_2017</a><br /><div class="outline-text-5" id="text-3-6-2-4">
<p>
"The classifier assigns each tweet to one of four predefined categories: racism, sexism, both (racism and sexism) and non-hate-speech. Four Convolutional Neural Network models were trained on resp. character 4-grams, word vectors based on semantic information built using word2vec, randomly generated word vectors, and word vectors combined with character n-grams. The feature set was down-sized in the networks by max- pooling, and a softmax function used to classify tweets. Tested by 10-fold cross-validation, the model based on word2vec embeddings performed best, with higher precision than recall, and a 78.3% F-score." 
</p>

<p>
Corpus: use the English Twtiter hate-speech dataset created by <a class='org-ref-reference' href="#waseem_hateful_2016">waseem_hateful_2016</a> 
</p>

<p>
"following Waseem and Hovy (2016) only length 4 character n-grams were used. Clearly it would be interesting to explore whether these are uniformly ineffective when changing the n-gram size" 
</p>
</div></li>

<li><a id="orge6817fc"></a><span class="done DONE">DONE</span> "Detecting Nastiness in Social Media"  <a class='org-ref-reference' href="#samghabadi_detecting_2017">samghabadi_detecting_2017</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /><div class="outline-text-5" id="text-3-6-2-5">
<p>
Corpus scraped from ask.fm 
</p>
<ul class="org-ul">
<li>586K question-answer pairs</li>
<li>Ask.fm's anonymity "allows attackers the power to freely harass users by flooding their pages with profanity-laden questions and comments" 63
<ul class="org-ul">
<li>"Several teen suicides have been attributed to cyberbullying in ask.fm"</li>
</ul></li>
<li>"We crawl data containing profanities and then determine whether or not it contains invective. Annotations on this data are improved iteratively by in-lab annotations and crowdsourcing." 63
<ul class="org-ul">
<li>Crowdsourced annotation of corpus using CrowdFlower 65</li>
</ul></li>
</ul>

<p>
Bad words list: 
</p>
<ul class="org-ul">
<li>! "Bad words list" compiled from Google's bad words list and words listed in <a class='org-ref-reference' href="#hosseinmardi_towards_2014">hosseinmardi_towards_2014</a></li>
<li>"most of these bad words are often used in a casual way, so detecting cases in which there are potential invective requires careful feature engineering" 65</li>
</ul>

<p>
"We also show the robustness of our model by evaluating it on different data sets (Wikipeida Abusive Language Data Set, and Kaggle)." 
</p>
<ul class="org-ul">
<li>? Yet is this robustness a good thing? Shouldn't domain-specific models work better?</li>
</ul>

<p>
And spam: "Researchers have reported that cyberbullying posts are contextual, personalized, and creative, which make them harder to detect than detecting spam." 64
</p>

<p>
Final F-score of 59%
</p>

<p>
Data available at <a href="http://ritual.uh.edu/resources">http://ritual.uh.edu/resources</a>
</p>

<p>
Also test their system on Kaggle data 
</p>

<p>
Use supervised classification algorithm linear SVM 
</p>

<p>
Features: 
</p>
<ul class="org-ul">
<li>TF-IDF-weighted n-grams, char n-grams</li>
<li>! also k-skip n-grams ("to capture long-distance context")</li>
<li>Normalized count of emoticons</li>
<li>SentiWordNet scores on sentences</li>
<li>LIWC (Linguistic Inquiry and Word Count) categories
<ul class="org-ul">
<li>? Has anyone used WordNet hypernyms?</li>
</ul></li>
<li>LDA topics</li>
<li>Two types of Word embeddings: document vectors, and averaged word vectors</li>
<li>! patterns: "combination of lexical forms and POS tags"</li>
</ul>

<p>
Results: 
</p>
<ul class="org-ul">
<li>Best F-score AUC (area under curve) is 0.889 for Wikipedia data set;</li>
<li>performs with a F-score of 0.75 using all features</li>
</ul>

<p>
Poor performance with ask.fm, since they use shorter texts
</p>
</div></li>

<li><a id="orgd02f2fc"></a><span class="todo TODO">TODO</span> "Automated hate speech detection and the problem of offensive language." <a class='org-ref-reference' href="#davidson_automated_2017">davidson_automated_2017</a><br /></li>
<li><a id="orgfa2e6c3"></a><span class="todo TODO">TODO</span> "Hateful Symbols or Hateful People: Predictive features for hate speech detection on twitter" <a class='org-ref-reference' href="#waseem_hateful_2016">waseem_hateful_2016</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /></li>
<li><a id="orgf967ea6"></a><span class="todo TODO">TODO</span> "Abusive language detection in online user content" <a class='org-ref-reference' href="#nobata_abusive_2016">nobata_abusive_2016</a><br /></li>
<li><a id="org53a5524"></a><span class="todo TODO">TODO</span> "Detection of harassment on web 2.0" <a class='org-ref-reference' href="#yin_detection_2009">yin_detection_2009</a><br /></li>
<li><a id="orgad08674"></a><span class="todo TODO">TODO</span> "Impact of content features for automatic online abuse detection." <a class='org-ref-reference' href="#papegnies_impact_2017">papegnies_impact_2017</a><br /></li>
<li><a id="org3a2e1d7"></a><span class="todo TODO">TODO</span> "Ex machina: Personal attacks seen at scale." <a class='org-ref-reference' href="#wulczyn_ex_2017">wulczyn_ex_2017</a>&#xa0;&#xa0;&#xa0;<span class="tag"><span class="hasCorpus">hasCorpus</span></span><br /></li>
<li><a id="org08556f8"></a><span class="todo TODO">TODO</span> "Smokey: Automatic recognition of hostile messages" <a class='org-ref-reference' href="#spertus_smokey:_1997">spertus_smokey:_1997</a><br /></li>
<li><a id="org8de693f"></a><span class="todo TODO">TODO</span> "Measuring the reliability of hate speech annotations: The case of the European refugee crisis." <a class='org-ref-reference' href="#ross_measuring_2017">ross_measuring_2017</a><br /></li>
<li><a id="org21367bb"></a><span class="todo TODO">TODO</span> "Detecting offensive tweets via topical feature discovery over a large scale twitter corpus" <a class='org-ref-reference' href="#xiang_detecting_2012">xiang_detecting_2012</a><br /></li>
<li><a id="orgccf40bd"></a><span class="todo TODO">TODO</span> "Cross-Language Learning from Bots and Users to Detect Vandalism on Wikipedia" <a class='org-ref-reference' href="#tran_cross-language_2015">tran_cross-language_2015</a><br /></li>
<li><a id="org5f88670"></a><span class="todo TODO">TODO</span> "Mining for gold farmers: Automatic detection of deviant players in mmogs." <a class='org-ref-reference' href="#ahmad_mining_2009">ahmad_mining_2009</a><br /></li>
<li><a id="orgec28c42"></a><span class="todo TODO">TODO</span> "Don’t hate the player, hate the game: The racialization of labor in World of Warcraft." <a class='org-ref-reference' href="#nakamura_dont_2009">nakamura_dont_2009</a><br /></li>
<li><a id="org60ff81c"></a><span class="todo TODO">TODO</span> "Antisocial Behavior in Online Discussion Communities" <a class='org-ref-reference' href="#cheng_antisocial_2015">cheng_antisocial_2015</a><br /></li>
<li><a id="orgfabb124"></a><span class="todo TODO">TODO</span> "Deep Learning for User Comment Moderation" <a class='org-ref-reference' href="#pavlopoulos_deep_2017">pavlopoulos_deep_2017</a><br /></li>
<li><a id="orgcf021b2"></a><span class="todo TODO">TODO</span> "Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words" <a class='org-ref-reference' href="#serra_class-based_2017">serra_class-based_2017</a><br /></li>
<li><a id="org994e614"></a><span class="todo TODO">TODO</span> "One-step and Two-step Classification for Abusive Language Detection on Twitter" <a class='org-ref-reference' href="#park_one-step_2017">park_one-step_2017</a><br /></li>
<li><a id="org1b95e73"></a><span class="todo TODO">TODO</span> "Technology Solutions to Combat Online Harassment" <a class='org-ref-reference' href="#kennedy_iii_hack_2017">kennedy_iii_hack_2017</a><br /></li>
<li><a id="org435c2c8"></a><span class="todo TODO">TODO</span> "Understanding Abuse: A Typology of Abusive Language Detection Subtasks"  <a class='org-ref-reference' href="#waseem_understanding_2017">waseem_understanding_2017</a><br /></li>
<li><a id="orgbcc0d1d"></a><span class="todo TODO">TODO</span> "Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations" <a class='org-ref-reference' href="#palmer_illegal_2017">palmer_illegal_2017</a><br /></li>
<li><a id="orga46a39a"></a><span class="todo TODO">TODO</span> "Locate the hate: Detecting tweets against blacks." <a class='org-ref-reference' href="#kwok_locate_2013">kwok_locate_2013</a><br /></li>
<li><a id="org20bd4a9"></a><span class="todo TODO">TODO</span> "Hate speech detection with comment embeddings" <a class='org-ref-reference' href="#djuric_hate_2015">djuric_hate_2015</a><br /></li>
<li><a id="orgeb43552"></a><span class="todo TODO">TODO</span> "Analyzing the targets of hate in online social media" <a class='org-ref-reference' href="#silva_analyzing_2016">silva_analyzing_2016</a><br /></li></ol>
</div>

<div id="outline-container-org885213e" class="outline-4">
<h4 id="org885213e"><span class="section-number-4">3.6.3</span> Linguistic properties of abusive language</h4>
<div class="outline-text-4" id="text-3-6-3">
</div><ol class="org-ol"><li><a id="orgaa42ece"></a><span class="todo TODO">TODO</span> "Dimensions of Abusive Language on Twitter" <a class='org-ref-reference' href="#clarke_dimensions_2017">clarke_dimensions_2017</a><br /></li>
<li><a id="org1bcd3b2"></a><span class="todo TODO">TODO</span> "Abusive language detection in online user content" <a class='org-ref-reference' href="#nobata_abusive_2016">nobata_abusive_2016</a><br /></li></ol>
</div>
<div id="outline-container-orgf72e017" class="outline-4">
<h4 id="orgf72e017"><span class="section-number-4">3.6.4</span> Sentiment analysis</h4>
<div class="outline-text-4" id="text-3-6-4">
</div><ol class="org-ol"><li><a id="org6b618b6"></a><span class="todo TODO">TODO</span> "A survey of opinion mining and sentiment analysis"  <a class='org-ref-reference' href="#liu_survey_2012">liu_survey_2012</a><br /></li></ol>
</div>
<div id="outline-container-org5c600e3" class="outline-4">
<h4 id="org5c600e3"><span class="section-number-4">3.6.5</span> Of opinion spam</h4>
<div class="outline-text-4" id="text-3-6-5">
</div><ol class="org-ol"><li><a id="org595f1e8"></a><span class="todo TODO">TODO</span> "Opinion spam and analysis" <a class='org-ref-reference' href="#jindal_opinion_2008">jindal_opinion_2008</a><br /></li>
<li><a id="org4550f88"></a><span class="todo TODO">TODO</span> "Review spam detection" <a class='org-ref-reference' href="#jindal_review_2007">jindal_review_2007</a><br /></li>
<li><a id="orge0d705d"></a><span class="todo TODO">TODO</span> "Detecting group review spam"  <a class='org-ref-reference' href="#mukherjee_detecting_2011">mukherjee_detecting_2011</a><br /></li>
<li><a id="org074a2af"></a><span class="todo TODO">TODO</span> "Analyzing and detecting review spam" <a class='org-ref-reference' href="#jindal_analyzing_2007">jindal_analyzing_2007</a><br /></li>
<li><a id="orge2d2570"></a><span class="todo TODO">TODO</span> "Finding unusual review patterns using unexpected rules"  <a class='org-ref-reference' href="#jindal_finding_2010">jindal_finding_2010</a><br /></li>
<li><a id="org05827e5"></a><span class="todo TODO">TODO</span> "Detecting product review spammers using rating behavior" <a class='org-ref-reference' href="#lim_detecting_2010">lim_detecting_2010</a><br /></li>
<li><a id="org6c52878"></a><span class="todo TODO">TODO</span> "Distortion as a validation criterion in the identification of suspicious reviews" <a class='org-ref-reference' href="#wu_distortion_2010">wu_distortion_2010</a><br /></li>
<li><a id="orgd739332"></a><span class="todo TODO">TODO</span> "Comparison of deceptive and truthful travel reviews" <a class='org-ref-reference' href="#yoo_comparison_2009">yoo_comparison_2009</a><br /></li></ol>
</div>
</div>
<div id="outline-container-orgee57e92" class="outline-3">
<h3 id="orgee57e92"><span class="section-number-3">3.7</span> Psychology, Perception</h3>
<div class="outline-text-3" id="text-3-7">
</div><div id="outline-container-org9bd9246" class="outline-4">
<h4 id="org9bd9246"><span class="section-number-4">3.7.1</span> <span class="todo TODO">TODO</span> "The “Nasty Effect:” Online Incivility and Risk Perceptions of Emerging Technologies." <a class='org-ref-reference' href="#anderson_nasty_2014">anderson_nasty_2014</a></h4>
</div>
<div id="outline-container-org79ac00e" class="outline-4">
<h4 id="org79ac00e"><span class="section-number-4">3.7.2</span> <span class="todo TODO">TODO</span> "Newsworthiness and Network Gatekeeping on Twitter: The Role of Social Deviance" <a class='org-ref-reference' href="#diakopoulos_newsworthiness_2014">diakopoulos_newsworthiness_2014</a></h4>
</div>
<div id="outline-container-org89131e5" class="outline-4">
<h4 id="org89131e5"><span class="section-number-4">3.7.3</span> And (Computational/Quantitative) Psycholinguistics</h4>
<div class="outline-text-4" id="text-3-7-3">
</div><ol class="org-ol"><li><a id="orgade0261"></a><span class="done DONE">DONE</span> Labs<br /><div class="outline-text-5" id="text-3-7-3-1">
</div>
<ol class="org-ol"><li><a id="org8f38a32"></a><span class="done DONE">DONE</span> UCSD: <a href="http://cpl.ucsd.edu/">Computational Psycholinguistics Lab</a><br /><div class="outline-text-6" id="text-3-7-3-1-1">
<ul class="org-ul">
<li>Website not updated since 2014</li>
</ul>
</div></li>
<li><a id="org4b4dbab"></a><span class="done DONE">DONE</span> MIT: <a href="http://cpl.ucsd.edu/">Computational Psycholinguistics Lab</a><br /><div class="outline-text-6" id="text-3-7-3-1-2">
<ul class="org-ul">
<li>Website not updated since 2014</li>
</ul>
</div></li></ol></li>
<li><a id="orgdef8f1b"></a>Linguistic properties of speech/writing of those diagnosed with mental illness<br /><ol class="org-ol"><li><a id="orga0eeaa0"></a><span class="done DONE">DONE</span> "The Emotional Lexicon of Individuals Diagnosed with Antisocial Personality Disorder" <a class='org-ref-reference' href="#gawda_emotional_2013">gawda_emotional_2013</a><br /><div class="outline-text-6" id="text-3-7-3-2-1">
<p>
Abstract: "This study investigated the specific emotional lexicons in narratives created by persons diagnosed with antisocial personality disorder (ASPD) to test the hypothesis that individuals with ASPD exhibit deficiencies in emotional language. Study participants consisted of 60 prison inmates with ASPD, 40 prison inmates without ASPD, and 60 men without antisocial tendencies who described situations involving love, hate and anxiety depicted by photographs. The lexical choices made in the narratives were analyzed, and a comparison of the three groups revealed differences between the emotional narratives of inmates with ASPD, inmates without ASPD, and the control group. Although the narratives of the individuals with ASPD included more words describing emotions and higher levels of emotional intensity, the valence of these words was inappropriate. The linguistic characteristics of these narratives were associated with high levels of psychopathy and low emotional reactivity." 
</p>

<ul class="org-ul">
<li>Citing previous research, "individuals with psychopathic personalities create less structured narratives that lack temporal perspective &#x2026; and do not describe the emotional context or focus on negative aspects of the situation" 572</li>
</ul>

<p>
Subjects: 
</p>
<ul class="org-ul">
<li>"60 prison inmates with ASPD"</li>
<li>"40 prison inmates without ASPD"</li>
<li>"60 men wihtout antisocial tendencies"</li>
<li>very similar age, education, IQ, verbal comprehension, etc among these groups</li>
</ul>

<p>
Results: 
</p>
<ul class="org-ul">
<li>ASPD narratives show much higher: 
<ul class="org-ul">
<li>emotion words (all)</li>
<li>positive words (all)</li>
<li>negative words (love)</li>
<li>high-intensity words (love)</li>
<li>nouns (hate)</li>
<li>adjectives (love)</li>
<li>verbs (love, anxiety)</li>
</ul></li>
<li>ASPD narratives show much lower: 
<ul class="org-ul">
<li>negative words (hate)</li>
</ul></li>
</ul>

<p>
? This seems to suggest that with ASPD-diagnosed patients, sentimental valence of words might need to be context-dependent. 
</p>
<ul class="org-ul">
<li>Sentiment on its own, therefore, would prove not to be a great indicator of abusive language, but whether that sentiment was out-of-place for the context.</li>
</ul>
</div>

<ol class="org-ol"><li><a id="orgf7b2581"></a><span class="todo TODO">TODO</span> survey works cited in this bibliography<br /></li></ol></li>

<li><a id="org8088c63"></a><span class="todo TODO">TODO</span> "Syntax of Emotional Narratives of Persons Diagnosed with Antisocial Personality" <a class='org-ref-reference' href="#gawda_syntax_2010">gawda_syntax_2010</a><br /></li>
<li><a id="orgeb85f83"></a><span class="done DONE">DONE</span> "The Language of the Psychopath" <a class='org-ref-reference' href="#rieber_language_1994">rieber_language_1994</a><br /><div class="outline-text-6" id="text-3-7-3-2-3">
<p>
Deep review of the literature of the language of psychopathy, although not strictly employing a quantitative approach to the language.
</p>

<p>
"The true psychopath compels the psychiatric observer to ask the perplexing and largely unanswered question 'Why doesn't that person have the common decency to go crazy?'" 2
</p>

<p>
? Language that "goes crazy," therefore, cannot be considered a mark of psychopathy. 
</p>

<p>
"[Psychopaths] do not allow themselves to be moved by words and concepts that their fellow citizens value." 12
</p>

<p>
Notes Eichler's 1965 study's results: "sociopaths were higher than normals on <i>negation, retraction, evaluation</i>. As compared with impulsives, sociopaths were higher than normal on <i>nonpersonal references</i>." 15
</p>
</div></li>

<li><a id="org1680164"></a><span class="todo TODO">TODO</span> "A graph theory model of the semantic structure of attitudes" <a class='org-ref-reference' href="#bovasso_graph_1993">bovasso_graph_1993</a><br /><div class="outline-text-6" id="text-3-7-3-2-4">
<p>
abstract: "The semantic structure underlying the attitudes of pretreatment and posttreatment drug addicts was modeled using a network analysis of free word associations." 
</p>
</div></li></ol></li>
<li><a id="org5760741"></a>Linguistic properties of emotional expression<br /><ol class="org-ol"><li><a id="org8caa118"></a><span class="todo TODO">TODO</span> "Measuring Emotional Expression with the Linguistic Inquiry and Word Count" <a class='org-ref-reference' href="#kahn_measuring_2007">kahn_measuring_2007</a><br /></li>
<li><a id="orge262200"></a><span class="todo TODO">TODO</span> "Linguistic Markers and Emotional Intensity" <a class='org-ref-reference' href="#argaman_linguistic_2010">argaman_linguistic_2010</a><br /><div class="outline-text-6" id="text-3-7-3-3-2">
<ul class="org-ul">
<li>Study speakers of Hebrew language.</li>
</ul>
</div></li></ol></li>
<li><a id="org850df42"></a>Swearing<br /><ol class="org-ol"><li><a id="orgf53a86a"></a><span class="done DONE">DONE</span> "Swears in Context: The Difference Between Casual and Abusive Swearing" <a class='org-ref-reference' href="#kapoor_swears_2016">kapoor_swears_2016</a><br /><div class="outline-text-6" id="text-3-7-3-4-1">
<p>
Notes Rieber et al. 1979: "obscenities used denotatively can be considered far more harh and offensive than those used connotatively." 
</p>

<p>
Cites patent <a href="https://www.google.com/patents/US20110191105">Patent US20110191105</a> (see above) where: "Reactions to offensive words were explained in terms of an 'offensiveness threshold' based on the individual’s sensitivity to profane language. Thus, if a word’s offensiveness score was higher than the individual’s offensiveness threshold, the word would be considered inappropriate and offensive; but if the individual’s tolerance for swearwords were high, and the word’s offensiveness score did not exceed the threshold, it was not likely to be perceived as offensive." 260
</p>

<p>
Distinguish between "mild," "moderate," and "severe" types of swears, cross-linguistically and across natioalities.
</p>

<p>
Test "appropriateness" 
</p>

<p>
Hypotheses: 
</p>
<ul class="org-ul">
<li>"H1: Mild swears are more appropriate than moderate swears, which in turn, are more appropriate than severe swears."</li>
<li>"H2: Swearing in casual contexts is more appropriate than swearing in abusive settings."</li>
<li>"H3: Mild swears in casual contexts are the least inappropriate, and severe swears in abusive contexts are the most inappropriate."</li>
</ul>

<p>
Results: 
</p>
<ul class="org-ul">
<li>"Mild swears were likely to be used in casual, cathartic, and hostile scenarios; moderate swears were more likely to be used in conversational and abusive contexts."</li>
<li>results "partially support H4": "severe swears are likely to be employed in abusive and hostile contexts (H4)." 266</li>
</ul>
</div></li>

<li><a id="org98a778b"></a><span class="todo TODO">TODO</span> "Does Emotional Arousal Influence Swearing Fluency?" <a class='org-ref-reference' href="#stephens_does_2017">stephens_does_2017</a><br /></li></ol></li></ol>
</div>
</div>
<div id="outline-container-orgbeebc60" class="outline-3">
<h3 id="orgbeebc60"><span class="section-number-3">3.8</span> Gamergate</h3>
<div class="outline-text-3" id="text-3-8">
</div><div id="outline-container-orge44cdcb" class="outline-4">
<h4 id="orge44cdcb"><span class="section-number-4">3.8.1</span> <span class="done DONE">DONE</span> <a href="http://www.newyorker.com/tech/elements/zoe-quinns-depression-quest">Zoe Quinn’s Depression Quest | The New Yorker</a></h4>
<div class="outline-text-4" id="text-3-8-1">
</div>
</div>
<div id="outline-container-orgeca6e08" class="outline-4">
<h4 id="orgeca6e08"><span class="section-number-4">3.8.2</span> <span class="todo TODO">TODO</span> <a href="https://www.nytimes.com/2014/10/16/technology/gamergate-women-video-game-threats-anita-sarkeesian.html">Feminist Critics of Video Games Facing Threats in ‘GamerGate’ Campaign - The New York Times</a></h4>
<div class="outline-text-4" id="text-3-8-2">
</div><ol class="org-ol"><li><a id="org2a40a48"></a><span class="todo TODO">TODO</span> "What Lies Beneath: The Linguistic Traces of Deception in Online Dating" <a class='org-ref-reference' href="#toma_what_2012">toma_what_2012</a><br /></li></ol>
</div>
<div id="outline-container-org5d4af67" class="outline-4">
<h4 id="org5d4af67"><span class="section-number-4">3.8.3</span> Anita Sarkeesian, Zoe Quinn</h4>
<div class="outline-text-4" id="text-3-8-3">
</div><ol class="org-ol"><li><a id="orgc3e0cd4"></a><span class="todo TODO">TODO</span> Video: <a href="https://www.youtube.com/watch?v=HLteBt0_LiI">Speech for the UN</a><br /></li></ol>
</div>
</div>
</div>
<div id="outline-container-org56973fb" class="outline-2">
<h2 id="org56973fb"><span class="section-number-2">4</span> Questions</h2>
<div class="outline-text-2" id="text-4">
</div><div id="outline-container-orgd6dbad0" class="outline-3">
<h3 id="orgd6dbad0"><span class="section-number-3">4.1</span> Has anyone done a comment/article similarity (relevance) study like <a class='org-ref-reference' href="#diakopoulos_editors_2015">diakopoulos_editors_2015</a> but using word/document vectors instead of tf-idf?</h3>
<div class="outline-text-3" id="text-4-1">
<ul class="org-ul">
<li><a class='org-ref-reference' href="#kolhatkar_constructive_2017">kolhatkar_constructive_2017</a> vectorizes words, but not to compute similarity with articles</li>
<li><a class='org-ref-reference' href="#gamback_using_2017">gamback_using_2017</a> uses word embeddings, finds that categorizer works best with these</li>
</ul>
</div>
</div>
<div id="outline-container-org86a7ab2" class="outline-3">
<h3 id="org86a7ab2"><span class="section-number-3">4.2</span> Has anyone studied platform/OS source as predictor of potentially abusive language?</h3>
<div class="outline-text-3" id="text-4-2">
<ul class="org-ul">
<li><a href="http://keyhole.co/">Keyhole</a> shows high incidence of bot platforms for #gamergate. These account for almost 20%: 
<ul class="org-ul">
<li><a href="http://twittbot.net/">twittbot</a></li>
<li><a href="http://cheapbotsdonequick.com/">Cheap Bots, Done Quick!</a></li>
<li>ITTT (If this, then that)</li>
</ul></li>
</ul>
</div>
</div>
<div id="outline-container-orgaa64721" class="outline-3">
<h3 id="orgaa64721"><span class="section-number-3">4.3</span> What can psycholinguistics studies offer to fingerprinting of abusive language?</h3>
</div>
<div id="outline-container-org4fe7e33" class="outline-3">
<h3 id="org4fe7e33"><span class="section-number-3">4.4</span> Has anyone written a Twitter bot to identify abusive speech, and then ask the alleged abuser/abusee whether he/she thought it was abusive?</h3>
<div class="outline-text-3" id="text-4-4">
<ul class="org-ul">
<li>This approach might be able to learn from correct/incorrect identifications.</li>
</ul>
</div>
</div>
<div id="outline-container-org503667e" class="outline-3">
<h3 id="org503667e"><span class="section-number-3">4.5</span> What Twitter accounts or hashtags might be cataloging abusive tweets? Can these be mined to create new datasets?</h3>
</div>
<div id="outline-container-org5bc2155" class="outline-3">
<h3 id="org5bc2155"><span class="section-number-3">4.6</span> If we can identify male voices or deceptive, can we use that as a proxy to identifying trolls?</h3>
</div>
</div>
<div id="outline-container-orgef4d498" class="outline-2">
<h2 id="orgef4d498"><span class="section-number-2">5</span> Books and Other Sources</h2>
<div class="outline-text-2" id="text-5">
</div><div id="outline-container-orgd529e0a" class="outline-3">
<h3 id="martellozzo_cybercrime_2017"><a id="orgd529e0a"></a><span class="section-number-3">5.1</span> <span class="todo TODO">TODO</span> - Cybercrime and its victims</h3>
<div class="outline-text-3" id="text-martellozzo_cybercrime_2017">
<p>
<a class='org-ref-reference' href="#martellozzo_cybercrime_2017">martellozzo_cybercrime_2017</a>
</p>
</div>
</div>
<div id="outline-container-orga3e9c34" class="outline-3">
<h3 id="jane_misogyny_2016"><a id="orga3e9c34"></a><span class="section-number-3">5.2</span> <span class="todo TODO">TODO</span> - Misogyny Online: A Short (and Brutish) History</h3>
<div class="outline-text-3" id="text-jane_misogyny_2016">
<p>
<a class='org-ref-reference' href="#jane_misogyny_2016">jane_misogyny_2016</a>
</p>
</div>
</div>
<div id="outline-container-org3307448" class="outline-3">
<h3 id="org3307448"><span class="section-number-3">5.3</span> <span class="todo TODO">TODO</span> - "Gendertrolling: How Misogyny Went Viral" <a class='org-ref-reference' href="#mantilla_gendertrolling:_2015">mantilla_gendertrolling:_2015</a></h3>
</div>
<div id="outline-container-orgaa0231c" class="outline-3">
<h3 id="alba_weeding_2015"><a id="orgaa0231c"></a><span class="section-number-3">5.4</span> <span class="done DONE">DONE</span> - Weeding Out Online Bullying Is Tough, So Let Machines Do It</h3>
<div class="outline-text-3" id="text-alba_weeding_2015">
<p>
<a class='org-ref-reference' href="#alba_weeding_2015">alba_weeding_2015</a>
<a href="https://www.wired.com/2015/07/weeding-online-bullying-tough-let-machines/">Weeding Out Online Bullying Is Tough, So Let Machines Do It | WIRED</a>
</p>

<p>
SRI International uses data from a major unspecified social media company to train an algorithm against reported data. 
</p>

<p>
"Smart abusers": "Jamia Wilson, executive director of Women Action Media, a group Twitter appointed last fall to look at reports of harassment on the social network, says her main concern is that abusers are well-aware of the initiatives to curb harassment on networks—and employ sophisticated techniques to avoid detection." 
</p>
</div>
</div>

<div id="outline-container-org1b876c5" class="outline-3">
<h3 id="duggan_online_2014"><a id="org1b876c5"></a><span class="section-number-3">5.5</span> <span class="todo TODO">TODO</span> - Pew Research Report 2014: Online Harassment</h3>
<div class="outline-text-3" id="text-duggan_online_2014">
<p>
<a class='org-ref-reference' href="#duggan_online_2014">duggan_online_2014</a>
</p>
</div>
</div>
</div>

<div id="outline-container-orgae77d2d" class="outline-2">
<h2 id="orgae77d2d"><span class="section-number-2">6</span> Reports</h2>
<div class="outline-text-2" id="text-6">
</div><div id="outline-container-orgcdc0a23" class="outline-3">
<h3 id="orgcdc0a23"><span class="section-number-3">6.1</span> Report 1 <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-22 Tue&gt;</span></span></h3>
<div class="outline-text-3" id="text-6-1">
<p>
The detection and prediction of abusive or other "low-quality" language is a much-discussed topic in the computer science field of natural language processing and in computational linguistics. The work I've examined so far largely treats the problem as one of document classification, a subset of machine learning. Documents, which could be articles, comments, tweets, or other text, are first preprocessed (converting them to words or sequences of words), vectorized (transformed into numeric representations of these words), and the resulting vectors, usually along with other contextual features, are used to train machine learning algorithms to recognize abusive or other kinds of language. Once the algorithm is trained against labeled data (comments that have been marked as abusive by other users, for instance), it can then be used to guess whether a test document should be categorized as abusive.  
</p>

<p>
Although the machine learning algorithm ultimately decides which of the features best categorize its data, whether to use word vector features or other contextual features, and how to weight those features, the researcher must first decide which features to feed it. In some cases, features include term frequencies, adjusted for their frequency in the document or corpus (TF-IDF) (<a class='org-ref-reference' href="#diakopoulos_editors_2015">diakopoulos_editors_2015</a>), or n-dimensional word embeddings (<a class='org-ref-reference' href="#agichtein_finding_2008">agichtein_finding_2008</a>), trained on data like <a href="https://nlp.stanford.edu/projects/glove/">Stanford's GloVe vectors</a>. Nicholas Diakopoulos et al., for instance, introduce a measure of the "relevance" of a news website comment to its article by measuring the cosine similarities of TF-IDF vectors between them. Eugene Agichtein et al use a similar technique to measure relevance of questions and answers from a Q&amp;A website, measuring instead the KL divergence of their language models. Agichtein's team also vectorizes their texts by transforming them into part-of-speech representations, discovering that certain grammatical constructions correlate with the "quality" of the question or answer. 
</p>

<p>
Sentiment analysis, a sub-field of natural language processing, can also provide useful features for categorization. Stefan Siersdorfer et al find that sentiment scores,  computed using the SentiWordNet, correlate with user ratings of comments on YouTube (<a class='org-ref-reference' href="#siersdorfer_how_2010">siersdorfer_how_2010</a>). Carlos Castillo et al, as well, find sentiment scores to be among the best features that distinguish between "credible" and "non-credible" tweets (<a class='org-ref-reference' href="#castillo_predicting_2013">castillo_predicting_2013</a>). 
</p>

<p>
Some of the more interesting features used to train these categorizers, however, are metatextual, rather than textual features. Castillo et al, for instance, find that whether a Twitter user has completed his or her self-description ("bio") is a feature that is weighted highly in distinguishing between tweets automatically categorized as either "news" and "discussion" (<a class='org-ref-reference' href="#castillo_predicting_2013">castillo_predicting_2013</a>). Agichtein et al use social network theory, and in particular trust propagation theory, to predict "high-quality" questions and answers. If user A answers a question asked by a well-known expert answerer B, for instance, they assume a certain level of expertise on the part of user A.  
</p>

<p>
While these papers describe techniques for abusive language detection, and not necessarily software, such software does exist. TrollBusters, the fruit of a 2015 hackathon, claims to "identify communities of trolls around any given issue using natural language processing" and "counter cyberattacks in real-time with online community support and positive messaging." As far as I can tell, it is proprietary software. <a href="http://www.perspectiveapi.com/">Perspective</a>, a product produced by the startup Jigsaw, an Alphabet (Google) company, is a more mature-looking product, with a public API that could be used to label comments according to their potential "toxicity." Although much of <a href="https://github.com/conversationai">Perspective's code</a> is on GitHub, it is unclear how much of their model is public, so there might still be room for development of a fully open-source tool. 
</p>

<p>
There are a few dozen other papers in this area I have yet to explore, and a few related fields, besides. The fields of automated essay grading and readability indexing may hold techniques that are useful to the automated detection of abusive text. Non-computational fields, as well, such as psychology and media studies, may provide useful ideas for ML feature design. I hope to explore the Gamergate controversy in more detail, especially since <a href="https://prpole.github.io/semantic-analysis-of-one-million-gamergate-tweets/">a colleague of mine has recently done a computational analysis of its tweets</a>. (A quick analysis of gamergate tweets on Keyhole reveals that around 10% of the tweets came from Twitter bot platforms&#x2013;are there automated abuse robots, and how might these be identified?) 
</p>
</div>
</div>
<div id="outline-container-org88b6ddb" class="outline-3">
<h3 id="org88b6ddb"><span class="section-number-3">6.2</span> Report 2, <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-28 Mon&gt;</span></span></h3>
<div class="outline-text-3" id="text-6-2">
<p>
Most of the work I've examined this week belongs to the fields of computational linguistics and natural language processing, and treats the problem of the identification of abusive language as a document categorizing problem. The training data used for these studies is often generated by employing casual workers on Amazon Mechanical Turk or CrowdFlower to manually annotate data. Features used by these studies include average sentiment analysis scores, emoticons used, sylistic patterns such as sentence length, word embeddings, and LDA (topic modeling) topics. In one case (<a class='org-ref-reference' href="#samghabadi_detecting_2017">samghabadi_detecting_2017</a>) a "bad words dictionary" was created from combining a Google-created list with a list from another researcher. Categorizers used include Long Short-Term Memory (LSTM) recurrent neural networks, (<a class='org-ref-reference' href="#kolhatkar_constructive_2017">kolhatkar_constructive_2017</a>), Convolutional Neural Networks (<a class='org-ref-reference' href="#gamback_using_2017">gamback_using_2017</a>), and Support Vector Machines (SVM) (<a class='org-ref-reference' href="#samghabadi_detecting_2017">samghabadi_detecting_2017</a>). <b>The method that performs best in categorizing abusive language seems to vary greatly according to data set and domain.</b> Sood et al. (<a class='org-ref-reference' href="#sood_automatic_2012">sood_automatic_2012</a>), for instance, find that word bigrams (sequences of two words) are the best-performing features, while Samghabadi et al. (<a class='org-ref-reference' href="#samghabadi_detecting_2017">samghabadi_detecting_2017</a>) find character 4-grams (sequences of four characters) to perform better. Data sets also show a wide variety: some consist of news comments, while others are of tweets. Typically, the longer the document, the better the categorizer will perform, and different algorithms are needed for each.
</p>

<p>
Although a number of these studies don't seem to publish their data and code, many of them do, making room for easy repetition of their experiments, or design of new experiments that make use of some of their code and/or data. In particular, the 2012 Kaggle task "Detecting Insults in Social Commentary" has <a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary/discussion/2744">a thread where participants are posting their code</a>. Also, I've started tagging those studies that publish their training corpora using the tag "hasCorpus."  
</p>

<p>
As previously noted, very little user-space software seems to exist for detection of harassment, and its quality seems to be very much in its infancy. I tested Jigsaw's <i>Perspective,</i> which I mentioned in my previous report, against a number of intentionally ambiguous and threatening sentences. I then compared these scores with those generated from the Wiki DeTox agression model, also a Jigsaw project:  
</p>

<ul class="org-ul">
<li>"Be careful, you might find some white powder in an envelope come in the mail one day." 
<ul class="org-ul">
<li>WDT: 1% aggressive</li>
<li>Perspective: 14% toxic</li>
</ul></li>
<li>"If you keep this up, you find yourself sleeping with the fishes." 
<ul class="org-ul">
<li>WDT: 12% aggressive.</li>
<li>Perspective: 38% toxic</li>
</ul></li>
<li>"I'm going to come to your house." 
<ul class="org-ul">
<li>WDT: 48% aggressive.</li>
<li>Perspective: 15% toxic</li>
</ul></li>
<li>"I'm going to nominate you for the Nobel prize, you brilliant man." 
<ul class="org-ul">
<li>WDT: 61% aggressive.</li>
<li>Perspective: 17% toxic.</li>
</ul></li>
</ul>

<p>
These scores highlight both the high variability between algorithms, and their difficulty with ambiguous language. 
</p>

<p>
More abstract and theoretical work in this area also seems worthy of more examination. Heylighen et al's formality score, a formula using part-of-speech representations of words, uses anthropological and psycholinguistic theories of contextuality (linguistic deixis). Although this measure is used directly in categorization experiments (<a class='org-ref-reference' href="#agichtein_finding_2008">agichtein_finding_2008</a>), its methodology might also be adapted to build other POS pattern-based approaches for the detection of abusive language. The methods of the sub-field of deceptive opinion spam (false product reviews, for instance), which in some cases succeed in detecting opinion spam at 90%, a success rate much higher than those of human judges, might also be adapted to the detection of abusive language.  
</p>
</div>
</div>
<div id="outline-container-orga84db44" class="outline-3">
<h3 id="orga84db44"><span class="section-number-3">6.3</span> Report 3, <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-14 Thu&gt;</span></span></h3>
<div class="outline-text-3" id="text-6-3">
<p>
This week, I began by exploring some of the winning entries from the 2012 Kaggle data science contest, <a href="https://www.kaggle.com/c/detecting-insults-in-social-commentary">Detecting Insults in Social Commentary</a>. The top six entries used the Python programming language and its machine learning libraries, like Scikit-Learn; other entries used the statistical language R or other programming languages. Since the top entries all seemed to use similar categorizers and meta-categorizers (grid-search cross-validation techniques), they largely differ in preprocessing. One coder credits "good tokenization" as one of the major keys to his success. Domain-specific knowledge, and in particular linguistic observation of the training data, then, provided the most tangible advantages. Knowledge of the obfuscation techniques used by speakers of insults, for instance, contributed to these useful tokenization techniques. 
</p>

<p>
Following my previous report on formality scores and their use in these categorization tasks, I began to investigate the field of computational psycholinguistics. A few articles in this field exist that take quantitative approaches to the study of language produced by people who have been diagnosed with mental illness. <a class='org-ref-reference' href="#gawda_emotional_2013">gawda_emotional_2013</a>, for instance, studies narratives written by prison inmates diagnosed with Antisocial Personality Disorder (ASPD), as compared with a control group, and those diagnosed as not having the disorder. They find that emotional words are higher in general among those with ASPD, but negative words, for instance, might have lower than normal scores for narratives that describe hate. When seen in the context of our project of the computational identification of abusive language, this finding suggests that negative words on their own may not be markers of abuse, at least that originating from those with ASPD. Similarly, <a class='org-ref-reference' href="#rieber_language_1994">rieber_language_1994</a>, a literature review of "the language of psychopathy" finds that often one of the distinguishing linguistic features of these patients is the <i>lack</i> of emotional markers in certain contexts. Here again, this indicates that strong emotional valence, as measured by sentiment analysis, might not on its own be a useful feature for a categorizer, and that contextually contrasting emotional content might perform better.
</p>

<p>
These contextual complications are analogous with those studied in a few papers on swearing. <a class='org-ref-reference' href="#kapoor_swears_2016">kapoor_swears_2016</a>, for instance, attempts to differentiate between "casual" and "abusive" swearing. They categorize swear words as "mild," "moderate," and "severe," and find that "moderate" and "severe" swear words are more likely to occur in abusive contexts. They cite <a href="https://www.google.com/patents/US20110191105">a 2011 patent</a> that scores offensiveness as swearing that contrasts with a user's swearing "threshold." This is another instance of abuse detection that relies on contextually contrasting language. 
</p>

<p>
Since many projects in abusive language detection position themselves socio-contextually, and describe their studies as attempt to identify "trolls," or those who habitually abuse or harass others, an important subcategory of this area of research is the identification of professional trolls. These are trolls that are either <i>agents provocateurs</i> employed by government agencies, or employed by private "reputation management" consultants. One study in this area, studying comments on a Bulgarian news website, found that the day of the week and the hour of the day were useful features to distinguish between paid and unpaid trolls. Computationally identifying paid trolls, and other systematic or automated forms of harassment, might leverage metadata like this, potentially making it one of the easiest subtasks for abuse detection. 
</p>

<p>
New directions for research include six US patents related to the detection of abusive language, or for "offensiveness" more generally; a statistical exploration of the <a href="http://hatebase.org">hatebase.org</a> dataset of hate speech (thanks for the tip, Colin); more work related to troll detection, especially in graph theory and signed social network theory; and more fine-grained analysis of the code from the 2012 Kaggle competition and other publicly-available algorithms. 
</p>
</div>
</div>
</div>

<div id="outline-container-orgc63c967" class="outline-2">
<h2 id="orgc63c967"><span class="section-number-2">7</span> References</h2>
<div class="outline-text-2" id="text-7">
<p>
<a id="org7b82a7a"></a>  <h1 class='org-ref-bib-h1'>Bibliography</h1>
<ul class='org-ref-bib'><li><a id="anti-defamation_league_adl_2016">[anti-defamation_league_adl_2016] Anti-Defamation League, ADL Report: Control-Alt-Delete: Recommendations of the ADL Task Force on the Harassment of Journalists, <i></i>, <b></b>, . <a href="https://www.adl.org/sites/default/files/documents/assets/pdf/press-center/adl-journalism-task-force-recommendations.pdf">link</a>.</a></li>
<li><a id="alba_weeding_2015">[alba_weeding_2015] Alba, Weeding Out Online Bullying Is Tough, So Let Machines Do It, <i>WIRED</i>, <b></b>, . <a href="https://www.wired.com/2015/07/weeding-online-bullying-tough-let-machines/">link</a>.</a></li>
<li><a id="lapowsky_its_2015">[lapowsky_its_2015] Lapowsky, It's Too Easy for Trolls to Game Twitter's Anti-Abuse Tools, <i>WIRED</i>, <b></b>, . <a href="https://www.wired.com/2015/05/wam-twitter-harassment/">link</a>.</a></li>
<li><a id="wauters_towards_2014">[wauters_towards_2014] Wauters, Lievens & Valcke, Towards a better protection of social media users: a legal perspective on the terms of use of social networking sites, <i>International Journal of Law and Information Technology</i>, <b>22(3)</b>, 254-294 . <a href="https://academic-oup-com.ezproxy.cul.columbia.edu/ijlit/article-abstract/22/3/254/2907401">link</a>.</a></li>
<li><a id="citron_intermediaries_2011">[citron_intermediaries_2011] Citron & Norton, Intermediaries and hate speech: Fostering digital citizenship for our information age, <i>BUL Rev.</i>, <b>91</b>, 1435 . <a href="http://heinonline.org.ezproxy.cul.columbia.edu/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/bulr91&section=59">link</a>.</a></li>
<li><a id="geiger_work_2010">[geiger_work_2010] Geiger & Ribes, The Work of Sustaining Order in Wikipedia: The Banning of a Vandal, 117-126, in in: Proceedings of the 2010 ACM Conference on Computer Supported Cooperative Work, edited by ACM </a></li>
<li><a id="tkacz_wikipedia_2014">[tkacz_wikipedia_2014] Tkacz, Wikipedia and the Politics of Openness, University of Chicago Press .</a></li>
<li><a id="warnick_what_2010">[warnick_what_2010] Warnick, What we talk about when we talk about talking: Ethos at work in an online community, Iowa State University .</a></li>
<li><a id="crawford_what_2016">[crawford_what_2016] Crawford & Gillespie, What is a flag for? Social media reporting tools and the vocabulary of complaint, <i>New Media & Society</i>, <b>18(3)</b>, 410-428 . <a href="http://dx.doi.org/10.1177/1461444814543163">link</a>. <a href="http://dx.doi.org/10.1177/1461444814543163">doi</a>.</a></li>
<li><a id="matias_reporting_2015">[matias_reporting_2015] Matias, Johnson, Boesel, Keegan, Friedman & DeTar, Reporting, Reviewing, and Responding to Harassment on Twitter, <i>arXiv:1505.03359 [cs]</i>, <b></b>, . <a href="http://arxiv.org/abs/1505.03359">link</a>.</a></li>
<li><a id="wright_vectors_2017">[wright_vectors_2017] Wright, Ruths, Dillon, Saleem & Benesch, Vectors for Counterspeech on Twitter, <i>ACL 2017</i>, <b></b>, 57 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=69">link</a>.</a></li>
<li><a id="grimmelmann_virtues_2015">[grimmelmann_virtues_2015] Grimmelmann, The virtues of moderation, <i>Yale JL & Tech.</i>, <b>17</b>, 42 . <a href="http://heinonline.org.ezproxy.cul.columbia.edu/hol-cgi-bin/get_pdf.cgi?handle=hein.journals/yjolt17&section=3">link</a>.</a></li>
<li><a id="lampe_slash_2004">[lampe_slash_2004] Lampe & Resnick, Slash (dot) and burn: distributed moderation in a large online conversation space, 543-550, in in: Proceedings of the SIGCHI conference on Human factors in computing systems, edited by ACM </a></li>
<li><a id="su_rephrasing_2017">[su_rephrasing_2017] Su, Huang, Chang & Lin, Rephrasing Profanity in Chinese Text, <i>ACL 2017</i>, <b></b>, 18 . <a href="http://www.aclweb.org/anthology/W17-30#page=30">link</a>.</a></li>
<li><a id="fiser_legal_2017">[fiser_legal_2017] Fišer, Ljubešic & Erjavec, Legal Framework, Dataset and Annotation Schema for Socially Unacceptable Online Discourse Practices in Slovene, <i>ACL 2017</i>, <b></b>, 46 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=58">link</a>.</a></li>
<li><a id="mubarak_abusive_2017">[mubarak_abusive_2017] Mubarak, Darwish & Magdy, Abusive Language Detection on Arabic Social Media, <i>ACL 2017</i>, <b></b>, 52 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=64">link</a>.</a></li>
<li><a id="mihaylov_exposing_2015">[mihaylov_exposing_2015] Mihaylov, Koychev, Georgiev & Nakov, Exposing Paid Opinion Manipulation Trolls., 443-450, in in: RANLP, edited by </a></li>
<li><a id="mihaylov_finding_2015">[mihaylov_finding_2015] Mihaylov, Georgiev & Nakov, Finding Opinion Manipulation Trolls in News Community Forums., 310-314, in in: CoNLL, edited by </a></li>
<li><a id="ortega_propagation_2012">[ortega_propagation_2012] Ortega, Troyano, Cruz, Vallejo & Enríquez, Propagation of trust and distrust for the detection of trolls in a social network, <i>Computer Networks</i>, <b>56(12)</b>, 2884-2895 . <a href="http://www.sciencedirect.com/science/article/pii/S138912861200179X">link</a>. <a href="http://dx.doi.org/10.1016/j.comnet.2012.05.002">doi</a>.</a></li>
<li><a id="kumar_accurately_2014">[kumar_accurately_2014] Kumar, Spezzano & Subrahmanian, Accurately detecting trolls in slashdot zoo via decluttering, 188-195, in in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on, edited by IEEE </a></li>
<li><a id="rowe_assessing_2009">[rowe_assessing_2009] Rowe & Butters, Assessing trust: contextual accountability, <i>ESWC, Heraklion</i>, <b></b>, . <a href="http://ceur-ws.org/Vol-447/paper2.pdf">link</a>.</a></li>
<li><a id="xu_filtering_2010">[xu_filtering_2010] Xu & Zhu, Filtering offensive language in online communities using grammatical relations, 1-10, in in: Proceedings of the Seventh Annual Collaboration, Electronic Messaging, Anti-Abuse and Spam Conference, edited by </a></li>
<li><a id="razavi_offensive_2010">[razavi_offensive_2010] Razavi, Inkpen, Uritsky & Matwin, Offensive language detection using multi-level classification, <i>Advances in Artificial Intelligence</i>, <b></b>, 16-27 . <a href="http://link.springer.com.ezproxy.cul.columbia.edu/content/pdf/10.1007/978-3-642-13059-5.pdf#page=31">link</a>.</a></li>
<li><a id="siersdorfer_how_2010">[siersdorfer_how_2010] Siersdorfer, Chelaru, Nejdl & San Pedro, How useful are your comments?: analyzing and predicting youtube comments and comment ratings, 891-900, in in: Proceedings of the 19th international conference on World wide web, edited by ACM </a></li>
<li><a id="diakopoulos_editors_2015">[diakopoulos_editors_2015] Diakopoulos, The Editor's Eye: Curation and Comment Relevance on the New York Times, 1153-1157, in in: Proceedings of the 18th ACM Conference on Computer Supported Cooperative Work & Social Computing, edited by ACM </a></li>
<li><a id="castillo_predicting_2013">[castillo_predicting_2013] Castillo, Mendoza & Poblete, Predicting information credibility in time-sensitive social media, <i>Internet Research</i>, <b>23(5)</b>, 560-588 . <a href="http://www.emeraldinsight.com.ezproxy.cul.columbia.edu/doi/abs/10.1108/IntR-05-2012-0095">link</a>.</a></li>
<li><a id="kolhatkar_constructive_2017">[kolhatkar_constructive_2017] Kolhatkar & Taboada, Constructive Language in News Comments, <i>ACL 2017</i>, <b></b>, 11 . <a href="http://www.aclweb.org/anthology/W17-30#page=23">link</a>.</a></li>
<li><a id="agichtein_finding_2008">[agichtein_finding_2008] Agichtein, Castillo, Donato, Gionis & Mishne, Finding high-quality content in social media, 183-194, in in: Proceedings of the 2008 international conference on web search and data mining, edited by ACM </a></li>
<li><a id="heylighen_variation_2002">[heylighen_variation_2002] Heylighen & Dewaele, Variation in the contextuality of language: An empirical measure, <i>Foundations of Science</i>, <b>7(3)</b>, 293-340 . <a href="http://www.springerlink.com.ezproxy.cul.columbia.edu/index/p08225g588771321.pdf">link</a>.</a></li>
<li><a id="danescu-niculescu-mizil_how_2009">[danescu-niculescu-mizil_how_2009] Danescu-Niculescu-Mizil, Kossinets, Kleinberg & Lee, How opinions are received by online communities: a case study on amazon. com helpfulness votes, 141-150, in in: Proceedings of the 18th international conference on World wide web, edited by ACM </a></li>
<li><a id="brand_comment_2014">[brand_comment_2014] Brand & Van Der Merwe, Comment classification for an online news domain, <i></i>, <b></b>, . <a href="http://scholar.sun.ac.za/handle/10019.1/96148">link</a>.</a></li>
<li><a id="dadvar_improved_2012">[dadvar_improved_2012] Dadvar, de Jong, Ordelman & Trieschnigg, Improved cyberbullying detection using gender information, <i></i>, <b></b>, . <a href="http://eprints.eemcs.utwente.nl/21608/">link</a>.</a></li>
<li><a id="hosseinmardi_towards_2014">[hosseinmardi_towards_2014] Hosseinmardi, Ghasemianlangroodi, Han, Lv & Mishra, Towards understanding cyberbullying behavior in a semi-anonymous social network, 244-252, in in: Advances in Social Networks Analysis and Mining (ASONAM), 2014 IEEE/ACM International Conference on, edited by IEEE </a></li>
<li><a id="lieberman_lets_2011">[lieberman_lets_2011] Lieberman, Dinakar & Jones, Let's gang up on cyberbullying, <i>Computer</i>, <b>44(9)</b>, 93-96 . <a href="http://ieeexplore.ieee.org.ezproxy.cul.columbia.edu/abstract/document/6017178/">link</a>.</a></li>
<li><a id="kansara_framework_2015">[kansara_framework_2015] Kansara & Shekokar, A framework for cyberbullying detection in social network, <i>International Journal of Current Engineering and Technology</i>, <b>5</b>, . <a href="http://inpressco.com/wp-content/uploads/2015/02/Paper90494-498.pdf">link</a>.</a></li>
<li><a id="macbeth_script-based_2013">[macbeth_script-based_2013] Macbeth, Adeyema, Lieberman & Fry, Script-based story matching for cyberbullying prevention, 901-906, in in: CHI'13 Extended Abstracts on Human Factors in Computing Systems, edited by ACM </a></li>
<li><a id="xu_fast_2012">[xu_fast_2012] Xu, Zhu & Bellmore, Fast learning for sentiment analysis on bullying, 10, in in: Proceedings of the First International Workshop on Issues of Sentiment Discovery and Opinion Mining, edited by ACM </a></li>
<li><a id="xu_examination_2013">[xu_examination_2013] Xu, Burchfiel, Zhu & Bellmore, An Examination of Regret in Bullying Tweets., 697-702, in in: HLT-NAACL, edited by </a></li>
<li><a id="van_hee_detection_2015">[van_hee_detection_2015] Van Hee, Lefever, Verhoeven, Mennes, Desmet, De Pauw, Daelemans & Hoste, Detection and fine-grained classification of cyberbullying events, 672-680, in in: International Conference Recent Advances in Natural Language Processing (RANLP), edited by </a></li>
<li><a id="xu_learning_2012">[xu_learning_2012] Xu, Jun, Zhu & Bellmore, Learning from bullying traces in social media, 656-666, in in: Proceedings of the 2012 conference of the North American chapter of the association for computational linguistics: Human language technologies, edited by Association for Computational Linguistics </a></li>
<li><a id="dadvar_cyberbullying_2012">[dadvar_cyberbullying_2012] Dadvar & De Jong, Cyberbullying detection: a step toward a safer internet yard, 121-126, in in: Proceedings of the 21st International Conference on World Wide Web, edited by ACM </a></li>
<li><a id="dinakar_modeling_2011">[dinakar_modeling_2011] Dinakar, Reichart & Lieberman, Modeling the detection of Textual Cyberbullying., <i>The Social Mobile Web</i>, <b>11(2)</b>, . <a href="http://www.aaai.org/ocs/index.php/ICWSM/ICWSM11/paper/download/3841/4384">link</a>.</a></li>
<li><a id="chen_detecting_2012">[chen_detecting_2012] Chen, Zhou, Zhu & Xu, Detecting offensive language in social media to protect adolescent online safety, 71-80, in in: Privacy, Security, Risk and Trust (PASSAT), 2012 International Conference on and 2012 International Confernece on Social Computing (SocialCom), edited by IEEE </a></li>
<li><a id="nahar_effective_2013">[nahar_effective_2013] Nahar, Li & Pang, An effective approach for cyberbullying detection, <i>Communications in Information Science and Management Engineering</i>, <b>3(5)</b>, 238 . <a href="http://search.proquest.com.ezproxy.cul.columbia.edu/openview/71d58095eda9e18ae9938e96a5acc1ef/1?pq-origsite=gscholar&cbl=2026788">link</a>.</a></li>
<li><a id="ott_finding_2011">[ott_finding_2011] Ott, Choi, Cardie & Hancock, Finding deceptive opinion spam by any stretch of the imagination, 309-319, in in: Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, edited by Association for Computational Linguistics </a></li>
<li><a id="sood_automatic_2012">[sood_automatic_2012] Sood, Churchill & Antin, Automatic identification of personal insults on social news sites, <i>Journal of the Association for Information Science and Technology</i>, <b>63(2)</b>, 270-285 . <a href="http://onlinelibrary.wiley.com.ezproxy.cul.columbia.edu/doi/10.1002/asi.21690/full">link</a>.</a></li>
<li><a id="gamback_using_2017">[gamback_using_2017] Gambäck & Sikdar, Using Convolutional Neural Networks to Classify Hate-Speech, <i>ACL 2017</i>, <b></b>, 85 . <a href="http://www.aclweb.org/anthology/W17-30#page=97">link</a>.</a></li>
<li><a id="waseem_hateful_2016">[waseem_hateful_2016] Waseem & Hovy, Hateful Symbols or Hateful People? Predictive Features for Hate Speech Detection on Twitter., 88-93, in in: SRW@ HLT-NAACL, edited by </a></li>
<li><a id="samghabadi_detecting_2017">[samghabadi_detecting_2017] Samghabadi, Maharjan, Sprague, Diaz-Sprague & Solorio, Detecting Nastiness in Social Media, <i>ACL 2017</i>, <b></b>, 63 . <a href="http://www.aclweb.org/anthology/W17-30#page=75">link</a>.</a></li>
<li><a id="davidson_automated_2017">[davidson_automated_2017] Davidson, Warmsley, Macy & Weber, Automated Hate Speech Detection and the Problem of Offensive Language, <i>arXiv preprint arXiv:1703.04009</i>, <b></b>, . <a href="https://arxiv.org/abs/1703.04009">link</a>.</a></li>
<li><a id="nobata_abusive_2016">[nobata_abusive_2016] Nobata, Tetreault, Thomas, Mehdad & Chang, Abusive language detection in online user content, 145-153, in in: Proceedings of the 25th International Conference on World Wide Web, edited by International World Wide Web Conferences Steering Committee </a></li>
<li><a id="yin_detection_2009">[yin_detection_2009] Yin, Xue, Hong, Davison, Kontostathis & Edwards, Detection of harassment on web 2.0, <i>Proceedings of the Content Analysis in the WEB</i>, <b>2</b>, 1-7 . <a href="http://www.academia.edu/download/38035244/Yin_etal_CAW2009.pdf">link</a>.</a></li>
<li><a id="papegnies_impact_2017">[papegnies_impact_2017] Papegnies, Labatut, Dufour & Linares, Impact Of Content Features For Automatic Online Abuse Detection, <i>arXiv preprint arXiv:1704.03289</i>, <b></b>, . <a href="https://arxiv.org/abs/1704.03289">link</a>.</a></li>
<li><a id="wulczyn_ex_2017">[wulczyn_ex_2017] Wulczyn, Thain & Dixon, Ex machina: Personal attacks seen at scale, 1391-1399, in in: Proceedings of the 26th International Conference on World Wide Web, edited by International World Wide Web Conferences Steering Committee </a></li>
<li><a id="spertus_smokey:_1997">[spertus_smokey:_1997] Spertus, Smokey: Automatic recognition of hostile messages, 1058-1065, in in: AAAI/IAAI, edited by </a></li>
<li><a id="ross_measuring_2017">[ross_measuring_2017] Ross, Rist, Carbonell, Cabrera, Kurowsky & Wojatzki, Measuring the reliability of hate speech annotations: The case of the european refugee crisis, <i>arXiv preprint arXiv:1701.08118</i>, <b></b>, . <a href="https://arxiv.org/abs/1701.08118">link</a>.</a></li>
<li><a id="xiang_detecting_2012">[xiang_detecting_2012] Xiang, Fan, Wang, Hong & Rose, Detecting offensive tweets via topical feature discovery over a large scale twitter corpus, 1980-1984, in in: Proceedings of the 21st ACM international conference on Information and knowledge management, edited by ACM </a></li>
<li><a id="tran_cross-language_2015">[tran_cross-language_2015] Tran & Christen, Cross-language learning from bots and users to detect vandalism on wikipedia, <i>IEEE Transactions on Knowledge and Data Engineering</i>, <b>27(3)</b>, 673-685 . <a href="http://ieeexplore.ieee.org.ezproxy.cul.columbia.edu/abstract/document/6857333/">link</a>.</a></li>
<li><a id="ahmad_mining_2009">[ahmad_mining_2009] Ahmad, Keegan, Srivastava, Williams & Contractor, Mining for gold farmers: Automatic detection of deviant players in mmogs, 340-345, in in: Computational Science and Engineering, 2009. CSE'09. International Conference on, edited by IEEE </a></li>
<li><a id="nakamura_dont_2009">[nakamura_dont_2009] Nakamura, Don't hate the player, hate the game: The racialization of labor in World of Warcraft, <i>Critical Studies in Media Communication</i>, <b>26(2)</b>, 128-144 . <a href="http://www.tandfonline.com.ezproxy.cul.columbia.edu/doi/abs/10.1080/15295030902860252">link</a>.</a></li>
<li><a id="cheng_antisocial_2015">[cheng_antisocial_2015] Cheng, Danescu-Niculescu-Mizil & Leskovec, Antisocial Behavior in Online Discussion Communities., 61-70, in in: ICWSM, edited by </a></li>
<li><a id="pavlopoulos_deep_2017">[pavlopoulos_deep_2017] Pavlopoulos, Malakasiotis & Androutsopoulos, Deep Learning for User Comment Moderation, <i>arXiv preprint arXiv:1705.09993</i>, <b></b>, . <a href="https://arxiv.org/abs/1705.09993">link</a>.</a></li>
<li><a id="serra_class-based_2017">[serra_class-based_2017] Serra, Leontiadis, Spathis, Stringhini, Blackburn & Vakali, Class-based Prediction Errors to Detect Hate Speech with Out-of-vocabulary Words, <i>ACL 2017</i>, <b></b>, 36 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=48">link</a>.</a></li>
<li><a id="park_one-step_2017">[park_one-step_2017] Park & Fung, One-step and Two-step Classification for Abusive Language Detection on Twitter, <i>arXiv preprint arXiv:1706.01206</i>, <b></b>, . <a href="https://arxiv.org/abs/1706.01206">link</a>.</a></li>
<li><a id="kennedy_iii_hack_2017">[kennedy_iii_hack_2017] Kennedy III, McCollough, Dixon, Bastidas, Ryan, Loo & Sahay, Hack Harassment: Technology Solutions to Combat Online Harassment, <i>ACL 2017</i>, <b></b>, 73 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=85">link</a>.</a></li>
<li><a id="waseem_understanding_2017">[waseem_understanding_2017] Waseem, Davidson, Warmsley & Weber, Understanding Abuse: A Typology of Abusive Language Detection Subtasks, <i>arXiv preprint arXiv:1705.09899</i>, <b></b>, . <a href="https://arxiv.org/abs/1705.09899">link</a>.</a></li>
<li><a id="palmer_illegal_2017">[palmer_illegal_2017] Palmer, Robinson & Phillips, Illegal is not a Noun: Linguistic Form for Detection of Pejorative Nominalizations, <i>ACL 2017</i>, <b></b>, 91 . <a href="http://www.aclweb.org/anthology/W17-30#page=103">link</a>.</a></li>
<li><a id="kwok_locate_2013">[kwok_locate_2013] Kwok & Wang, Locate the Hate: Detecting Tweets against Blacks., in in: AAAI, edited by </a></li>
<li><a id="djuric_hate_2015">[djuric_hate_2015] Djuric, Zhou, Morris, Grbovic, Radosavljevic & Bhamidipati, Hate speech detection with comment embeddings, 29-30, in in: Proceedings of the 24th International Conference on World Wide Web, edited by ACM </a></li>
<li><a id="silva_analyzing_2016">[silva_analyzing_2016] Silva, Mondal, Correa, Benevenuto & Weber, Analyzing the Targets of Hate in Online Social Media., 687-690, in in: ICWSM, edited by </a></li>
<li><a id="clarke_dimensions_2017">[clarke_dimensions_2017] Clarke & Grieve, Dimensions of Abusive Language on Twitter, <i>ACL 2017</i>, <b></b>, 1 . <a href="http://www.aclweb.org/anthology/W/W17/W17-30.pdf#page=13">link</a>.</a></li>
<li><a id="liu_survey_2012">[liu_survey_2012] Liu & Zhang, A Survey of Opinion Mining and Sentiment Analysis, <i>SpringerLink</i>, <b></b>, 415-463 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/chapter/10.1007/978-1-4614-3223-4_13">link</a>. <a href="http://dx.doi.org/10.1007/978-1-4614-3223-4_13">doi</a>.</a></li>
<li><a id="jindal_opinion_2008">[jindal_opinion_2008] Jindal & Liu, Opinion spam and analysis, 219-230, in in: Proceedings of the 2008 International Conference on Web Search and Data Mining, edited by ACM </a></li>
<li><a id="jindal_review_2007">[jindal_review_2007] Jindal & Liu, Review spam detection, 1189-1190, in in: Proceedings of the 16th international conference on World Wide Web, edited by ACM </a></li>
<li><a id="mukherjee_detecting_2011">[mukherjee_detecting_2011] Mukherjee, Liu, Wang, Glance & Jindal, Detecting group review spam, 93-94, in in: Proceedings of the 20th international conference companion on World wide web, edited by ACM </a></li>
<li><a id="jindal_analyzing_2007">[jindal_analyzing_2007] Jindal & Liu, Analyzing and detecting review spam, 547-552, in in: Data Mining, 2007. ICDM 2007. Seventh IEEE International Conference on, edited by IEEE </a></li>
<li><a id="jindal_finding_2010">[jindal_finding_2010] Jindal, Liu & Lim, Finding unusual review patterns using unexpected rules, 1549-1552, in in: Proceedings of the 19th ACM international conference on Information and knowledge management, edited by ACM </a></li>
<li><a id="lim_detecting_2010">[lim_detecting_2010] Lim, Nguyen, Jindal, Liu & Lauw, Detecting product review spammers using rating behaviors, 939-948, in in: Proceedings of the 19th ACM international conference on Information and knowledge management, edited by ACM </a></li>
<li><a id="wu_distortion_2010">[wu_distortion_2010] Wu, Greene, Smyth & Cunningham, Distortion as a validation criterion in the identification of suspicious reviews, 10-13, in in: Proceedings of the First Workshop on Social Media Analytics, edited by ACM </a></li>
<li><a id="yoo_comparison_2009">[yoo_comparison_2009] Yoo & Gretzel, Comparison of deceptive and truthful travel reviews, <i>Information and communication technologies in tourism 2009</i>, <b></b>, 37-47 . <a href="http://www.springerlink.com.ezproxy.cul.columbia.edu/index/J487243460868455.pdf">link</a>.</a></li>
<li><a id="anderson_nasty_2014">[anderson_nasty_2014] Anderson, Brossard, Scheufele, Xenos & Ladwig, The “nasty effect:” Online incivility and risk perceptions of emerging technologies, <i>Journal of Computer-Mediated Communication</i>, <b>19(3)</b>, 373-387 . <a href="http://onlinelibrary.wiley.com.ezproxy.cul.columbia.edu/doi/10.1111/jcc4.12009/full">link</a>.</a></li>
<li><a id="diakopoulos_newsworthiness_2014">[diakopoulos_newsworthiness_2014] Diakopoulos & Zubiaga, Newsworthiness and Network Gatekeeping on Twitter: The Role of Social Deviance., in in: ICWSM, edited by </a></li>
<li><a id="gawda_emotional_2013">[gawda_emotional_2013] Gawda, The Emotional Lexicon of Individuals Diagnosed with Antisocial Personality Disorder, <i>Journal of Psycholinguistic Research</i>, <b>42(6)</b>, 571-580 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/s10936-012-9237-z">link</a>. <a href="http://dx.doi.org/10.1007/s10936-012-9237-z">doi</a>.</a></li>
<li><a id="gawda_syntax_2010">[gawda_syntax_2010] Gawda, Syntax of Emotional Narratives of Persons Diagnosed with Antisocial Personality, <i>Journal of Psycholinguistic Research</i>, <b>39(4)</b>, 273-283 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/s10936-009-9140-4">link</a>. <a href="http://dx.doi.org/10.1007/s10936-009-9140-4">doi</a>.</a></li>
<li><a id="rieber_language_1994">[rieber_language_1994] Rieber & Vetter, The language of the psychopath, <i>Journal of Psycholinguistic Research</i>, <b>23(1)</b>, 1-28 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/BF02143173">link</a>. <a href="http://dx.doi.org/10.1007/BF02143173">doi</a>.</a></li>
<li><a id="bovasso_graph_1993">[bovasso_graph_1993] Bovasso, Szalay, Biase & Stanford, A graph theory model of the semantic structure of attitudes, <i>Journal of Psycholinguistic Research</i>, <b>22(4)</b>, 411-425 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/BF01074344">link</a>. <a href="http://dx.doi.org/10.1007/BF01074344">doi</a>.</a></li>
<li><a id="kahn_measuring_2007">[kahn_measuring_2007] Kahn, Tobin, Massey & Anderson, Measuring Emotional Expression with the Linguistic Inquiry and Word Count, <i>The American Journal of Psychology</i>, <b>120(2)</b>, 263-286 . <a href="http://www.jstor.org/stable/20445398">link</a>. <a href="http://dx.doi.org/10.2307/20445398">doi</a>.</a></li>
<li><a id="argaman_linguistic_2010">[argaman_linguistic_2010] Argaman, Linguistic Markers and Emotional Intensity, <i>Journal of Psycholinguistic Research</i>, <b>39(2)</b>, 89-99 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/s10936-009-9127-1">link</a>. <a href="http://dx.doi.org/10.1007/s10936-009-9127-1">doi</a>.</a></li>
<li><a id="kapoor_swears_2016">[kapoor_swears_2016] Kapoor, Swears in Context: The Difference Between Casual and Abusive Swearing, <i>Journal of Psycholinguistic Research</i>, <b>45(2)</b>, 259-274 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/s10936-014-9345-z">link</a>. <a href="http://dx.doi.org/10.1007/s10936-014-9345-z">doi</a>.</a></li>
<li><a id="stephens_does_2017">[stephens_does_2017] Stephens & Zile, Does Emotional Arousal Influence Swearing Fluency?, <i>Journal of Psycholinguistic Research</i>, <b>46(4)</b>, 983-995 . <a href="https://link-springer-com.ezproxy.cul.columbia.edu/article/10.1007/s10936-016-9473-8">link</a>. <a href="http://dx.doi.org/10.1007/s10936-016-9473-8">doi</a>.</a></li>
<li><a id="toma_what_2012">[toma_what_2012] Toma & Hancock, What lies beneath: The linguistic traces of deception in online dating profiles, <i>Journal of Communication</i>, <b>62(1)</b>, 78-97 . <a href="http://onlinelibrary.wiley.com.ezproxy.cul.columbia.edu/doi/10.1111/j.1460-2466.2011.01619.x/full">link</a>.</a></li>
<li><a id="martellozzo_cybercrime_2017">[martellozzo_cybercrime_2017] Martellozzo & Jane, Cybercrime and its victims, Routledge .</a></li>
<li><a id="jane_misogyny_2016">[jane_misogyny_2016] Jane, Misogyny Online: A Short (and Brutish) History, SAGE .</a></li>
<li><a id="mantilla_gendertrolling:_2015">[mantilla_gendertrolling:_2015] Mantilla, Gendertrolling: How Misogyny Went Viral: How Misogyny Went Viral, ABC-CLIO .</a></li>
<li><a id="duggan_online_2014">[duggan_online_2014] Duggan, Online Harassment, <i></i>, <b></b>, . <a href="http://www.pewinternet.org/2014/10/22/online-harassment/">link</a>.</a></li>
</ul>
</p>
</div>
</div>
<div id="outline-container-org39c6f85" class="outline-2">
<h2 id="org39c6f85"><span class="section-number-2">8</span> Meeting notes</h2>
<div class="outline-text-2" id="text-8">
</div><div id="outline-container-org506568f" class="outline-3">
<h3 id="org506568f"><span class="section-number-3">8.1</span> Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-22 Tue&gt;</span></span></h3>
<div class="outline-text-3" id="text-8-1">
<p>
How does anti-bullying work in real life? 
How does online bullying differ from real-world bullying? 
</p>
<ul class="org-ul">
<li>Does bullying happen IRL when no one else is around, when they're not being watched?</li>
<li>Clear definitions of harassment and bullying are important here.</li>
</ul>
<p>
The training corpus and its limitations is important. 
Statistical literature on evaluating bullying? 
</p>
<ul class="org-ul">
<li>How could we quantify the adverse effects of bullying?</li>
</ul>
<p>
How would intervention work? 
"Publications on the Study of Bullying" 
</p>
<ul class="org-ul">
<li><a href="http://research.cs.wisc.edu/bullying/">http://research.cs.wisc.edu/bullying/</a></li>
<li>Using social media data to distinguish bullying from teasing.</li>
</ul>
<p>
What opportunities for colloration are there? 
Aggression, personal attacks as irrelevance. 
What power differentials are there between high-profile (lots of followers) figures and low-profile figures? 
What applications of RST might there be?  
</p>
</div>
</div>
<div id="outline-container-org6b654cc" class="outline-3">
<h3 id="org6b654cc"><span class="section-number-3">8.2</span> Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-08-28 Mon&gt;</span></span></h3>
<div class="outline-text-3" id="text-8-2">
<p>
Google account suspension of School of Prof. Studies stats professor, tweeting about Clinton and the 2016 election
</p>
<ul class="org-ul">
<li>ML algorithm probably made a mistake in categorizing this as abusive</li>
<li><a href="https://www.inc.com/sonya-mann/salil-mehta-free-speech.html">A Handful of Tech Companies Decide Who Has Free Speech Online. That's Not Good. | Inc.com</a></li>
</ul>
</div>
<div id="outline-container-org4b51f3b" class="outline-4">
<h4 id="org4b51f3b"><span class="section-number-4">8.2.1</span> Colin's week 1 summary: <a href="https://docs.google.com/document/d/1Hmk5KZxQ0ci_QZHlWFLDwX_Sr47fGgeSKS1qFFw17ok/edit?ts=59a45e96#heading=h.9eg2yefb1sbk">Summaries Week 1 - Google Docs</a></h4>
</div>
</div>

<div id="outline-container-org284c713" class="outline-3">
<h3 id="org284c713"><span class="section-number-3">8.3</span> Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-07 Thu&gt;</span></span></h3>
<div class="outline-text-3" id="text-8-3">
<p>
Colin: lack of theorizing re: cyberbullying
techniques of counterspeech
communities of abuse / trust propogation
social network studies have been done, and formality studies, but not yet formality+social network
! do more reading in psycholinguistics.
</p>
<ul class="org-ul">
<li>deixis</li>
</ul>
</div>
</div>
<div id="outline-container-orgd3beb0d" class="outline-3">
<h3 id="orgd3beb0d"><span class="section-number-3">8.4</span> Notes from meeting <span class="timestamp-wrapper"><span class="timestamp">&lt;2017-09-14 Thu&gt;</span></span></h3>
<div class="outline-text-3" id="text-8-4">
</div><div id="outline-container-orgf41271d" class="outline-4">
<h4 id="orgf41271d"><span class="section-number-4">8.4.1</span> NYU twitter bots: <a href="https://cds.nyu.edu/using-data-science-moderate-online-harrassment/">Using Data Science to Moderate Online Harrassment - NYU Center for Data Science</a></h4>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Jonathan Reeve</p>
<p class="date">Created: 2017-10-10 Tue 10:28</p>
<p class="validation"><a href="http://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
