---
title: A Safer Online Public Square
authors: Jonathan Reeve, Colin Muller
---

# Problems
## Taxonomies

 - Hate speech
   - “An expression that denigrates or stigmatizes a person or people based on their membership of a group that is usually but not always immutable, such as an ethnic or religious group. Sometimes other groups, defined by disability or sexual orientation, for example, are included.” Source: Benesch, Susan. Defining and diminishing hate speech. 2014. 

 - Bullying:
   - “Cyberbullying is any behavior performed through electronic or digital media by individuals or groups that repeatedly communicates hostile or aggressive messages intended to inflict harm or discomfort on others. Additionally, the following addendum may be included with the definition.... In cyberbullying experiences, the identity of the bully may or may not be known. Cyberbullying can occur through electronically mediated communication at school; however, cyberbullying behaviors commonly occur outside of school as well." Tokunaga, Robert S. "Following you home from school: A critical review and synthesis of research on cyberbullying victimization." Computers in human behavior 26.3 (2010): 278.
   - Definitions of cyberbullying are derived from definitions of traditional bullying which generally include the 3 conditions of 1. Repeated behavior 2. Psychological torment 3. Carried out with intent.
   - Cyberbullying is seen more as an “opportunistic offense” since individuals who don’t engage in traditional bullying will do so online since of the low threat of being caught and the lack of any clear disciplinary authority

 - Harassment and stalking
 - Dangerous speech
   - “speech that can inspire or catalyze intergroup violence” Source: Counterspeech on Twitter: A Field Study https://dangerousspeech.org/counterspeech-on-twitter-a-field-study/ 
   - Susan Benesch puts forward the following conditions that make the likelihood of speech resulting in group violence : 
     - there is a “powerful speaker with a high degree of influence;”
     - there is a receptive audience with “grievances and fear that the speaker can cultivate;”
     - a speech act “that is clearly under-stood as a call to violence;”
     - a social or historical context that is “propitious for violence, for any of a variety of reasons;”
     - An “influential means of dissemination.”” 
     - Source: http://www.worldpolicy.org/sites/default/files/Dangerous%20Speech%20Guidelines%20Benesch%20January%202012.pdf 

 - Abuse of journalists
   - "Gamergate"
 - Related language patterns that, while not strictly abusive language, could be useful to its detection
   - Misinformation (e.g. Russian fake news)
   - Deceptive opinion spam (e.g. fake Amazon product reviews) 

## Statistics 

 - General stats related to abusive langauge
 - Cyberbulling stats
 - Hate speech stats

# Existing Approaches
## Organizations 
### Advocacy Groups (Colin and Jonathan)

 - [Women's Media Center Speech Project](http://wmcspeechproject.com/)
 - Working to Halt Online Abuse
 - No Hate Speech Movement
 - Etc...

#### Legal Aid (Colin)
#### Education (Colin)

### Initiatives by Social Media Platforms

 - Official policies of Facebook, Twitter
 - Twitter's "progress on addressing online abuse"
 - Implementations of Perspective API on Facebook, Reddit
 - New social media outlets (Mastodon) created with these problems in mind
 - Moderation, flagging

### Databases and Datasets

 - Trolldor: "the global blacklist of twitter trolls"
 - Hatebase
 - Gamergate tweets
 - Public training data from Kaggle contest and other similar projects

### Organizations and Projects Employing Machine Learning 

 - Jigsaw (Google)
   - Perspective API
 - Wikimedia Foundation WikiDeTox project
 - Brief survey of US patents for detection of "offensiveness"
 
## Computational Detection of Abusive Language, Behaviors, or People (Jonathan)

### General Classification Studies

 - Tokenization and pre-processing
 - Features used
 - Classifiers used
 - Meta-classification

### Detection of Quality, Formality

 - Formality scores
 - Grammatical quality
 
### Detection and Analysis of Swearing

 - Disambiguation of friendly and abusive swearing

### Sentiment Analysis

### Metadata Analysis

 - Detection of bots, trolls
 - Social network theory
 - Trust propogation

### Related Fields

 - Detection of deceptive opinion spam 
 - Detection of misinformation

## And the Law (Colin)
## Counterspeech (Colin)

 - Kevin Munger article

### Types

A useful method of typologizing harmful speech online is by distinguishing between the types of exchanges (vectors). (This is based on the models put forward in Counterspeech on Twitter: A Field Study)
 
 - One-to-one: one person deploying counterspeech against one person’s hate speech
 - One-to-many: one person deploying counterspeech against many people’s hate speech
 - Many-to-one: many people deploying counterspeech against one person’s hate speech
 - Many-to-many: many people deploying counterspeech against many people’s hate speech
 
# Future Directions

## Potential Applications of Related Fields (Jonathan)

### Psycholinguistics

 - Linguistic properties of emotional speech
 - "Language of psychopathy"

### Fusions of Existing Approaches 

 - Formality detection and social network theory
 - Quality ranking

## Automated Counterspeech 
